{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.api._v2.keras import layers\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import numba as nb\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of transmitter-receiver pairs\n",
    "K = 5\n",
    "\n",
    "# Minimum rate for the achievable SINR of multiple concurrent transmissions\n",
    "SINR_P_min = tf.constant([0.2, 0.2, 0.2, 0.2, 0.2], dtype=tf.float32)\n",
    "\n",
    "# Maximum transmit power\n",
    "PMax = tf.constant(1.0, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variances for noise signals at different dB levels\n",
    "sigma_sqr_noise_0dB = np.full(5, 1e-0, dtype=float)\n",
    "sigma_sqr_noise_10dB = np.full(5, 1e-1, dtype=float)\n",
    "sigma_sqr_noise_20dB = np.full(5, 1e-2, dtype=float)\n",
    "sigma_sqr_noise_30dB = np.full(5, 1e-3, dtype=float)\n",
    "sigma_sqr_noise_40dB = np.full(5, 1e-4, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load and reshape the CSV files into 3D arrays\n",
    "def load_and_reshape(file_path, K):\n",
    "    # Load the CSV file as a 2D array\n",
    "    FH2D = loadtxt(file_path, delimiter=',', dtype=str)\n",
    "    \n",
    "    # Reshape the 2D array into a 3D array\n",
    "    FH3D = FH2D.reshape(FH2D.shape[0], -1, K)\n",
    "    \n",
    "    # Return the reshaped array and its size\n",
    "    return FH3D, FH3D.shape[0]\n",
    "\n",
    "Folder = \"C:\\\\Users\\\\essay\\\\Desktop\\\\FYP\\\\Datasets\\\\K=5\"\n",
    "\n",
    "# Loading and reshaping the arrays from CSV files\n",
    "FH3D_0dB, FH3D_0dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_0dB.csv'), K=5)\n",
    "FH3D_10dB, FH3D_10dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_10dB.csv'), K=5)\n",
    "FH3D_20dB, FH3D_20dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_20dB.csv'), K=5)\n",
    "FH3D_30dB, FH3D_30dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_30dB.csv'), K=5)\n",
    "FH3D_40dB, FH3D_40dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_40dB.csv'), K=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert string data to complex data and remove initial whitespace using vectorized operations\n",
    "def cnvrt_2_cmplx_data(FH3D_size, FH3D):\n",
    "    # Use np.char.strip to remove initial whitespace from the entire 3D array\n",
    "    FH3D_stripped = np.char.strip(FH3D)\n",
    "    \n",
    "    # Convert the stripped string array to complex numbers using vectorized conversion\n",
    "    FHCmplx = FH3D_stripped.astype(np.complex_)\n",
    "    \n",
    "    # Reshape the array directly to the desired shape (H_size, K, K)\n",
    "    F_H = FHCmplx.reshape(FH3D_size, K, K)\n",
    "    \n",
    "    return F_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "## Converting string data to complex data and removing the initial whitespace\n",
    "F_H_0dB = cnvrt_2_cmplx_data(FH3D_0dB_size, FH3D_0dB)\n",
    "F_H_10dB = cnvrt_2_cmplx_data(FH3D_10dB_size, FH3D_10dB)\n",
    "F_H_20dB = cnvrt_2_cmplx_data(FH3D_20dB_size, FH3D_20dB)\n",
    "F_H_30dB = cnvrt_2_cmplx_data(FH3D_30dB_size, FH3D_30dB)\n",
    "F_H_40dB = cnvrt_2_cmplx_data(FH3D_40dB_size, FH3D_40dB)\n",
    "\n",
    "print(F_H_0dB.shape)\n",
    "print(F_H_10dB.shape)\n",
    "print(F_H_20dB.shape)\n",
    "print(F_H_30dB.shape)\n",
    "print(F_H_40dB.shape)\n",
    "\n",
    "F_H_0dB_size = F_H_0dB.shape[0]\n",
    "F_H_10dB_size = F_H_10dB.shape[0]\n",
    "F_H_20dB_size = F_H_20dB.shape[0]\n",
    "F_H_30dB_size = F_H_30dB.shape[0]\n",
    "F_H_40dB_size = F_H_40dB.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.23631937+0.22921883j -0.54667901-0.20138914j\n",
      "   -0.47946164+0.498344j    0.3113009 -0.22798014j\n",
      "    0.69691993-0.88261167j]\n",
      "  [-0.14673233-0.67982819j  1.05716624-0.17533585j\n",
      "    1.40408283-0.3634557j  -0.01055404-0.70807464j\n",
      "   -0.25915166+0.60921694j]\n",
      "  [ 0.78419976-0.33361193j  0.40834267+1.0118874j\n",
      "   -0.96713008-0.16796663j -0.6647029 -0.7954383j\n",
      "    0.02752075-0.71561235j]\n",
      "  [ 0.3465332 -0.09099838j -0.4367235 +1.37334099j\n",
      "    0.7779833 +0.29038137j -0.05983818+0.77268389j\n",
      "    0.50615944-0.15630014j]\n",
      "  [ 0.53521481-0.13481686j  1.21080065-0.03027252j\n",
      "   -0.48457478+0.57532919j  0.01145698-0.21696277j\n",
      "    1.17455914+1.17218511j]]\n",
      "\n",
      " [[ 0.79699507+0.63304366j  0.01760131+0.32898345j\n",
      "    0.05801209+0.55645257j  0.38766506-0.43073101j\n",
      "   -0.45751618-0.60856057j]\n",
      "  [-0.26554943-0.92245427j -0.85025071+0.87457213j\n",
      "    0.29233821+0.99113017j -1.19413667-0.06657383j\n",
      "    0.12229737+0.16174348j]\n",
      "  [-0.10512262-1.25990919j -0.40637738-0.68602838j\n",
      "    0.01210378-1.02630839j  0.47588371-0.08603115j\n",
      "    0.09309989+0.11602879j]\n",
      "  [-0.22732738+0.79207634j -0.16634939-0.27815233j\n",
      "    1.24831871+0.01199174j  0.75898117-0.08660323j\n",
      "    0.81174366+0.45061337j]\n",
      "  [ 0.36262892-0.5270233j  -0.73321827-1.38334335j\n",
      "   -0.00912687+0.92046035j  1.20061156+0.09927137j\n",
      "   -0.14781791+0.99923613j]]\n",
      "\n",
      " [[-0.64804294+0.46525681j  0.16549187+0.47468413j\n",
      "   -0.20747958-0.17463521j  0.43210841-0.12210355j\n",
      "    0.65070062-0.36521428j]\n",
      "  [-0.56029947+1.25975985j -0.11264297+1.73582172j\n",
      "    0.39986776+1.24560395j  0.309937  +0.03050013j\n",
      "    0.02377968-0.09915411j]\n",
      "  [ 0.84955967-0.88454336j -1.06070152+0.40656115j\n",
      "    1.12302148-0.77515379j -1.24576166+0.02660652j\n",
      "    0.05830689-0.10745618j]\n",
      "  [-0.88447658+0.96005678j -0.03175394+0.58287616j\n",
      "   -0.17964543+0.72722242j -0.69696048+0.03552663j\n",
      "   -1.28187984-0.46384551j]\n",
      "  [-0.23177995+0.5015831j   0.09772908+1.59263317j\n",
      "    0.34319981+0.14942333j  0.88534137+0.34671507j\n",
      "    0.19711277+1.59253349j]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.35110619+0.75164102j -0.66832613-0.88770411j\n",
      "    0.56969782+0.60267587j  0.1448037 +0.17523717j\n",
      "    0.2925982 +1.4000573j ]\n",
      "  [ 0.10966727-1.22817466j  0.79169845+0.40461756j\n",
      "    0.16540382+0.72903676j  0.03785419+0.72473118j\n",
      "   -0.97545371+0.74242792j]\n",
      "  [-0.54865403+1.01148071j  0.22893075+0.5099906j\n",
      "    0.89581451-0.89142613j  0.5665831 -0.38018336j\n",
      "   -0.66661349+0.50856041j]\n",
      "  [-0.36387826+1.17965168j -0.01587501-0.66000489j\n",
      "   -0.10909053+0.70365052j  0.05971599+1.01355122j\n",
      "    0.1232049 +0.73097491j]\n",
      "  [ 0.42698062-0.89785996j -0.95494014-0.88348405j\n",
      "   -0.90977225+0.00804317j -0.20193161-0.02668996j\n",
      "   -1.69940106-0.17876902j]]\n",
      "\n",
      " [[ 0.76513758-0.89034527j  1.01685448-0.00874106j\n",
      "    0.28316273+0.87179655j -0.68672858-0.12423602j\n",
      "   -0.44265524+0.24376109j]\n",
      "  [-0.40001253-0.11647371j -0.53445838+1.26245197j\n",
      "   -1.13089017-0.72087593j -0.49797817-0.70575168j\n",
      "   -0.9633443 +0.51147263j]\n",
      "  [ 0.54043188+0.3411341j  -0.67908527+1.55748463j\n",
      "   -1.30985573+0.24588651j -1.43974121-0.04183714j\n",
      "   -0.51747427+1.2642712j ]\n",
      "  [ 0.16977946-0.20115379j -0.55330591-1.15664491j\n",
      "   -0.27434796+0.55125128j -0.85766661-0.10238393j\n",
      "    0.81617442-0.00872848j]\n",
      "  [-0.81229511-0.19632708j  0.41739093-0.45775496j\n",
      "   -0.76014925+0.71615056j -0.30547585-0.55516717j\n",
      "   -1.65385442+0.29650634j]]\n",
      "\n",
      " [[ 0.13441276-1.1112329j  -0.10208992+0.37949394j\n",
      "    0.21410846+0.60197919j  1.06091448-0.72269727j\n",
      "    0.10345367-1.57739645j]\n",
      "  [ 0.24680004+0.11809635j  0.69535003-0.0301694j\n",
      "    0.69358654+0.54599125j  0.54677691-0.53646087j\n",
      "    1.46393104+0.72790428j]\n",
      "  [-0.11393922-0.178748j   -0.01908946-0.04262089j\n",
      "    0.94483365+0.38377272j -0.4907984 -0.4920892j\n",
      "    0.52972141+1.3019612j ]\n",
      "  [-0.7882661 -0.15441574j  0.41362767-0.48322579j\n",
      "    0.90501556+0.51547975j -1.01851061+0.79979708j\n",
      "   -0.01309613-0.60471579j]\n",
      "  [-0.43597285+0.28624563j -0.06172437+0.16210253j\n",
      "    0.43510299+0.38052826j -0.53205679+0.33003762j\n",
      "   -0.81119791+0.79430835j]]]\n"
     ]
    }
   ],
   "source": [
    "print(F_H_0dB)\n",
    "# print(F_H_10dB)\n",
    "# print(F_H_20dB)\n",
    "# print(F_H_30dB)\n",
    "# print(F_H_40dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the square of the absolute value of a complex tensor\n",
    "def cmplx_abs_sqr(cmplx_var):\n",
    "    # Calculate the squared magnitude of the complex numbers\n",
    "    return tf.math.square(tf.math.real(cmplx_var)) + tf.math.square(tf.math.imag(cmplx_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the matrix A (K x K) using TensorFlow functions\n",
    "def generate_A(F_H_size, K, SINR_P_min, F_H):\n",
    "    # Calculate the squared magnitude of the complex matrix and cast to float32\n",
    "    F_H_abs_sqr = tf.cast(cmplx_abs_sqr(F_H), dtype=tf.float32)\n",
    "\n",
    "    # Create an identity matrix for selecting diagonal elements (float32)\n",
    "    identity_matrix = tf.eye(K, dtype=tf.float32)\n",
    "\n",
    "    # Expand SINR_P_min to match dimensions for broadcasting and cast to float32\n",
    "    SINR_P_min_expanded = tf.expand_dims(tf.cast(SINR_P_min, dtype=tf.float32), axis=-1)  # Shape: (K, 1)\n",
    "\n",
    "    # Create the matrix A using TensorFlow operations\n",
    "    Aij = tf.where(\n",
    "        tf.equal(identity_matrix, 1),  # Condition to keep diagonal elements\n",
    "        F_H_abs_sqr,                   # Use F_H_abs_sqr for diagonal elements\n",
    "        -SINR_P_min_expanded * F_H_abs_sqr  # Multiply off-diagonal elements by -SINR_P_min\n",
    "    )\n",
    "\n",
    "    # Reshape the resulting array to (F_H_size, K, K)\n",
    "    Aij = tf.reshape(Aij, (F_H_size, K, K))\n",
    "\n",
    "    return Aij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to generate the vector b (K x 1) using TensorFlow operations\n",
    "def generate_b(F_H_size, K, SINR_P_min, sigma_sqr_noise, F_H):\n",
    "    # Calculate the vector b by broadcasting SINR_P_min and sigma_sqr_noise\n",
    "    b = tf.multiply(SINR_P_min, sigma_sqr_noise)  # Element-wise multiplication\n",
    "    \n",
    "    # Reshape to (1, K, 1) to match dimensions for broadcasting\n",
    "    b = tf.reshape(b, (1, K, 1))\n",
    "\n",
    "    # Repeat this result across the F_H_size dimension\n",
    "    bi = tf.repeat(b, repeats=F_H_size, axis=0)\n",
    "    \n",
    "    return bi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split datasets into training, validation, and testing\n",
    "def split(np_array):\n",
    "    # Define fixed sizes for training, validation, and testing datasets\n",
    "    train_data_size = 200000\n",
    "    valid_data_size = 25000\n",
    "    test_data_size = 25000\n",
    "\n",
    "    # Calculate the indices for slicing the dataset\n",
    "    train_e_indx = train_data_size\n",
    "    valid_e_indx = train_e_indx + valid_data_size\n",
    "    test_e_indx = valid_e_indx + test_data_size\n",
    "\n",
    "    # Slice the input array into training, validation, and testing datasets\n",
    "    train_data = np_array[:train_e_indx]\n",
    "    valid_data = np_array[train_e_indx:valid_e_indx]\n",
    "    test_data = np_array[valid_e_indx:test_e_indx]\n",
    "\n",
    "    # Calculate the absolute values of the datasets\n",
    "    train_input = np.abs(train_data)\n",
    "    valid_input = np.abs(valid_data)\n",
    "    test_input = np.abs(test_data)\n",
    "\n",
    "    # Print the shapes to verify correctness\n",
    "    print(train_input.shape, valid_input.shape, test_input.shape)\n",
    "\n",
    "    # Return the split datasets\n",
    "    return [train_input, valid_input, test_input, test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# List of F_H matrices\n",
    "F_H_matrices = [F_H_0dB, F_H_10dB, F_H_20dB, F_H_30dB, F_H_40dB]\n",
    "\n",
    "# Split each matrix and assign the results to corresponding variables\n",
    "splits = [split(F_H) for F_H in F_H_matrices]\n",
    "\n",
    "(train_input_F_H_0dB, valid_input_F_H_0dB, test_input_F_H_0dB, test_data_F_H_0dB), \\\n",
    "(train_input_F_H_10dB, valid_input_F_H_10dB, test_input_F_H_10dB, test_data_F_H_10dB), \\\n",
    "(train_input_F_H_20dB, valid_input_F_H_20dB, test_input_F_H_20dB, test_data_F_H_20dB), \\\n",
    "(train_input_F_H_30dB, valid_input_F_H_30dB, test_input_F_H_30dB, test_data_F_H_30dB), \\\n",
    "(train_input_F_H_40dB, valid_input_F_H_40dB, test_input_F_H_40dB, test_data_F_H_40dB) = splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of p_hat vectors\n",
    "# p_hat_vectors = [p_hat_0dB, p_hat_10dB, p_hat_20dB, p_hat_30dB, p_hat_40dB]\n",
    "\n",
    "# # Split each vector and assign the results to corresponding variables\n",
    "# p_hat_splits = [split(p_hat) for p_hat in p_hat_vectors]\n",
    "\n",
    "# (train_input_p_hat_0dB, valid_input_p_hat_0dB, test_input_p_hat_0dB, test_data_p_hat_0dB), \\\n",
    "# (train_input_p_hat_10dB, valid_input_p_hat_10dB, test_input_p_hat_10dB, test_data_p_hat_10dB), \\\n",
    "# (train_input_p_hat_20dB, valid_input_p_hat_20dB, test_input_p_hat_20dB, test_data_p_hat_20dB), \\\n",
    "# (train_input_p_hat_30dB, valid_input_p_hat_30dB, test_input_p_hat_30dB, test_data_p_hat_30dB), \\\n",
    "# (train_input_p_hat_40dB, valid_input_p_hat_40dB, test_input_p_hat_40dB, test_data_p_hat_40dB) = p_hat_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of sizes and dB levels\n",
    "sizes = [F_H_0dB_size, F_H_10dB_size, F_H_20dB_size, F_H_30dB_size, F_H_40dB_size]\n",
    "dB_levels = [0, 10, 20, 30, 40]\n",
    "\n",
    "# Create EsN0 arrays and reshape into vectors using TensorFlow\n",
    "EsN0_arrays = [tf.fill([size, 1], dB) for size, dB in zip(sizes, dB_levels)]\n",
    "\n",
    "# Unpack into variables\n",
    "(EsN0_vector_0dB, EsN0_vector_10dB, EsN0_vector_20dB, \n",
    " EsN0_vector_30dB, EsN0_vector_40dB) = EsN0_arrays\n",
    "\n",
    "# Print shapes of the vectors\n",
    "print(EsN0_vector_0dB.shape)\n",
    "print(EsN0_vector_10dB.shape)\n",
    "print(EsN0_vector_20dB.shape)\n",
    "print(EsN0_vector_30dB.shape)\n",
    "print(EsN0_vector_40dB.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10]\n",
      " [10]\n",
      " [10]\n",
      " ...\n",
      " [10]\n",
      " [10]\n",
      " [10]], shape=(250000, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(EsN0_vector_10dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split EsN0 vector for training, validation, and testing\n",
    "def split_EsN0(tf_vector):\n",
    "    # Define fixed sizes for training, validation, and testing datasets\n",
    "    train_data_size = 200000\n",
    "    valid_data_size = 25000\n",
    "    test_data_size = 25000\n",
    "\n",
    "    # Calculate indices for slicing\n",
    "    train_e_indx = train_data_size\n",
    "    valid_e_indx = train_e_indx + valid_data_size\n",
    "    test_e_indx = valid_e_indx + test_data_size\n",
    "\n",
    "    # Slice the tensor directly into training, validation, and testing datasets using TensorFlow\n",
    "    train_data = tf.reshape(tf_vector[:train_e_indx], (train_data_size, -1, 1))\n",
    "    valid_data = tf.reshape(tf_vector[train_e_indx:valid_e_indx], (valid_data_size, -1, 1))\n",
    "    test_data = tf.reshape(tf_vector[valid_e_indx:test_e_indx], (test_data_size, -1, 1))\n",
    "\n",
    "    # Calculate the absolute values (if needed)\n",
    "    train_input = tf.abs(train_data)\n",
    "    valid_input = tf.abs(valid_data)\n",
    "    test_input = tf.abs(test_data)\n",
    "\n",
    "    # Print shapes to verify correctness\n",
    "    print(train_input.shape, valid_input.shape, test_input.shape)\n",
    "\n",
    "    # Return the split datasets\n",
    "    return [train_input, valid_input, test_input, test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of EsN0 vectors\n",
    "EsN0_vectors = [EsN0_vector_0dB, EsN0_vector_10dB, EsN0_vector_20dB, EsN0_vector_30dB, EsN0_vector_40dB]\n",
    "\n",
    "# Split each EsN0 vector\n",
    "EsN0_splits = [split_EsN0(EsN0) for EsN0 in EsN0_vectors]\n",
    "\n",
    "# Unpack the split results into corresponding variables\n",
    "(train_input_EsN0_0dB, valid_input_EsN0_0dB, test_input_EsN0_0dB, test_data_EsN0_0dB), \\\n",
    "(train_input_EsN0_10dB, valid_input_EsN0_10dB, test_input_EsN0_10dB, test_data_EsN0_10dB), \\\n",
    "(train_input_EsN0_20dB, valid_input_EsN0_20dB, test_input_EsN0_20dB, test_data_EsN0_20dB), \\\n",
    "(train_input_EsN0_30dB, valid_input_EsN0_30dB, test_input_EsN0_30dB, test_data_EsN0_30dB), \\\n",
    "(train_input_EsN0_40dB, valid_input_EsN0_40dB, test_input_EsN0_40dB, test_data_EsN0_40dB) = EsN0_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 5, 5)\n",
      "(1000000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of input arrays for F_H and EsN0\n",
    "train_inputs_F_H = [train_input_F_H_0dB, train_input_F_H_10dB, \n",
    "                    train_input_F_H_20dB, train_input_F_H_30dB, \n",
    "                    train_input_F_H_40dB]\n",
    "\n",
    "train_inputs_EsN0 = [train_input_EsN0_0dB, train_input_EsN0_10dB, \n",
    "                     train_input_EsN0_20dB, train_input_EsN0_30dB, \n",
    "                     train_input_EsN0_40dB]\n",
    "\n",
    "# Stack the datasets vertically using TensorFlow's tf.concat\n",
    "train_input_F_H = tf.concat(train_inputs_F_H, axis=0)\n",
    "train_input_EsN0 = tf.concat(train_inputs_EsN0, axis=0)\n",
    "\n",
    "# Print shapes to verify correctness\n",
    "print(train_input_F_H.shape)\n",
    "print(train_input_EsN0.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 5, 5)\n",
      "(125000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of validation input arrays for F_H and EsN0\n",
    "valid_inputs_F_H = [valid_input_F_H_0dB, valid_input_F_H_10dB, \n",
    "                    valid_input_F_H_20dB, valid_input_F_H_30dB, \n",
    "                    valid_input_F_H_40dB]\n",
    "\n",
    "valid_inputs_EsN0 = [valid_input_EsN0_0dB, valid_input_EsN0_10dB, \n",
    "                     valid_input_EsN0_20dB, valid_input_EsN0_30dB, \n",
    "                     valid_input_EsN0_40dB]\n",
    "\n",
    "# Stack the datasets vertically using TensorFlow's tf.concat\n",
    "valid_input_F_H = tf.concat(valid_inputs_F_H, axis=0)\n",
    "valid_input_EsN0 = tf.concat(valid_inputs_EsN0, axis=0)\n",
    "\n",
    "# Print shapes to verify correctness\n",
    "print(valid_input_F_H.shape)\n",
    "print(valid_input_EsN0.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the training datasets using TensorFlow\n",
    "train_shuffler = tf.random.shuffle(tf.range(tf.shape(train_input_F_H)[0]))\n",
    "\n",
    "train_input_F_H_shuffled = tf.gather(train_input_F_H, train_shuffler)\n",
    "train_input_EsN0_shuffled = tf.gather(train_input_EsN0, train_shuffler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the validation datasets using TensorFlow\n",
    "valid_shuffler = tf.random.shuffle(tf.range(tf.shape(valid_input_F_H)[0]))\n",
    "\n",
    "valid_input_F_H_shuffled = tf.gather(valid_input_F_H, valid_shuffler)\n",
    "valid_input_EsN0_shuffled = tf.gather(valid_input_EsN0, valid_shuffler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1000000       1      26], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "const = K * K\n",
    "len1 = tf.shape(train_input_F_H_shuffled)[0]\n",
    "\n",
    "# Reshape train_input_F_H_shuffled using TensorFlow's reshape function\n",
    "train_input_F_H_shuffled_reshaped = tf.reshape(train_input_F_H_shuffled, (len1, 1, const))  # size X row X column\n",
    "\n",
    "# Ensure both tensors are of the same type, e.g., float32\n",
    "train_input_F_H_shuffled_reshaped = tf.cast(train_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "train_input_EsN0_shuffled = tf.cast(train_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# Remove the dimension of size 1 in the middle\n",
    "#train_y_true = tf.squeeze(train_y_true, axis=1)\n",
    "\n",
    "# Print the shape of the result\n",
    "print(tf.shape(train_y_true))  # Expected output: [1000000, 26]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constants\n",
    "# const = K * K\n",
    "# len1 = tf.shape(train_input_F_H_shuffled)[0]\n",
    "\n",
    "# # Reshape train_input_F_H_shuffled using TensorFlow's reshape function\n",
    "# train_input_F_H_shuffled_reshaped = tf.reshape(train_input_F_H_shuffled, (len1, 1, const))  # size X row X column\n",
    "\n",
    "# # Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "# train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# # Print the shape of the result\n",
    "# print(tf.shape(train_y_true))\n",
    "\n",
    "# # Ensure both tensors are of the same type, e.g., float32\n",
    "# train_input_F_H_shuffled_reshaped = tf.cast(train_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "# train_input_EsN0_shuffled = tf.cast(train_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# # Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "# train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# # Print the shape of the result\n",
    "# print(tf.shape(train_y_true))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([125000      1     26], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Reshape valid_input_F_H_shuffled\n",
    "len2 = tf.shape(valid_input_F_H_shuffled)[0]\n",
    "\n",
    "# Reshape using TensorFlow\n",
    "valid_input_F_H_shuffled_reshaped = tf.reshape(valid_input_F_H_shuffled, [len2, 1, const])  # size X row X column\n",
    "\n",
    "# Ensure both tensors are of the same data type, for example, float32\n",
    "valid_input_F_H_shuffled_reshaped = tf.cast(valid_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "valid_input_EsN0_shuffled = tf.cast(valid_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# Concatenate reshaped F_H and EsN0 inputs using TensorFlow\n",
    "valid_y_true = tf.concat([valid_input_F_H_shuffled_reshaped, valid_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "#valid_y_true = tf.squeeze(valid_y_true, axis=1) \n",
    "\n",
    "# Print the shape of the result using TensorFlow\n",
    "print(tf.shape(valid_y_true))\n",
    "\n",
    "#print(valid_y_true.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Functional_Api\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " hij_inputs (InputLayer)        [(None, 5, 5)]       0           []                               \n",
      "                                                                                                  \n",
      " EsN0_inputs (InputLayer)       [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " flatten_layer_hij (Flatten)    (None, 25)           0           ['hij_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " Flatten_Layer_EsN0 (Flatten)   (None, 1)            0           ['EsN0_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 26)           0           ['flatten_layer_hij[0][0]',      \n",
      "                                                                  'Flatten_Layer_EsN0[0][0]']     \n",
      "                                                                                                  \n",
      " Dense_layer_1 (Dense)          (None, 50)           1350        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " BN_Layer_1 (BatchNormalization  (None, 50)          200         ['Dense_layer_1[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Dense_Layer_2 (Dense)          (None, 25)           1275        ['BN_Layer_1[0][0]']             \n",
      "                                                                                                  \n",
      " BN_Layer_2 (BatchNormalization  (None, 25)          100         ['Dense_Layer_2[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " P_hat (Dense)                  (None, 5)            130         ['BN_Layer_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,055\n",
      "Trainable params: 2,905\n",
      "Non-trainable params: 150\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define the DNN model - The Functional API\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "hij_inputs = keras.Input(shape=(K,K), name = \"hij_inputs\")\n",
    "Flatten_1 = layers.Flatten(name = \"flatten_layer_hij\")(hij_inputs)\n",
    "\n",
    "EsN0_inputs = keras.Input(shape=(1,1), name = \"EsN0_inputs\")\n",
    "Flatten_2 = layers.Flatten(name = \"Flatten_Layer_EsN0\")(EsN0_inputs)\n",
    "\n",
    "concat_layers = concatenate([Flatten_1, Flatten_2])\n",
    "\n",
    "Dense_1 = layers.Dense(2*K*K, activation=\"relu\", name = \"Dense_layer_1\")(concat_layers)\n",
    "BN_1 = layers.BatchNormalization(name = \"BN_Layer_1\")(Dense_1)\n",
    "\n",
    "Dense_2 = layers.Dense(K*K, activation=\"relu\", name = \"Dense_Layer_2\")(BN_1)\n",
    "BN_2 = layers.BatchNormalization(name = \"BN_Layer_2\")(Dense_2)\n",
    "\n",
    "P_hat = layers.Dense(K, activation=\"sigmoid\", name = \"P_hat\")(BN_2)\n",
    "\n",
    "model = keras.Model(inputs = [hij_inputs, EsN0_inputs], outputs = P_hat, name = \"Functional_Api\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "## Convert SINR_P_min from numpy array to tensor\n",
    "SINR_P_min_t = tf.convert_to_tensor(SINR_P_min, dtype = float)\n",
    "tf.print(SINR_P_min_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A_tilda(A, K):\n",
    "    # Identity matrix of size K x K\n",
    "    I = tf.eye(K)\n",
    "    \n",
    "    # Negative identity matrix\n",
    "    neg_I = -I\n",
    "\n",
    "    # Repeat the identity and negative identity across batch dimension (1000)\n",
    "    I_batch = tf.tile(tf.expand_dims(I, axis=0), [A.shape[0], 1, 1])\n",
    "    neg_I_batch = tf.tile(tf.expand_dims(neg_I, axis=0), [A.shape[0], 1, 1])\n",
    "\n",
    "    # Concatenate I, -I, and A to form A_tilda\n",
    "    A_tilda = tf.concat([I_batch, neg_I_batch, A], axis=1)\n",
    "\n",
    "    return A_tilda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_B_tilda(B, K):\n",
    "    # Zero vector of size K\n",
    "    zeros = tf.zeros_like(B)\n",
    "    ones = tf.ones_like(B) * -PMax\n",
    "\n",
    "    # Reshape B to match the required dimensions\n",
    "    B_reshaped = tf.reshape(B, (-1, K, 1))\n",
    "\n",
    "    # Concatenate zeros and B to form B_tilda\n",
    "    B_tilda = tf.concat([zeros, ones, B_reshaped], axis=1)\n",
    "\n",
    "    return B_tilda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_A_tilda(A_tilda):\n",
    "    return tf.transpose(A_tilda, perm=[0, 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized loss function that penalizes the constraint violation\n",
    "def custom_loss_DC3(y_true, y_pred):\n",
    "    # Multiply predicted values by p_max\n",
    "    p = tf.multiply(PMax, y_pred)\n",
    "    p = tf.reshape(p, (-1, K, 1))\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "    learning_rate = 1e-3\n",
    "        \n",
    "\n",
    "    # Extract EsN0 value and reshape y_true to exclude EsN0 column\n",
    "    mtrx_elmnt = K * K\n",
    "    EsN0_val = y_true[:, 0, mtrx_elmnt]\n",
    "    y_true_updt = y_true[:, :, :-1]\n",
    "\n",
    "    # Determine noise variance based on EsN0 value\n",
    "    sigma_sqr_noise_lf = tf.where(EsN0_val < 10, 1e-0,\n",
    "                                  tf.where(EsN0_val < 20, 1e-1,\n",
    "                                           tf.where(EsN0_val < 30, 1e-2,\n",
    "                                                    tf.where(EsN0_val < 40, 1e-3, 1e-4))))\n",
    "\n",
    "    # Reshape y_true to form hij matrix and calculate squared magnitudes\n",
    "    hij = tf.reshape(y_true_updt[:, 0:K*K], (-1, K, K))\n",
    "    hij_abs_sqr = tf.square(tf.abs(hij))\n",
    "\n",
    "\n",
    "\n",
    "      ## Create matrix A\n",
    "    A = generate_A(hij.shape[0], K, SINR_P_min, hij)\n",
    "    b = generate_b(hij.shape[0], K, SINR_P_min, sigma_sqr_noise_0dB, hij)\n",
    "    \n",
    "    B = tf.reshape(b, (-1, K, 1))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Define A_tilda, b_tilda, A_transpose_tilda\n",
    "     ## Compute A_tilda and B_tilda\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(B, K)\n",
    "\n",
    "    ## Transpose A_tilda\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    \n",
    "    # Gradient Descent for Correction\n",
    "    for i in range(100):\n",
    "         # V = tf.linalg.matmul(A_tilda , p )  - b_tilda\n",
    "         V = B_tilda - tf.matmul(A_tilda, p)\n",
    "         V_relu = tf.nn.relu(V)\n",
    "         gd   = -2 * tf.matmul( A_tilda_T ,V_relu)\n",
    "         p = p - learning_rate * gd\n",
    "    \n",
    "    p = tf.nn.relu(p)\n",
    "         \n",
    "\n",
    "             \n",
    "    # # Calculate interference and SINR for each transmitter-receiver pair\n",
    "    #ph = tf.reduce_sum(tf.multiply(p[:, tf.newaxis], hij_abs_sqr), axis=2)  # Interference + noise\n",
    "\n",
    "    ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr), axis=2) \n",
    "    diag_part_expanded = tf.expand_dims(tf.linalg.diag_part(hij_abs_sqr), axis=-1)\n",
    "    numr = tf.multiply(p, diag_part_expanded)  # Signal power (numerator)\n",
    "    sigma_sqr_noise_lf_expanded = tf.expand_dims(sigma_sqr_noise_lf, axis=-1)\n",
    "    dnumr = sigma_sqr_noise_lf_expanded + ph - tf.squeeze(numr, axis=-1)\n",
    "    SINR_i = tf.divide(tf.squeeze(numr, axis=-1), dnumr)\n",
    "    \n",
    "    #numr = tf.multiply(p, tf.linalg.diag_part(hij_abs_sqr))  # Signal power (numerator)\n",
    "    #dnumr = sigma_sqr_noise_lf[:, tf.newaxis] + ph - numr  # Denominator of SINR\n",
    "    #SINR_i = tf.divide(numr, dnumr)  # SINR values\n",
    "    R_P = tf.reduce_sum(tf.math.log(1 + SINR_i) / tf.math.log(2.0), axis=1)  # Sum rate\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # p1 = tf.reshape(p, (-1, K, 1))\n",
    "\n",
    "    w = PMax - p\n",
    "    \n",
    "    A_p = tf.matmul(A, p)\n",
    "\n",
    "    #B = tf.reshape(b, (-1, K, 1))\n",
    "   \n",
    "    s = B - A_p\n",
    "\n",
    "\n",
    "    # Apply ReLU to the constraint violation\n",
    "    constraint_violation = tf.nn.relu(tf.concat([p, w, s],axis=1))\n",
    "    \n",
    "    # L2 norm of the constraint violation\n",
    "    penalty_term = tf.reduce_sum(tf.square(constraint_violation), axis=1)  # ||ReLU(gx(y))||^2\n",
    "\n",
    "\n",
    "    # Final loss calculation\n",
    "\n",
    "    # lambda_l = 5.0\n",
    "    lambda_l = 10.0\n",
    "    # lambda_l = 15.0\n",
    "    # lambda_l = 20.0\n",
    "    # lambda_l = 25.0\n",
    "\n",
    "    loss = -R_P + lambda_l * penalty_term\n",
    "    return tf.reduce_mean(loss)  # Batch mean loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss_DC3(y_true, y_pred):\n",
    "#     # Multiply predicted values by PMax\n",
    "#     p = tf.multiply(PMax, y_pred)  # p: [batch_size, K, 1]\n",
    "#     p = tf.reshape(p, (-1, K, 1))  # Ensure p has shape [batch_size, K, 1]\n",
    "\n",
    "#     eta = 1e-3\n",
    "\n",
    "#     # Extract EsN0 value and reshape y_true to exclude EsN0 column\n",
    "#     mtrx_elmnt = K * K\n",
    "#     EsN0_val = y_true[:, 0, mtrx_elmnt]\n",
    "#     y_true_updt = y_true[:, :, :-1]\n",
    "\n",
    "#     # Determine noise variance based on EsN0 value\n",
    "#     sigma_sqr_noise_lf = tf.where(\n",
    "#         EsN0_val < 10, 1e-0,\n",
    "#         tf.where(EsN0_val < 20, 1e-1,\n",
    "#                  tf.where(EsN0_val < 30, 1e-2,\n",
    "#                           tf.where(EsN0_val < 40, 1e-3, 1e-4))))\n",
    "#     sigma_sqr_noise_lf = tf.reshape(sigma_sqr_noise_lf, (-1, 1, 1))  # Shape: [batch_size, 1, 1]\n",
    "\n",
    "#     # Reshape y_true to form hij matrix and calculate squared magnitudes\n",
    "#     hij = tf.reshape(y_true_updt[:, 0:K*K], (-1, K, K))  # Shape: [batch_size, K, K]\n",
    "#     hij_abs_sqr = tf.square(tf.abs(hij))  # Shape: [batch_size, K, K]\n",
    "\n",
    "#     # Generate matrices A and b (assuming these functions are defined)\n",
    "#     A = generate_A(hij.shape[0], K, SINR_P_min, hij)\n",
    "#     b = generate_b(hij.shape[0], K, SINR_P_min, sigma_sqr_noise_0dB, hij)\n",
    "\n",
    "#     # Define A_tilda, b_tilda, A_transpose_tilda\n",
    "#     A_tilda = generate_A_tilda(A, K)\n",
    "#     B_tilda = generate_B_tilda(b, K)\n",
    "#     A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "#     # Gradient Descent for Correction\n",
    "#     for i in range(5):\n",
    "#         V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "#         V_relu = tf.nn.relu(V)\n",
    "#         gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)\n",
    "#         p = p + eta * gd\n",
    "\n",
    "#     # Ensure p remains of shape [batch_size, K, 1]\n",
    "\n",
    "#     # Compute ph (Interference + noise)\n",
    "#     p_expanded = tf.expand_dims(p, axis=1)  # Shape: [batch_size, 1, K, 1]\n",
    "#     hij_abs_sqr_expanded = tf.expand_dims(hij_abs_sqr, axis=-1)  # Shape: [batch_size, K, K, 1]\n",
    "\n",
    "#     # Multiply p and hij_abs_sqr\n",
    "#     ph_intermediate = tf.multiply(p_expanded, hij_abs_sqr_expanded)  # Shape: [batch_size, K, K, 1]\n",
    "#     ph = tf.reduce_sum(ph_intermediate, axis=2)  # Sum over interfering users; shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute numr (Signal power numerator)\n",
    "#     diag_hij_abs_sqr = tf.linalg.diag_part(hij_abs_sqr)  # Shape: [batch_size, K]\n",
    "#     diag_hij_abs_sqr = tf.expand_dims(diag_hij_abs_sqr, axis=-1)  # Shape: [batch_size, K, 1]\n",
    "#     numr = tf.multiply(p, diag_hij_abs_sqr)  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute dnumr (Denominator of SINR)\n",
    "#     dnumr = sigma_sqr_noise_lf + ph - numr  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute SINR\n",
    "#     SINR_i = tf.divide(numr, dnumr)  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute sum rate R_P\n",
    "#     R_P = tf.reduce_sum(tf.math.log(1 + SINR_i) / tf.math.log(2.0), axis=1)  # Shape: [batch_size, 1]\n",
    "\n",
    "#     # Constraint terms\n",
    "#     w = PMax - p  # Shape: [batch_size, K, 1]\n",
    "#     A_p = tf.linalg.matmul(A, p)  # Ensure A is of shape [batch_size, K, K], p: [batch_size, K, 1]; result: [batch_size, K, 1]\n",
    "#     s = b - A_p  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Apply ReLU to the constraint violation\n",
    "#     constraint_violation = tf.nn.relu(tf.concat([p, w, s], axis=1))  # Shape: [batch_size, 3*K, 1]\n",
    "\n",
    "#     # L2 norm of the constraint violation\n",
    "#     penalty_term = tf.reduce_sum(tf.square(constraint_violation), axis=[1, 2])  # Shape: [batch_size]\n",
    "\n",
    "#     # Final loss calculation\n",
    "#     lambda_l = 10.0\n",
    "#     loss = -R_P[:, 0] + lambda_l * penalty_term  # Shape: [batch_size]\n",
    "#     return tf.reduce_mean(loss)  # Batch mean loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 100s 91ms/step - loss: 24.2774 - val_loss: 24.2262\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2217 - val_loss: 24.2148\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2161 - val_loss: 24.2115\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2139 - val_loss: 24.2104\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2129 - val_loss: 24.2096\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2123 - val_loss: 24.2092\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2115 - val_loss: 24.2084\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 24.2107 - val_loss: 24.2080\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2094 - val_loss: 24.2075\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2078 - val_loss: 24.2053\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 24.2064 - val_loss: 24.2036\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 24.2049 - val_loss: 24.2020\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2041 - val_loss: 24.2010\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2035 - val_loss: 24.2005\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2030 - val_loss: 24.2001\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2022 - val_loss: 24.1990\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: 24.2014 - val_loss: 24.1983\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2009 - val_loss: 24.1979\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 24.2005 - val_loss: 24.1975\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 24.2001 - val_loss: 24.1971\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGwCAYAAABSN5pGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgcElEQVR4nO3de1hUZeIH8O9wvw8XRUBAEC94QU1FV0jFMm95wdWltDI3y3Z/6KZuLbrlWtuzYalppWvubmFtmd1EWVQM5eIVA/FGGiEiCII3EEQuDsP5/THNkYHhNszd7+d5zjMz57zzzns4Dnx9z3veIxEEQQARERERiSwM3QAiIiIiY8OARERERNQMAxIRERFRMwxIRERERM0wIBERERE1w4BERERE1AwDEhEREVEzVoZugKlqbGzEtWvX4OzsDIlEYujmEBERUQcIgoC7d+/Cx8cHFhat9xMxIGno2rVr8PPzM3QziIiISANXr16Fr69vq9sZkDTk7OwMQPEDdnFxMXBriIiIqCOqqqrg5+cn/h1vjUEDUmxsLHbt2oWff/4Z9vb2CAsLw7vvvov+/fu3KCsIAqZNm4akpCTEx8cjMjJSbZ0ymQxvvPEG9u3bh8uXL0MqlWLixIlYu3YtfHx8xHK//PILXnvtNRw7dgz379/HkCFD8Pbbb2PChAkdarvytJqLiwsDEhERkYlpb3iMQQdpp6enIzo6GhkZGUhOToZMJsOkSZNw7969FmU3bdrUobE+NTU1yM7OxurVq5GdnY1du3YhNzcXM2fOVCk3ffp0NDQ0ICUlBadOncLQoUMxffp0lJWVaW3/iIiIyDRJjOlmtTdv3oSnpyfS09Mxbtw4cf2ZM2cwffp0ZGVlwdvbu80eJHUyMzMxatQoFBYWwt/fH7du3UL37t1x+PBhjB07FgBw9+5duLi4IDk5GRMnTmy3zqqqKkilUlRWVrIHiYiIyER09O+3UV3mX1lZCQBwd3cX19XU1GD+/PnYsmULvLy8NK5XIpHA1dUVAODh4YH+/fvj888/x71799DQ0IBt27bB09MTI0aMUFtHfX09qqqqVBYiIiIyT0YzSLuxsRHLli1DeHg4Bg8eLK5fvnw5wsLCMGvWLI3qraurQ0xMDObNmycmRYlEgoMHDyIyMhLOzs6wsLCAp6cnkpKS4Obmprae2NhYvPXWWxq1gYiIjJtcLodMJjN0M0gLrK2tYWlp2eV6jCYgRUdHIycnB0ePHhXXJSQkICUlBadPn9aoTplMhqioKAiCgK1bt4rrBUFAdHQ0PD09ceTIEdjb2+M///kPZsyYgczMTHh7e7eoa9WqVVixYoX4WjkKnoiITJcgCCgrK8OdO3cM3RTSIldXV3h5eXVpnkKjCEhLlixBYmIiDh8+rDInQUpKCvLz88VTY0pz5szB2LFjkZaW1mqdynBUWFiIlJQUlfOMKSkpSExMREVFhbj+n//8J5KTk/HZZ59h5cqVLeqztbWFra1t13aUiIiMijIceXp6wsHBgRP/mjhBEFBTU4MbN24AgNoOj44yaEASBAFLly5FfHw80tLSEBgYqLJ95cqVePHFF1XWhYSEYOPGjZgxY0ar9SrDUV5eHlJTU+Hh4aGyvaamBgBazKBpYWGBxsbGruwSERGZCLlcLoaj5n8nyHTZ29sDAG7cuAFPT0+NT7cZNCBFR0djx44d2LNnD5ydncVL7KVSKezt7eHl5aV2YLa/v79KmAoODkZsbCxmz54NmUyGuXPnIjs7G4mJiZDL5WK97u7usLGxwZgxY+Dm5obnn38ef/vb32Bvb49///vfKCgowJNPPqmfnSciIoNSjjlycHAwcEtI25THVCaTaRyQDHoV29atW1FZWYmIiAh4e3uLy9dff92penJzc8Ur4EpKSpCQkIDi4mIMGzZMpd7jx48DALp164akpCRUV1fjsccew8iRI3H06FHs2bMHQ4cO1fp+EhGR8eJpNfOjjWNq8FNs2nhP03UBAQEdqnfkyJE4cOBApz+fiIiIzJ9RzYNEREREZAwYkIiIiB5yAQEB2LRpU4fLp6WlQSKRmPX0CAxIRubePSAvD/h1SBUREZFIIpG0ubz55psa1ZuZmYnFixd3uHxYWBhKS0shlUo1+jxTYBTzINEDkyYBx48D330HzJlj6NYQEZExKS0tFZ9//fXX+Nvf/obc3FxxnZOTk/hcEATI5XJYWbX/p7579+6daoeNjY3Gt/8yFexBMjI+PorHa9cM2w4iooeRICh68vW9dPSaJeX0N15eXpBKpZBIJOLrn3/+Gc7Ozti/fz9GjBgBW1tbHD16FPn5+Zg1axZ69OgBJycnhIaG4uDBgyr1Nj/FJpFI8J///AezZ8+Gg4MD+vbti4SEBHF781Ns27dvh6urKw4cOIABAwbAyckJU6ZMUQl0DQ0N+NOf/gRXV1d4eHggJiYGzz//fKduPq9PDEhGhgGJiMhwamoAJyf9L7/OX6wVK1euxNq1a3Hx4kUMGTIE1dXVmDZtGg4dOoTTp09jypQpmDFjBoqKitqs56233kJUVBTOnTuHadOm4ZlnnkF5eXkbP7sarF+/Hv/9739x+PBhFBUV4dVXXxW3v/vuu/jyyy8RFxeHY8eOoaqqCrt379bWbmsdA5KRYUAiIqKu+Pvf/44nnngCQUFBcHd3x9ChQ/Hyyy9j8ODB6Nu3L95++20EBQWp9Aips3DhQsybNw99+vTBO++8g+rqavz444+tlpfJZPj4448xcuRIDB8+HEuWLMGhQ4fE7R999BFWrVqF2bNnIzg4GJs3b25xKzFjwjFIRoYBiYjIcBwcgOpqw3yutowcOVLldXV1Nd58803s3bsXpaWlaGhoQG1tbbs9SEOGDBGfOzo6wsXFRbzHmToODg4ICgoSX3t7e4vlKysrcf36dYwaNUrcbmlpiREjRhjtLb4YkIwMAxIRkeFIJICjo6Fb0TWOzXbg1VdfRXJyMtavX48+ffrA3t4ec+fOxf3799usx9raWuW1RCJpM8yoK6/JhNDGgqfYjIwyIJWUGLYdRERkHo4dO4aFCxdi9uzZCAkJgZeXF65cuaLXNkilUvTo0QOZmZniOrlcjuzsbL22ozPYg2RklAGpslJxZYOp/0+GiIgMq2/fvti1axdmzJgBiUSC1atXG+S01tKlSxEbG4s+ffogODgYH330ESoqKoz2XnjsQTIyLi4PzkU3uTqSiIhII++//z7c3NwQFhaGGTNmYPLkyRg+fLje2xETE4N58+ZhwYIFGDNmDJycnDB58mTY2dnpvS0dIRFM+QShAVVVVUEqlaKyshIuLi5arbtvX+DSJSA9HRg3TqtVExHRr+rq6lBQUIDAwECj/SNtzhobGzFgwABERUXh7bff1mrdbR3bjv795ik2I+TjowhIHKhNRETmorCwED/88APGjx+P+vp6bN68GQUFBZg/f76hm6YWT7EZIV7JRkRE5sbCwgLbt29HaGgowsPDcf78eRw8eBADBgwwdNPUYg+SEWJAIiIic+Pn54djx44Zuhkdxh4kI8SAREREZFgMSEaIAYmIiMiwGJCMEAMSERGRYTEgGaGmAYmTMBAREekfA5IRUgake/eAu3cN2xYiIqKHEQOSEXJ0BKRSxXOeZiMiIm2LiIjAsmXLxNcBAQHYtGlTm++RSCTYvXt3lz9bW/XoGgOSkeI4JCIiUmfGjBmYMmWK2m1HjhyBRCLBuXPnOlVnZmYmFi9erI3mid58800MGzasxfrS0lJMnTpVq5+lCwxIRooBiYiI1Fm0aBGSk5NRXFzcYltcXBxGjhyJIUOGdKrO7t27w0F5I1Ad8/Lygq2trV4+qysYkIwUAxIREakzffp0dO/eHdu3b1dZX11djW+//RaRkZGYN28eevbsCQcHB4SEhOCrr75qs87mp9jy8vIwbtw42NnZYeDAgUhOTm7xnpiYGPTr1w8ODg7o3bs3Vq9eDZlMBgDYvn073nrrLZw9exYSiQQSiURsb/NTbOfPn8djjz0Ge3t7eHh4YPHixaiurha3L1y4EJGRkVi/fj28vb3h4eGB6Oho8bN0hTNpGykGJCIi/RMEATU1NXr/XAcHB0gkkg6VtbKywoIFC7B9+3a8/vrr4vu+/fZbyOVyPPvss/j2228RExMDFxcX7N27F8899xyCgoIwatSodutvbGzEb3/7W/To0QMnT55EZWWlynglJWdnZ2zfvh0+Pj44f/48XnrpJTg7O+Mvf/kLnnrqKeTk5CApKQkHDx4EAEiVg2ubuHfvHiZPnowxY8YgMzMTN27cwIsvvoglS5aoBMDU1FR4e3sjNTUVly5dwlNPPYVhw4bhpZde6tDPTBMMSEaKAYmISP9qamrg5OSk98+trq6Go6Njh8u/8MILWLduHdLT0xEREQFAcXptzpw56NWrF1599VWx7NKlS3HgwAF88803HQpIBw8exM8//4wDBw7A59c/Ru+8806LcUNvvPGG+DwgIACvvvoqdu7cib/85S+wt7eHk5MTrKys4OXl1epn7dixA3V1dfj888/F/d+8eTNmzJiBd999Fz169AAAuLm5YfPmzbC0tERwcDCefPJJHDp0SKcBiafYjBQDEhERtSY4OBhhYWH49NNPAQCXLl3CkSNHsGjRIsjlcrz99tsICQmBu7s7nJyccODAARQVFXWo7osXL8LPz08MRwAwZsyYFuW+/vprhIeHw8vLC05OTnjjjTc6/BlNP2vo0KEq4TA8PByNjY3Izc0V1w0aNAiWlpbia29vb9y4caNTn9VZ7EEyUgxIRET65+DgoDL+RZ+f21mLFi3C0qVLsWXLFsTFxSEoKAjjx4/Hu+++iw8++ACbNm1CSEgIHB0dsWzZMty/f19r7T1x4gSeeeYZvPXWW5g8eTKkUil27tyJDRs2aO0zmrK2tlZ5LZFI0NjYqJPPUmJAMlLNZ9Pu4KlpIiLqAolE0qlTXYYUFRWFV155BTt27MDnn3+OP/7xj5BIJDh27BhmzZqFZ599FoBiTNEvv/yCgQMHdqjeAQMG4OrVqygtLYW3tzcAICMjQ6XM8ePH0atXL7z++uviusLCQpUyNjY2kMvl7X7W9u3bce/ePfHnfuzYMVhYWKB///4daq+u8BSbkfr13yTq64HycsO2hYiIjI+TkxOeeuoprFq1CqWlpVi4cCEAoG/fvkhOTsbx48dx8eJFvPzyy7h+/XqH6504cSL69euH559/HmfPnsWRI0dUgpDyM4qKirBz507k5+fjww8/RHx8vEqZgIAAFBQU4MyZM7h16xbq6+tbfNYzzzwDOzs7PP/888jJyUFqaiqWLl2K5557Thx/ZCgGDUixsbEIDQ2Fs7MzPD09ERkZqXLOsSlBEDB16tR2Z+CUyWSIiYkRuxV9fHywYMECXGtyriotLU287LD5kpmZqe3d1IitLeDhoXjO02xERKTOokWLUFFRgcmTJ4tjht544w0MHz4ckydPRkREBLy8vBAZGdnhOi0sLBAfH4/a2lqMGjUKL774Iv7xj3+olJk5cyaWL1+OJUuWYNiwYTh+/DhWr16tUmbOnDmYMmUKJkyYgO7du6udasDBwQEHDhxAeXk5QkNDMXfuXDz++OPYvHlz538YWiYRBMPdDnXKlCl4+umnERoaioaGBvz1r39FTk4OLly40KKLc+PGjUhOTsb+/fsRHx/f6sGurKzE3Llz8dJLL2Ho0KGoqKjAK6+8ArlcjqysLADA/fv3Ud6sW2b16tU4dOgQ8vPzO3SpZVVVFaRSKSorK+Hi4qLZD6AdQ4YA588DSUnA5Mk6+QgioodWXV0dCgoKEBgYCDs7O0M3h7SorWPb0b/fBh2DlJSUpPJ6+/bt8PT0xKlTpzBu3Dhx/ZkzZ7BhwwZkZWWJ50NbI5VKW0xotXnzZowaNQpFRUXw9/eHjY2NymWHMpkMe/bswdKlSzs8D4U++PgoAhJ7kIiIiPTLqAZpV1ZWAgDc3d3FdTU1NZg/fz62bNnS5lwK7dUrkUjg6uqqdntCQgJu376N3//+963WUV9fr3L+tKqqSqO2dAavZCMiIjIMoxmk3djYiGXLliE8PByDBw8W1y9fvhxhYWGYNWuWRvXW1dUhJiYG8+bNa7Ur7ZNPPsHkyZPh6+vbaj2xsbGQSqXi4ufnp1F7OoMBiYiIyDCMpgcpOjoaOTk5OHr0qLguISEBKSkpOH36tEZ1ymQyREVFQRAEbN26VW2Z4uJicYbRtqxatQorVqwQX1dVVek8JDEgERERGYZRBKQlS5YgMTERhw8fVunFSUlJQX5+fotTY3PmzMHYsWORlpbWap3KcFRYWIiUlJRWe4/i4uLg4eGBmTNnttlGW1tbvd99mAGJiEj3DHitEumINo6pQQOSIAhYunQp4uPjkZaWhsDAQJXtK1euxIsvvqiyLiQkBBs3bsSMGTNarVcZjvLy8pCamgoP5fXyaj4/Li4OCxYsaDFLpzFgQCIi0h3l7/2amhrY29sbuDWkTcobDnflb7tBA1J0dDR27NiBPXv2wNnZGWVlZQAUV6LZ29vDy8tL7cBsf39/lTAVHByM2NhYzJ49GzKZDHPnzkV2djYSExMhl8vFet3d3WFjYyO+LyUlBQUFBS1CmLFQBqTSUqCxEbAwmhFjRESmz9LSEq6uruI9vRwcHIzqSmbqPEEQUFNTgxs3bsDV1VXl/m2dZdCApBwXpLwTsVJcXJw4I2hH5ObmilfAlZSUICEhAQAwbNgwlXKpqakqn/XJJ58gLCwMwcHBnW67Pnh5KW4xIpcDN28CBp5UlIjI7Cj/E67rG5+Sfrm6ump85buSQSeKNGX6mCgSUNxypKwMyM4GHnlEZx9DRPRQk8vlkMlkhm4GaYG1tXWbPUcmMVEktc/HRxGQrl1jQCIi0hVLS8sunY4h88NRLUaOA7WJiIj0jwHJyDEgERER6R8DkpFjQCIiItI/BiQjx4BERESkfwxIRo4BiYiISP8YkIwcAxIREZH+MSAZOWVAun4daGgwbFuIiIgeFgxIRq57d8DSEhAERUgiIiIi3WNAMnIWForZtAGgpMSwbSEiInpYMCCZAI5DIiIi0i8GJBPAgERERKRfDEgmgAGJiIhIvxiQTAADEhERkX4xIJkABiQiIiL9YkAyAQxIRERE+sWAZAIYkIiIiPSLAckEKAPS7dtAfb1h20JERPQwYEAyAe7ugK2t4nlpqWHbQkRE9DBgQDIBEglPsxEREekTA5KJYEAiIiLSHwYkE8GAREREpD8MSCaCAYmIiEh/GJBMBAMSERGR/jAgmQgGJCIiIv1hQDIRDEhERET6w4BkIhiQiIiI9IcByUQoA1JlJXDvnmHbQkREZO4YkEyEszPg6Kh4ztm0iYiIdIsByURwNm0iIiL9YUAyIQxIRERE+mHQgBQbG4vQ0FA4OzvD09MTkZGRyM3NVVtWEARMnToVEokEu3fvbrVOmUyGmJgYhISEwNHRET4+PliwYAGuqUkVe/fuxejRo2Fvbw83NzdERkZqac90QxmQSkoM2w4iIiJzZ9CAlJ6ejujoaGRkZCA5ORkymQyTJk3CPTWjkDdt2gSJRNJunTU1NcjOzsbq1auRnZ2NXbt2ITc3FzNnzlQp9/333+O5557D73//e5w9exbHjh3D/PnztbZvusAeJCIiIv2wMuSHJyUlqbzevn07PD09cerUKYwbN05cf+bMGWzYsAFZWVnw9vZus06pVIrk5GSVdZs3b8aoUaNQVFQEf39/NDQ04JVXXsG6deuwaNEisdzAgQO1sFe6w4BERESkH0Y1BqmyshIA4O7uLq6rqanB/PnzsWXLFnh5eWlcr0QigaurKwAgOzsbJSUlsLCwwCOPPAJvb29MnToVOTk5rdZRX1+PqqoqlUXfGJCIiIj0w2gCUmNjI5YtW4bw8HAMHjxYXL98+XKEhYVh1qxZGtVbV1eHmJgYzJs3Dy4uLgCAy5cvAwDefPNNvPHGG0hMTISbmxsiIiJQXl6utp7Y2FhIpVJx8fPz06g9XcGAREREpB9GE5Cio6ORk5ODnTt3iusSEhKQkpKCTZs2aVSnTCZDVFQUBEHA1q1bxfWNjY0AgNdffx1z5szBiBEjEBcXB4lEgm+//VZtXatWrUJlZaW4XL16VaM2dUXTgCQIev94IiKih4ZRBKQlS5YgMTERqamp8PX1FdenpKQgPz8frq6usLKygpWVYsjUnDlzEBER0WadynBUWFiI5ORksfcIgDiOqemYI1tbW/Tu3RtFRUVq67O1tYWLi4vKom/K4Vc1NYABzvARERE9NAwakARBwJIlSxAfH4+UlBQEBgaqbF+5ciXOnTuHM2fOiAsAbNy4EXFxca3WqwxHeXl5OHjwIDw8PFS2jxgxAra2tipTCshkMly5cgW9evXS3g5qmaMjIJUqnvM0GxERke4Y9Cq26Oho7NixA3v27IGzszPKysoAKK5Es7e3h5eXl9qB2f7+/iphKjg4GLGxsZg9ezZkMhnmzp2L7OxsJCYmQi6Xi/W6u7vDxsYGLi4u+MMf/oA1a9bAz88PvXr1wrp16wAAv/vd7/Sw55rz8VHcj+3aNWDAAEO3hoiIyDwZNCApxwU1P10WFxeHhQsXdrie3Nxc8Qq4kpISJCQkAACGDRumUi41NVX8rHXr1sHKygrPPfccamtrMXr0aKSkpMDNzU2jfdGXnj2BixfZg0RERKRLBg1IggYjjdW9p+m6gICADtVrbW2N9evXY/369Z1ugyHxSjYiIiLdM4pB2tRxDEhERES6x4BkYhiQiIiIdI8BycQwIBEREekeA5KJYUAiIiLSPQYkE8PZtImIiHSPAcnEKKeFun8faOW2cURERNRFDEgmxtYW6NZN8Zyn2YiIiHSDAckEcRwSERGRbjEgmSAGJCIiIt1iQDJBDEhERES6xYBkgpQBqaTEsO0gIiIyVwxIJog9SERERLrFgGSCGJCIiIh0iwHJBDEgERER6RYDkglSBqSyMkAuN2xbiIiIzBEDkgnq0QOQSBTh6OZNQ7eGiIjI/DAgmSArK0VIAniajYiISBcYkEwUxyERERHpDgOSierZU/HIgERERKR9DEgmij1IREREusOAZKIYkIiIiHSHAclEMSARERHpDgOSiWJAIiIi0h0GJBPFgERERKQ7DEgmShmQbtwAZDLDtoWIiMjcMCCZqG7dFBNGCgJw/bqhW0NERGReGJBMlIUF4O2teM7TbERERNrFgGTCOA6JiIhINxiQTBgDEhERkW4wIJkwBiQiIiLdYEAyYQxIREREumHQgBQbG4vQ0FA4OzvD09MTkZGRyM3NVVtWEARMnToVEokEu3fvbrVOmUyGmJgYhISEwNHRET4+PliwYAGuNUsRAQEBkEgkKsvatWu1uXs6pwxIJSWGbQcREZG5MWhASk9PR3R0NDIyMpCcnAyZTIZJkybh3r17Lcpu2rQJEomk3TpramqQnZ2N1atXIzs7G7t27UJubi5mzpzZouzf//53lJaWisvSpUu1sl/6wh4kIiIi3bAy5IcnJSWpvN6+fTs8PT1x6tQpjBs3Tlx/5swZbNiwAVlZWfBWXtveCqlUiuTkZJV1mzdvxqhRo1BUVAR/f39xvbOzM7y8vLSwJ4bBgERERKQbRjUGqbKyEgDg7u4urqupqcH8+fOxZcsWjcNMZWUlJBIJXF1dVdavXbsWHh4eeOSRR7Bu3To0NDS0Wkd9fT2qqqpUFkNTBqTycqCuzrBtISIiMicG7UFqqrGxEcuWLUN4eDgGDx4srl++fDnCwsIwa9Ysjeqtq6tDTEwM5s2bBxcXF3H9n/70JwwfPhzu7u44fvw4Vq1ahdLSUrz//vtq64mNjcVbb72lURt0xc0NsLUF6uuB0lIgMNDQLSIiIjIPRhOQoqOjkZOTg6NHj4rrEhISkJKSgtOnT2tUp0wmQ1RUFARBwNatW1W2rVixQnw+ZMgQ2NjY4OWXX0ZsbCxsbW1b1LVq1SqV91RVVcHPz0+jdmmLRKLoRSooUJxmY0AiIiLSDqM4xbZkyRIkJiYiNTUVvr6+4vqUlBTk5+fD1dUVVlZWsLJS5Lk5c+YgIiKizTqV4aiwsBDJyckqvUfqjB49Gg0NDbhy5Yra7ba2tnBxcVFZjAHHIREREWmfQXuQBEHA0qVLER8fj7S0NAQ26wJZuXIlXnzxRZV1ISEh2LhxI2bMmNFqvcpwlJeXh9TUVHh4eLTbljNnzsDCwgKenp6a7YyBMCARERFpn0EDUnR0NHbs2IE9e/bA2dkZZWVlABRXotnb28PLy0vtwGx/f3+VMBUcHIzY2FjMnj0bMpkMc+fORXZ2NhITEyGXy8V63d3dYWNjgxMnTuDkyZOYMGECnJ2dceLECSxfvhzPPvss3Nzc9LPzWtKzp+KRAYmIiEh7DBqQlOOCmp8ui4uLw8KFCztcT25urngFXElJCRISEgAAw4YNUymXmpqKiIgI2NraYufOnXjzzTdRX1+PwMBALF++XGWMkalgDxIREZH2GfwUmzbe03RdQEBAu/UOHz4cGRkZnf5sY8SAREREpH1GMUibNMeAREREpH0MSCaOAYmIiEj7GJBMnDIgVVUB1dWGbQsREZG5YEAycc7OgJOT4nlpqWHbQkREZC4YkMwAT7MRERFpFwOSGWBAIiIi0i4GJDPAgERERKRdDEhmgAGJiIhIuxiQzAADEhERkXYxIJkBBiQiIiLtYkAyA8qAVFJi2HYQERGZCwYkM9C0B0mD29sRERFRMwxIZsDbW/FYWwtUVhq2LUREROaAAckMODgArq6K5xyHRERE1HUMSGaCA7WJiIi0hwHJTDAgERERaQ8DkplgQCIiItIeBiQz0bOn4pEBiYiIqOsYkMwEe5CIiIi0hwHJTDAgERERaQ8DkplgQCIiItIeBiQzwdm0iYiItIcByUx4eSkeZTLg9m3DtoWIiMjUMSCZCRsboHt3xXOeZiMiIuoaBiQzwnFIRERE2sGAZEYYkIiIiLSDAcmMMCARERFpBwOSGWFAIiIi0g4GJDPCgERERKQdDEhmhAGJiIhIOxiQzAgDEhERkXYYNCDFxsYiNDQUzs7O8PT0RGRkJHJzc9WWFQQBU6dOhUQiwe7du1utUyaTISYmBiEhIXB0dISPjw8WLFiAa62khvr6egwbNgwSiQRnzpzRwl4ZjjIglZUBcrlh20JERGTKDBqQ0tPTER0djYyMDCQnJ0Mmk2HSpEm4d+9ei7KbNm2CRCJpt86amhpkZ2dj9erVyM7Oxq5du5Cbm4uZM2eqLf+Xv/wFPspkYeI8PQELC0U4unHD0K0hIiIyXVaG/PCkpCSV19u3b4enpydOnTqFcePGievPnDmDDRs2ICsrC97e3m3WKZVKkZycrLJu8+bNGDVqFIqKiuDv7y+u379/P3744Qd8//332L9/f5v11tfXo76+XnxdVVXV7v7pm5UV0KMHUFqqOM3Wzo+KiIiIWmFUY5AqKysBAO7u7uK6mpoazJ8/H1u2bIGX8oZjGtQrkUjg6uoqrrt+/Tpeeukl/Pe//4WDg0O7dcTGxkIqlYqLn5+fRm3RNY5DIiIi6jqjCUiNjY1YtmwZwsPDMXjwYHH98uXLERYWhlmzZmlUb11dHWJiYjBv3jy4uLgAUIxnWrhwIf7whz9g5MiRHapn1apVqKysFJerV69q1B5dY0AiIiLqOoOeYmsqOjoaOTk5OHr0qLguISEBKSkpOH36tEZ1ymQyREVFQRAEbN26VVz/0Ucf4e7du1i1alWH67K1tYWtra1G7dAnBiQiIqKu06gH6bPPPsPevXvF13/5y1/g6uqKsLAwFBYWdrq+JUuWIDExEampqfD19RXXp6SkID8/H66urrCysoKVlSLPzZkzBxEREW3WqQxHhYWFSE5OFnuPlPWeOHECtra2sLKyQp8+fQAAI0eOxPPPP9/p9hsTBiQiIqKukwiCIHT2Tf3798fWrVvx2GOP4cSJE5g4cSI2btyIxMREWFlZYdeuXR2qRxAELF26FPHx8UhLS0Pfvn1VtpeVleHWrVsq60JCQvDBBx9gxowZCAwMVFuvMhzl5eUhNTUV3bt3V9leVFSkMsj62rVrmDx5Mr777juMHj1aJaS1pqqqClKpFJWVlSrhy9A++QR48UVg2jSgSYYlIiIidPzvt0an2K5evSr2uuzevRtz5szB4sWLER4e3m7PTlPR0dHYsWMH9uzZA2dnZ5SVlQFQXIlmb28PLy8vtQOz/f39VcJRcHAwYmNjMXv2bMhkMsydOxfZ2dlITEyEXC4X63V3d4eNjY3KlWwA4OTkBAAICgrqUDgyZuxBIiIi6jqNTrE5OTnh9u3bAIAffvgBTzzxBADAzs4OtbW1Ha5n69atqKysREREBLy9vcXl66+/7lR7cnNzxSvgSkpKkJCQgOLiYgwbNkyl3uPHj3eqXlPEgERERNR1GvUgPfHEE3jxxRfxyCOP4JdffsG0adMAAD/99BMCAgI6XI8GZ/fUvqfpuoCAgE7Xq8l7jJUyIN24AchkgLW1YdtDRERkijTqQdqyZQvGjBmDmzdv4vvvv4eHhwcA4NSpU5g3b55WG0id4+HxIBT9emaRiIiIOkmjQdpkvIO0AaBXL6CoCMjIAEaPNnRriIiIjEdH/35r1IOUlJSkMl/Rli1bMGzYMMyfPx8VFRWaVElaxHFIREREXaNRQHrttdfEy+TPnz+PP//5z5g2bRoKCgqwYsUKrTaQOo8BiYiIqGs0GqRdUFCAgQMHAgC+//57TJ8+He+88w6ys7PFAdtkOAxIREREXaNRD5KNjQ1qamoAAAcPHsSkSZMAKOYZMsa73D9sGJCIiIi6RqMepEcffRQrVqxAeHg4fvzxR3Heol9++cXkJ1o0BwxIREREXaNRD9LmzZthZWWF7777Dlu3bkXPnj0BAPv378eUKVO02kDqPAYkIiKiruFl/hoy5sv8f/oJGDwYcHcHfp3wnIiIiKDje7EBgFwux+7du3Hx4kUAwKBBgzBz5kxYWlpqWiVpibIHqbwcqKsD7OwM2x4iIiJTo1FAunTpEqZNm4aSkhL0798fABAbGws/Pz/s3bsXQUFBWm0kdY6rqyIU1dUBpaVAk/v6EhERUQdoNAbpT3/6E4KCgnD16lVkZ2cjOzsbRUVFCAwMxJ/+9Cdtt5E6SSJ50ItUUmLYthAREZkijXqQ0tPTkZGRAXd3d3Gdh4cH1q5di/DwcK01jjTn4wNcvsyB2kRERJrQqAfJ1tYWd+/ebbG+uroaNjY2XW4UdR2vZCMiItKcRgFp+vTpWLx4MU6ePAlBECAIAjIyMvCHP/wBM2fO1HYbSQMMSERERJrTKCB9+OGHCAoKwpgxY2BnZwc7OzuEhYWhT58+2LRpk5abSJpgQCIiItKcRmOQXF1dsWfPHly6dEm8zH/AgAHo06ePVhtHmmNAIiIi0lyHA9KKFSva3J6amio+f//99zVvEWnFr5ObMyARERFpoMMB6fTp0x0qJ5FING4MaQ97kIiIiDTX4YDUtIeIjJ+3t+Lx7l3F4uxs2PYQERGZEo0GaZPxc3Z+EIpKSw3bFiIiIlPDgGTGeJqNiIhIMwxIZowBiYiISDMMSGaMAYmIiEgzDEhmjAGJiIhIMwxIZowBiYiISDMMSGaMAYmIiEgzDEhmjAGJiIhIMwxIZqxpQBIEw7aFiIjIlDAgmTHlbNq1tUBlpWHbQkREZEoYkMyYvT3g5qZ4ztNsREREHWfQgBQbG4vQ0FA4OzvD09MTkZGRyM3NVVtWEARMnToVEokEu3fvbrVOmUyGmJgYhISEwNHRET4+PliwYAGuNUsIM2fOhL+/P+zs7ODt7Y3nnnuuRRlzwHFIREREnWfQgJSeno7o6GhkZGQgOTkZMpkMkyZNwr1791qU3bRpEyQSSbt11tTUIDs7G6tXr0Z2djZ27dqF3NxczJw5U6XchAkT8M033yA3Nxfff/898vPzMXfuXK3tm7FQBqSSEsO2g4iIyJRYGfLDk5KSVF5v374dnp6eOHXqFMaNGyeuP3PmDDZs2ICsrCx4KwfWtEIqlSI5OVll3ebNmzFq1CgUFRXB398fALB8+XJxe69evbBy5UpERkZCJpPB2tq6Rb319fWor68XX1dVVXV8Rw2IPUhERESdZ1RjkCp/HUns7u4urqupqcH8+fOxZcsWeHl5aVyvRCKBq6ur2u3l5eX48ssvERYWpjYcAYrTgVKpVFz8/Pw0aou+MSARERF1ntEEpMbGRixbtgzh4eEYPHiwuH758uUICwvDrFmzNKq3rq4OMTExmDdvHlxcXFS2xcTEwNHRER4eHigqKsKePXtarWfVqlWorKwUl6tXr2rUHn1jQCIiIuo8owlI0dHRyMnJwc6dO8V1CQkJSElJwaZNmzSqUyaTISoqCoIgYOvWrS22v/baazh9+jR++OEHWFpaYsGCBRBamTDI1tYWLi4uKospYEAiIiLqPIOOQVJasmQJEhMTcfjwYfj6+orrU1JSkJ+f3+LU2Jw5czB27FikpaW1WqcyHBUWFiIlJUVtoOnWrRu6deuGfv36YcCAAfDz80NGRgbGjBmjrV0zuJ49FY8MSERERB1n0IAkCAKWLl2K+Ph4pKWlITAwUGX7ypUr8eKLL6qsCwkJwcaNGzFjxoxW61WGo7y8PKSmpsLDw6PdtjQ2NgKAykBsc6DsQSotBRobAQuj6TMkIiIyXgYNSNHR0dixYwf27NkDZ2dnlJWVAVBciWZvbw8vLy+1A7P9/f1VwlRwcDBiY2Mxe/ZsyGQyzJ07F9nZ2UhMTIRcLhfrdXd3h42NDU6ePInMzEw8+uijcHNzQ35+PlavXo2goCCz6j0CAOWPTyYDbt8Gunc3bHuIiIhMgUH7E7Zu3YrKykpERETA29tbXL7++utO1ZObmyteAVdSUoKEhAQUFxdj2LBhKvUeP34cAODg4IBdu3bh8ccfR//+/bFo0SIMGTIE6enpsLW11fp+GpK1NeDpqXjO02xEREQdY/BTbNp4T9N1AQEB7dYbEhKClJSUTn+2qfLxAW7cUASkoUMN3RoiIiLjxxEpDwFeyUZERNQ5DEgPAQYkIiKizmFAeggwIBEREXUOA9JDgAGJiIiocxiQHgIMSERERJ3DgPQQYEAiIiLqHAYkI1RTU6PV+pQBqawMkMu1WjUREZFZYkAyIo2NjYiJiYG3tzfy8vK0Vq+np+IWI42NivmQiIiIqG0MSEbEwsICOTk5qKqqwj/+8Q+t1Wtp+eCWIzzNRkRE1D4GJCOzZs0aAMAXX3yB/Px8rdXLcUhEREQdx4BkZEaNGoUpU6ZALpdrtReJAYmIiKjjGJCMkLIX6fPPP8fly5e1UqcyIJWUaKU6IiIis8aAZIR+85vfYNKkSZDL5XjnnXe0Uid7kIiIiDqOAclIKXuRPvvsM1y5cqXL9TEgERERdRwDkpEKCwvDxIkT0dDQoJVeJAYkIiKijmNAMmLKXqS4uDgUFhZ2qS4GJCIioo5jQDJijz76KB577DE0NDQgNja2S3X17Kl4vHkTuH9fC40jIiIyYwxIRk7Zi/Tpp5+iqKhI43o8PABra8XzsjJttIyIiMh8MSAZuXHjxmHChAmQyWRYu3atxvVIJDzNRkRE1FEMSCZA2Yv0ySefoLi4WON6GJCIiIg6hgHJBIwfPx7jx4/H/fv3u9SLxIBERETUMQxIJkLZi/Tvf/8bJRpOh82ARERE1DEMSCYiIiICY8eOxf379/Huu+9qVAcDEhERUccwIJkIiUQi9iL961//wjUNUg4DEhERUccwIJmQxx57DOHh4aivr8d7773X6fczIBEREXUMA5IJadqLtG3bNpSWlnbq/QxIREREHcOAZGImTpyIMWPGoK6uDuvWrevUe5UBqaICuHVLB40jIiIyEwxIJqZpL9LHH3+M69evd/i9UinQu7fi+ZQpQHm5LlpIRERk+hiQTNCkSZMwevRo1NbWdqoXSSIB4uOBbt2AU6eAiROB27d12FAiIiITxYBkgpr2Iv3zn//EjRs3OvzeIUOA1FTA0xM4fRp47DHFDWyJiIjoAQYkEzVlyhSEhoZ2uhcJAAYPBtLSAC8v4Nw5RUjqRMYiIiIyewYNSLGxsQgNDYWzszM8PT0RGRmJ3NxctWUFQcDUqVMhkUiwe/fuVuuUyWSIiYlBSEgIHB0d4ePjgwULFqjMG3TlyhUsWrQIgYGBsLe3R1BQENasWYP79+9rexd1piu9SAAwYIAiJHl7Azk5wIQJQCeGMxEREZk1gwak9PR0REdHIyMjA8nJyZDJZJg0aRLu3bvXouymTZsgkUjarbOmpgbZ2dlYvXo1srOzsWvXLuTm5mLmzJlimZ9//hmNjY3Ytm0bfvrpJ2zcuBEff/wx/vrXv2p1/3Rt2rRpGDlyJGpqarBhw4ZOv79/fyA9HejZE7hwAYiIADo5cwAREZFZkgiCIBi6EUo3b96Ep6cn0tPTMW7cOHH9mTNnMH36dGRlZcHb2xvx8fGIjIzscL2ZmZkYNWoUCgsL4e/vr7bMunXrsHXrVly+fFnt9vr6etTX14uvq6qq4Ofnh8rKSri4uHS4Ldr2v//9DzNnzoSjoyOuXLmCbt26dbqO/HxFD9LVq0C/fkBKiiI0ERERmZuqqipIpdJ2/34b1RikyspKAIC7u7u4rqamBvPnz8eWLVvg5eWlcb0SiQSurq5tlmn6uc3FxsZCKpWKi5+fn0Zt0bbp06dj+PDhuHfvnka9SAAQFKQ43ebvD/zyi6InqbhYq80kIiIyKUbTg9TY2IiZM2fizp07OHr0qLj+5Zdfhlwux3/+8x8AirE3nelBqqurQ3h4OIKDg/Hll1+qLXPp0iWMGDEC69evx0svvaS2jLH2IAHAnj17EBkZCScnJ1y5cgUeHh4a1XPliqIn6coVxXxJqamK0ERERGQuTK4HKTo6Gjk5Odi5c6e4LiEhASkpKdi0aZNGdcpkMkRFRUEQBGzdulVtmZKSEkyZMgW/+93vWg1HAGBrawsXFxeVxVjMnDkTw4YNQ3V1Nd5//32N6wkIUIxJ6t0buHwZGD9eEZaIiIgeNkYRkJYsWYLExESkpqbC19dXXJ+SkoL8/Hy4urrCysoKVlZWAIA5c+YgIiKizTqV4aiwsBDJyclqA821a9cwYcIEhIWF4V//+pdW90mfJBIJ/va3vwEAPvroI5R3YYpsf3/F6bY+fRThaPx4RVgiIiJ6mBg0IAmCgCVLliA+Ph4pKSkIDAxU2b5y5UqcO3cOZ86cERcA2LhxI+Li4lqtVxmO8vLycPDgQbWnnEpKShAREYERI0YgLi4OFhZGkRU1NmvWLAwZMgR3797Fxo0bu1SXn58iJPXrBxQVKcYk5edrpZlEREQmwaCpIDo6Gl988QV27NgBZ2dnlJWVoaysDLW1tQAALy8vDB48WGUBAH9/f5UwFRwcjPj4eACKcDR37lxkZWXhyy+/hFwuF+tVznOkDEf+/v5Yv349bt68KZYxVRYWFmIv0ocffoiKioou1dezpyIkBQcrrm4bPx7Iy9NCQ4mIiEyAQQPS1q1bUVlZiYiICHh7e4vL119/3al6cnNzxSvgSkpKkJCQgOLiYgwbNkyl3uPHjwMAkpOTcenSJRw6dAi+vr4qZUzZ7NmzMXjwYFRVVWk8bqspb2/FQO2BA4GSEkVIamUeTyIiIrNiNFexmZqOjoLXt2+//RZRUVGQSqW4cuVKm1MbdNSNG8Djjytm3O7RQxGaBgzoeluJiIj0zeSuYiPtmDNnDgYNGoTKykp88MEHWqnT01MRioYMUdyOJCIC+OknrVRNRERklBiQzIyFhQVWr14NQHF7FuWpx67q1k0xw/awYYoepYgIxY1uiYiIzBEDkhmaO3cuBgwYgDt37uDDDz/UWr0eHsChQ8CIEcCtW8BjjwG/XlhIRERkVhiQzJClpaXYi7Rx40ZUVVVprW53d+DgQSA0FLh9WzE2KTtba9UTEREZBQYkMxUVFYXg4GBUVFTgo48+0mrdrq5AcjLwm98A5eWKkJSVpdWPICIiMigGJDNlaWmJN954AwDw/vvv4+7du1qtXyoFDhwAwsKAO3eAiROBkye1+hFEREQGw4Bkxp5++mn069cP5eXl2Lx5s9brd3EBkpKARx8FKiuBSZOAEye0/jFERER6x4Bkxpr2Im3YsAHV1dVa/wxnZ2D/fsUkklVVipCUkAA0Nmr9o4iIiPSGAcnMzZs3D3369MHt27exZcsWnXyGkxOwdy8wYQJQXQ3MmgUEBgJr1gAFBTr5SCIiIp1iQDJzVlZWYi/S+vXrddKLBACOjkBiIrBsmWIQd1ER8Pe/A717K6YD+O9/gZoanXw0ERGR1jEgPQSeeeYZBAUF4datW9i6davOPsfBAdi4ESgtBb76CnjiCUAiUczCvWCB4t5uL78MZGQAvMENEREZM96LTUPGei+21sTFxeGFF15A9+7dUVBQAEdHR718blER8NlnQFyc6um2AQOA3/8eeO45wMtLL00hIiLivdhI1bPPPovAwEDcvHkTH3/8sd4+198fWL0auHRJ0ZP03HOAvT1w8SLwl78Avr7AzJnA7t2ATKa3ZhEREbWJAekhYW1tjddffx0A8M477+C7776DPjsPLSwU92/7/HOgrAz417+AMWMAuRz43/+A2bOBnj2BP/8ZyMnRW7OIiIjU4ik2DZnaKTYAkMlkCA0NxdmzZwEA48aNw8aNGzF8+HCDteniRcXpt88/B65ff7A+NFRxCm7ePMWgbyIiIm3gKTZqwdraGseOHcOaNWtgb2+Pw4cPY+TIkVi0aBFKS0sN0qYBA4D33gOuXlXMnzR7NmBlBWRmAv/3f4qB3c88o7j/G+dWIiIifWEPkoZMsQepqatXr2LlypXYsWMHAMDJyQl//etfsXz5ctjZ2Rm0bTduAF98AXz6KfDTTw/W9+qluBpu/HhgyBCge3fDtZGIiExTR/9+MyBpyNQDktKJEyewfPlynPz1RmoBAQF47733MHfuXEgkEoO2TRAUN8GNiwN27FDczqQpLy9FUGq6DBgA2NgYpr1ERGT8GJB0zFwCEgA0Njbiq6++QkxMDEpKSgAAjz76KDZt2oQRI0YYuHUKtbVAfDywaxdw9iyQn69+LiUrK0VIah6cvL0VczIREdHDjQFJx8wpICndu3cP69evx7vvvova2lpIJBIsXLgQ//jHP+Dt7W3o5qmorlacfjt3ThGYzp1TLM17mZQ8PFqGpkGDFFMOEBHRw4MBScfMMSApFRcXY+XKlfjyyy8BAI6OjuL4JHsjThSCoBjsrQxLyiU3V/0AbwsLoF+/lqHJ15en6YiIzBUDko6Zc0BSysjIwLJly8TxSb169cJ7772H3/3udwYfn9QZtbWK6QSahqazZ4Fbt9SXl0iAHj0APz/F4u//4Lly8fICLC31ux9ERNR1DEg69jAEJAAQBEEcn1RcXAwACA8Px6ZNmzBy5EgDt05zgqCYsFJdb1N9ffvvt7ICfHxaBqemYapbN457IiIyNgxIOvawBCSlmpoacXxSTU0NAIjjk3x8fAzcOu0RBODmTcWputaWkhLFDODtsbNTnK5rGqACAoDevRWLnx97oYiI9I0BSccetoCkVFxcjFWrVuGLL74AoBiftGrVKqxYscKoxydpk1yu6H0qKmo9RJWVtV+PlZVqYAoKevC8d2/gIfpnRUSkNwxIOvawBiSlkydPYtmyZcjIyAAA+Pv747333kNUVJRJjU/Slfv3FT1NysCkDFNXrgCXLwMFBYoybenWTX14CgpSnN5j7xMRUecxIOnYwx6QAMX4pJ07dyImJgZXr14FoBiftGzZMowePRq+vr4MS61obFQEqMuXFUt+/oPnly8rTvO1xcbmQe9T8/DUuzfg6KiX3SAiMjkMSDrGgPRATU0NNmzYgLVr14rjkwCgR48eCA0NRWhoKEaNGoXQ0FB4eHgYsKWmo6pK0cukLkBduQLIZG2/39sb6NNHEZiCgh4879MHcHPTyy4QERklBiQdY0BqqaSkBO+99x6OHDmCc+fOQa5mJHNgYKAYlkJDQzF8+HA4OTkZoLWmSy4Hiotbhqf8fMVSUdH2+93cVANT00cvL155R0TmjQFJxxiQ2lZbW4szZ84gMzMTP/74IzIzM/HLL7+0KGdhYYGBAweq9DSFhITAhjM1aqy8/EFYunRJ9bG0tO33Ojio73UKClJcdWdlpZ99ICLSFZMISLGxsdi1axd+/vln2NvbIywsDO+++y769+/foqwgCJg2bRqSkpIQHx+PyMhItXXKZDK88cYb2LdvHy5fvgypVIqJEydi7dq1Kpej/+Mf/8DevXtx5swZ2NjY4M6dO51qOwNS5925cwdZWVnIzMwUF+XcSk3Z2Nhg2LBhKqfm+vfvDwsLCwO02rzcu6fobWoenC5dUgwkVzfjuJKNDTB8ODBmjGIJCwN69tRf24mItMEkAtKUKVPw9NNPIzQ0FA0NDfjrX/+KnJwcXLhwAY7NRplu3LgRycnJ2L9/f5sBqbKyEnPnzsVLL72EoUOHoqKiAq+88grkcjmysrLEcmvWrIGrqyuKi4vxySefMCAZSGlpqRiWlD1NFWrOETk7O2PEiBEIDQ1FcHAwgoKCEBQUBB8fHwYnLbl/XzG+SV3P0+XL6q+68/N7EJbGjAGGDeNtWojIuJlEQGru5s2b8PT0RHp6OsaNGyeuP3PmDKZPn46srCx4e3u3GZDUyczMxKhRo1BYWAh/f3+Vbdu3b8eyZcsYkIyEIAi4fPmyGJYyMzORnZ2tMvi7KTs7O/Tu3RtBQUHo06ePGJz69OmDXr16wdraWs97YJ7kckVIysgATpxQLOfOtexxsrMDRo580Ms0ZoxiXBMRkbHo6N9voxpRUPnrrdjd3d3FdTU1NZg/fz62bNkCLw1/01ZWVkIikcDV1VXjttXX16O+yT0oqqqqNK6LWieRSMSQM2/ePABAQ0MDLly4IIalS5cuIT8/H1euXEFdXR0uXLiACxcutKjL0tIS/v7+LYJTUFAQevfu3aKXklpnaQn07atYnntOse7uXSAz80FgOnFCMf7p6FHFohQYqHpabsgQjmUiIuNnND1IjY2NmDlzJu7cuYOjTX67vvzyy5DL5fjPf/4DQPEHtDM9SHV1dQgPD0dwcLB4d/qmOtqD9Oabb+Ktt95qsZ49SIYjk8lQVFSE/Px8cVGGp/z8fNTW1rb5fm9v7xbBqVevXvDw8ICbmxvc3NzYA9UJggD88otqYMrJUaxvysEBCA19cFpuzBjFpJhERPpgcqfY/vjHP2L//v04evQofH19AQAJCQn485//jNOnT4uXgncmIMlkMsyZMwfFxcVIS0tT+4PoaEBS14Pk5+fHgGSkBEFAaWmp2uCUn5+P8vLyDtXj6OgohqXOLrwSD6isBH788UFgysgA1H3V+vQBHn0UmDoVmDQJ6EJnLxFRm0wqIC1ZsgR79uzB4cOHERgYKK5ftmwZPvzwQ5VBuHK5HBYWFhg7dizS0tJarVMmkyEqKgqXL19GSkpKqxMUcgzSw6miokJteLp69SoqKipQWVmJrn41HBwcWoQmb29v9O3bF3369EHfvn3Ru3dv2NnZaWmvjF9jI/Dzz6q9TM3PjlpaAuHhwJNPAtOmAYMGcW4mItIekwhIgiBg6dKliI+PR1paGvr27auyvaysDLdu3VJZFxISgg8++AAzZsxQCVNNKcNRXl4eUlNT0b1791bbwIBE6sjlclRVVaGiokJcysvLVV63tnQmXEkkEvj5+amEJuXzhyU8VVQAJ08Chw4B+/a1DEz+/oqgNG0a8NhjvI0KEXWNSQSk//u//8OOHTuwZ88elbmPpFJpq3eGV3eKLTg4GLGxsZg9ezZkMhnmzp2L7OxsJCYmokePHmI5d3d38bRHUVERysvLkZCQgHXr1uHIkSMAgD59+nRoZmcGJGpNW+Hq6tWruHTpEvLy8pCXl4e7d++2Wo9EIhEHmTcPUIGBgWYbngoKgP37gb17gZQUoK7uwTZbWyAiQhGWnnxSMYElEVFnmERAau1GpnFxcVi4cGGr72kekCQSifieK1eutNqzlJqaioiICADAwoUL8dlnn7VZpi0MSNRVgiDg5s2byMvLUwlNyuedCU/KAOXt7Q13d3d4eHhAKpWa/M2Ca2uB1FRFz9LevYp5mprq1+/BqbixYxUBioioLSYRkEwZAxLpkiAIuHHjhhiWmgaovLw8VFdXt1uHpaUl3Nzc4OHhIYamps9bW+fo6GiUwUoQFOOXlGHpyBGgoeHBdicnYOJERViaOhX49VoPIiIVDEg6xoBEhqIMT02D06VLl3Dp0iXcvHkTt2/fbnVizY6wsbFpNUh169ZN7SKVSvU+o3lVFZCcrAhM+/YBZWWq24cOfXAqbvRozr1ERAoMSDrGgETGrK6uDuXl5bh9+7b42PS5unW3b9+GTCbT6PMsLS3bDFBNF2U5Z2dnrfVUNTYCZ84oepb27VMM+m76m83NDXj8ccVpuHHjgJAQxdVyRPTwYUDSMQYkMjeCIODevXutBinlcuvWLZWlrbFSbbG2tlYJTkFBQViwYAEeffTRLgenW7eApCRFWEpKUlwp15SLi2LepbFjFcvIkRy/RPSwYEDSMQYkIoX6+voWwUldkGq6tHUKcODAgVi8eDEWLFgANze3LrevoUHRo5SeDhw+DBw/rrhNSlN2dorTcOPGKQLTmDGKMU1EZH4YkHSMAYlIczU1NSoh6ubNm0hNTcWOHTvE8GRnZ4eoqCgsXrwYYWFhWjsd19AAnD2rGOR95IgiNDWbbg2WlsDw4Q96mB59lLdDITIXDEg6xoBEpH1VVVX48ssvsW3bNpw9e1ZcP3jwYCxevBjPPfdcl246rY4gALm5iqCkDE2FhS3LDRz4oIdp7FjAz0+rzSAiPWFA0jEGJCLdEQQBP/74I7Zt24adO3eKNx62t7fHU089hcWLF+M3v/mNzqYjKCp60Lt05Ahw8WLLMgEBD8LSuHGKOZmMcHYEImqGAUnHGJCI9OPOnTtir9L58+fF9SEhIXj55Zfx7LPPQiqV6rQNN28CR48+CE2nTyuunGvK21txpZxyYQ8TkXFiQNIxBiQi/RIEARkZGdi2bRu+/vpr1P16DxIHBwc8/fTTePnllxEaGqqXSS6rqhQ32lWekjt5EqivVy3Tt68iKE2cCEyYALi767xZRNQBDEg6xoBEZDgVFRX473//i23btuFCk7vbDhs2DIsXL8Yzzzyj1+9lba3i6rhDhxRLVpZqD5NEAjzyyIPepbFjAQcHvTWPiJpgQNIxBiQiwxMEAcePH8e2bdvwzTffoP7XbhxHR0fMmzcPL7/8MkaOHKn3dt25o5hWQBmYmmQ4AIC1NRAW9iAwhYYq1hGR7jEg6RgDEpFxKS8vx+eff45t27bh559/FtcPHz4cixcvxrx58wz2Xb12DUhJeRCYrl5V3e7kBIwf/yAwhYRwwDeRrjAg6RgDEpFxEgQBR48exbZt2/Ddd9+JvUrW1tYYO3Yspk2bhmnTpiE4ONggN+UVBODSpQdhKSUFKC9XLePpCTz22IPAFBio92YSmS0GJB1jQCIyfrdv38Znn32Gf//73yq9SgAQEBAghqUJEybAwUCDgpT3kVMGpiNHgOYTjffqBQwaBPTvr5hOQPno48OeJqLOYkDSMQYkItOSl5eH/fv3Y9++fUhLSxN7lgDA1tYWERERYmDq06ePwdpZX6+4Ku7gQUVgOnkSkMvVl3V0VASlpqFJ+chfS0TqMSDpGAMSkem6d+8eUlNTsW/fPuzduxdFRUUq2/v27SuGpXHjxsHOzs5ALVXcNy4rSzHb9y+/PHgsKGg9OAGAl5f68BQYCNjY6K/9RMaGAUnHGJCIzIMgCLh48SL27duHffv24ciRI2hoaBC3Ozg44PHHH8e0adMwdepU9OrVy4CtfeD+feDyZdXQpHx+/Xrr77O0BHr3Vg1PQUFAz56Ary/g7Ky/fSAyBAYkHWNAIjJPVVVVOHjwoHg67tq1ayrbBw0ahKlTp2LatGkIDw+HjRF2x1RWAnl5LXudfvkFuHev7fc6OyvCknLx9W352tMTsLDQz74QaRsDko4xIBGZP0EQcO7cObF36fjx42hsMgOks7MznnjiCUybNg1TpkxBz549Ddja9gmCYsqBpqEpNxe4cgUoKVEEq46wslLcWqW1EKVc7O11ujtEGmFA0jEGJKKHT0VFBX744Qfs27cPSUlJuHHjhsr2QYMGYfLkyZg8eTLGjh0LexNLCNXViqCkXIqLW76+fr3lfeha4+6uCEre3ooxUV5eQI8eqo9eXoCbG3ukSH8YkHSMAYno4dbY2Ijs7Gyxd+nHH39E01+ndnZ2GD9+vBiYBgwYYJB5l7StoQEoK2s7RJWUKG6/0lFWVorA1DQ0NQ9SykeplFMbUNcwIOkYAxIRNVVeXo6DBw/iwIEDOHDgAEpKSlS2+/n5YdKkSZg8eTImTpwINzc3A7VU9wRBcbsVZWAqK1P0PDV9VD5vPklme2xtW4amXr0UA88DAxWP3bszRFHrGJB0jAGJiFojCAIuXLgghqX09HSVeZcsLCwwatQosXdp1KhRsLS0NGCLDef+feDGDfXhqfljR8dIOTg8CEzK0NT00dFRt/tExo0BSccYkIioo2pra3H48GExMF1odvdaV1dXTJw4UQxMfn5+BmqpcautfRCmlKHp2jXFIPOCAsW0ByUlih6stnTv3jI0KZ/7+SlO+ZH5YkDSMQYkItLU1atX8cMPP+DAgQNITk7GnTt3VLYPHDhQDEvjxo0zucHehlRfDxQVKcKSMjQVFDx4XlHR9vstLQF/f9XQpJwzqk8fRe8UmTYGJB1jQCIibWhoaEBmZqbYu/Tjjz+qTCVgZ2eHRx99FMOHD0dISAiGDBmC4OBgo5x/yRTcufMgMDUNUJcvK3qimpwJVcvX90Fg6tv3wfPAQMDaWh97QF3FgKRjDEhEpAsVFRUqg72Li4tblLGyskJwcLAYmJSPvr6+ZnGlnKE0NgKlparhKT//waSbbfU+WVoqQpK68OTry2kMjAkDko4xIBGRrilvg3L48GGcP38e586dw/nz51HZymhlqVQqBiZlaBo8eDB/R2nJ7duKsKSclbzp85qa1t9nZ6c4PacuPPGKO/1jQNIxBiQiMgRBEHD16lWVwHTu3Dnk5uaq3EOuqYCAgBa9TX379oUVRyNrhXKG8qaBSRmg8vMBmaz199rZKUJSRxfOA9V1DEg6xoBERMakvr4eubm5KqHp/PnzLeZjUrK1tcXAgQMREhKC4OBg9OzZEz4+PvDx8UHPnj3h4uLC03Va0NAAFBaqD0+Fhe1fcdectXXnAhVnKW+JAUnHGJCIyBSUl5e36G3KycnBvXbuWuvg4CAGJmVoavpauTjwsi6N1dUpxjzdvKl+uXFD9XV7NxpWx8JCEZK6dQM8PBSL8rm6dR4eilvEmPOAc5MISLGxsdi1axd+/vln2NvbIywsDO+++y769+/foqwgCJg2bRqSkpIQHx+PyMhItXXKZDK88cYb2LdvHy5fvgypVIqJEydi7dq18PHxEcuVl5dj6dKl+N///gcLCwvMmTMHH3zwAZycnDrUdgYkIjJVjY2NKCgoEANTfn4+rl27Ji7Npx1oi6ura7tBqlu3brC3t2ePVBfV1rYeptQtHZ1YUx2ptHOhysNDcbrQFJhEQJoyZQqefvpphIaGoqGhAX/961+Rk5ODCxcuwLHZVKcbN25EcnIy9u/f32ZAqqysxNy5c/HSSy9h6NChqKiowCuvvAK5XI6srCyx3NSpU1FaWopt27ZBJpPh97//PUJDQ7Fjx44OtZ0BiYjMVU1NjUpgUi4lJSUqz2s7ccM1KysruLi4QCqVQiqVtvq8rW3Ozs4P7Yzjmrh/XzGwXLncutXyefN17c0T1RYHh5ahqfnr5uucnfU/psokAlJzN2/ehKenJ9LT0zFu3Dhx/ZkzZzB9+nRkZWXB29u7zYCkTmZmJkaNGoXCwkL4+/vj4sWLGDhwIDIzMzFy5EgAQFJSEqZNm4bi4mKVnqbWMCAR0cNMEARUVVW1CE7Nw1RpaSlkbY1S7iQnJyeV8OTm5oZBgwYhNDQUoaGhCAgIYE9VFzQ0KEJSR0KV8rG8HJDLNfs8a+uWAappiJo9GwgK0u4+dvTvt1FdwqC8dNXd3V1cV1NTg/nz52PLli3w8vLSuF6JRAJXV1cAwIkTJ+Dq6iqGIwCYOHEiLCwscPLkScyePbtFHfX19Sr3UqqqqtKoLURE5kAikYhBZcCAAa2WEwQB1dXVqKqqQmVlpbg0fd3a86avlb9/q6urUV1drTL4fP/+/eLzbt26YeTIkWJgCg0N1fhvx8PIyurBAO+OamwEqqpa761qbV1treIKP+WtY9QZPFj7AamjjCYgNTY2YtmyZQgPD8fgwYPF9cuXL0dYWBhmzZqlUb11dXWIiYnBvHnzxKRYVlYGT09PlXJWVlZwd3dHWStHKTY2Fm+99ZZGbSAielhJJBI4OzvD2dkZPXv21Lie+vp6tUHq5s2bOH36NDIzM3H27FncunULSUlJSEpKEt/r6+urEphGjhwp/oeZus7CAnB1VSydCTO1ta2HKeX63r111er2GU1Aio6ORk5ODo4ePSquS0hIQEpKCk6fPq1RnTKZDFFRURAEAVu3bu1S+1atWoUVK1aIr6uqqnhDSSIiPbG1tUX37t3RvY2ujfr6epw7dw6ZmZnicuHCBRQXF6O4uBjx8fFi2T59+qiEpkceeaTF2FfSLXt7xSzjvr6Gbol6RhGQlixZgsTERBw+fBi+TX5SKSkpyM/Pb5H058yZg7FjxyItLa3VOpXhqLCwECkpKSrnGb28vHDjxg2V8g0NDSgvL2+1K9bW1ha2trad3zkiItILW1tbMfAoVVdXIzs7WyU0Xb58GZcuXcKlS5fw1VdfAQAsLCxUxjKFhoYiJCSE97x7iBl0kLYgCFi6dCni4+ORlpaGvn37qmwvKyvDrVu3VNaFhITggw8+wIwZMxAYGKi2XmU4ysvLQ2pqaov/cSgHaWdlZWHEiBEAgB9++AFTpkzhIG0iIjN3+/ZtZGVlqYSm0tLSFuVsbW0xePBg9OrVC35+fvD394efn5+4eHl58ao6E2QSV7H93//9H3bs2IE9e/aozH0klUphb2+v9j0SiaTFVWzBwcGIjY3F7NmzIZPJMHfuXGRnZyMxMRE9evQQy7m7u4v/G5g6dSquX7+Ojz/+WLzMf+TIkbzMn4joIVRSUqISmLKyslDRzjXvVlZW6Nmzp0poah6iPDw8eFWdkTGJgNTaP5q4uDgsXLiw1fc0D0gSiUR8z5UrV1rtWUpNTUVERAQAxUSRS5YsUZko8sMPP+REkUREBEEQkJ+fj5ycHFy9ehVXr15FUVGR+PzatWuQd+Dadnt7e5XA1DxIeXt7QyqVwoL3A9EbkwhIpowBiYjo4dXQ0IDS0lIxMKkLUc3HurZGOWWCm5sb3N3d4ebmJi7tveY98zqPAUnHGJCIiKgtdXV1KCkpUQlNzUNUZVfuBwLA0tISrq6ubQYqDw8PtY9WVkZxnZbeMSDpGAMSERF1VX19PSoqKlSW8vLyNl8r1zWdvFgTLi4ubQYodY+urq4mPzDdJGfSJiIiepjY2trCy8tLo9m+a2tr2w1WyuX27dvio/JmxFVVVaiqqsKVK1c6/JnKu1I0DU5tLU17taytrTu9j4bEgERERGSC7O3tYW9v36GpaZqSy+VigGoanNp7vHv3LgRBEANYfn5+pz7X2dm53UDVNFS5u7vD09PTYMGKAYmIiOghYmlpiW7duqFbt26dep9MJlPpkbp9+3aLniplL1bT18oeq7t37+Lu3bsoLCzs8Gfu2bMHM2fO7FQ7tYUBiYiIiNplbW2NHj16qMwv2BFyuRx37txpEaTaClXKpenN6/WNAYmIiIh0xtLSEh4eHvDw8OjU+wRBgCGvI2NAIiIiIqMjkUgMOscTp+4kIiIiaoYBiYiIiKgZBiQiIiKiZhiQiIiIiJphQCIiIiJqhgGJiIiIqBkGJCIiIqJmGJCIiIiImmFAIiIiImqGAYmIiIioGQYkIiIiomYYkIiIiIiaYUAiIiIiasbK0A0wVYIgAACqqqoM3BIiIiLqKOXfbeXf8dYwIGno7t27AAA/Pz8Dt4SIiIg66+7du5BKpa1ulwjtRShSq7GxEdeuXYOzszMkEonW6q2qqoKfnx+uXr0KFxcXrdVrrB6m/eW+mq+HaX+5r+brYdlfQRBw9+5d+Pj4wMKi9ZFG7EHSkIWFBXx9fXVWv4uLi1n/A23uYdpf7qv5epj2l/tqvh6G/W2r50iJg7SJiIiImmFAIiIiImqGAcnI2NraYs2aNbC1tTV0U/TiYdpf7qv5epj2l/tqvh62/W0PB2kTERERNcMeJCIiIqJmGJCIiIiImmFAIiIiImqGAYmIiIioGQYkA9iyZQsCAgJgZ2eH0aNH48cff2yz/Lfffovg4GDY2dkhJCQE+/bt01NLuyY2NhahoaFwdnaGp6cnIiMjkZub2+Z7tm/fDolEorLY2dnpqcWae/PNN1u0Ozg4uM33mOpxBYCAgIAW+yuRSBAdHa22vCkd18OHD2PGjBnw8fGBRCLB7t27VbYLgoC//e1v8Pb2hr29PSZOnIi8vLx26+3s914f2tpXmUyGmJgYhISEwNHRET4+PliwYAGuXbvWZp2afBf0ob3junDhwhbtnjJlSrv1GuNxBdrfX3XfX4lEgnXr1rVap7EeW11hQNKzr7/+GitWrMCaNWuQnZ2NoUOHYvLkybhx44ba8sePH8e8efOwaNEinD59GpGRkYiMjEROTo6eW9556enpiI6ORkZGBpKTkyGTyTBp0iTcu3evzfe5uLigtLRUXAoLC/XU4q4ZNGiQSruPHj3aallTPq4AkJmZqbKvycnJAIDf/e53rb7HVI7rvXv3MHToUGzZskXt9vfeew8ffvghPv74Y5w8eRKOjo6YPHky6urqWq2zs997fWlrX2tqapCdnY3Vq1cjOzsbu3btQm5uLmbOnNluvZ35LuhLe8cVAKZMmaLS7q+++qrNOo31uALt72/T/SwtLcWnn34KiUSCOXPmtFmvMR5bnRFIr0aNGiVER0eLr+VyueDj4yPExsaqLR8VFSU8+eSTKutGjx4tvPzyyzptpy7cuHFDACCkp6e3WiYuLk6QSqX6a5SWrFmzRhg6dGiHy5vTcRUEQXjllVeEoKAgobGxUe12Uz2uAIT4+HjxdWNjo+Dl5SWsW7dOXHfnzh3B1tZW+Oqrr1qtp7Pfe0Novq/q/PjjjwIAobCwsNUynf0uGIK6fX3++eeFWbNmdaoeUziugtCxYztr1izhsccea7OMKRxbbWIPkh7dv38fp06dwsSJE8V1FhYWmDhxIk6cOKH2PSdOnFApDwCTJ09utbwxq6ysBAC4u7u3Wa66uhq9evWCn58fZs2ahZ9++kkfzeuyvLw8+Pj4oHfv3njmmWdQVFTUallzOq7379/HF198gRdeeKHNGzeb6nFtqqCgAGVlZSrHTiqVYvTo0a0eO02+98aqsrISEokErq6ubZbrzHfBmKSlpcHT0xP9+/fHH//4R9y+fbvVsuZ0XK9fv469e/di0aJF7ZY11WOrCQYkPbp16xbkcjl69Oihsr5Hjx4oKytT+56ysrJOlTdWjY2NWLZsGcLDwzF48OBWy/Xv3x+ffvop9uzZgy+++AKNjY0ICwtDcXGxHlvbeaNHj8b27duRlJSErVu3oqCgAGPHjsXdu3fVljeX4woAu3fvxp07d7Bw4cJWy5jqcW1OeXw6c+w0+d4bo7q6OsTExGDevHlt3si0s98FYzFlyhR8/vnnOHToEN59912kp6dj6tSpkMvlasuby3EFgM8++wzOzs747W9/22Y5Uz22mrIydAPo4RAdHY2cnJx2z1ePGTMGY8aMEV+HhYVhwIAB2LZtG95++21dN1NjU6dOFZ8PGTIEo0ePRq9evfDNN9906H9lpuyTTz7B1KlT4ePj02oZUz2upCCTyRAVFQVBELB169Y2y5rqd+Hpp58Wn4eEhGDIkCEICgpCWloaHn/8cQO2TPc+/fRTPPPMM+1eOGGqx1ZT7EHSo27dusHS0hLXr19XWX/9+nV4eXmpfY+Xl1enyhujJUuWIDExEampqfD19e3Ue62trfHII4/g0qVLOmqdbri6uqJfv36tttscjisAFBYW4uDBg3jxxRc79T5TPa7K49OZY6fJ996YKMNRYWEhkpOT2+w9Uqe974Kx6t27N7p169Zqu039uCodOXIEubm5nf4OA6Z7bDuKAUmPbGxsMGLECBw6dEhc19jYiEOHDqn877qpMWPGqJQHgOTk5FbLGxNBELBkyRLEx8cjJSUFgYGBna5DLpfj/Pnz8Pb21kELdae6uhr5+fmtttuUj2tTcXFx8PT0xJNPPtmp95nqcQ0MDISXl5fKsauqqsLJkydbPXaafO+NhTIc5eXl4eDBg/Dw8Oh0He19F4xVcXExbt++3Wq7Tfm4NvXJJ59gxIgRGDp0aKffa6rHtsMMPUr8YbNz507B1tZW2L59u3DhwgVh8eLFgqurq1BWViYIgiA899xzwsqVK8Xyx44dE6ysrIT169cLFy9eFNasWSNYW1sL58+fN9QudNgf//hHQSqVCmlpaUJpaam41NTUiGWa7+9bb70lHDhwQMjPzxdOnTolPP3004KdnZ3w008/GWIXOuzPf/6zkJaWJhQUFAjHjh0TJk6cKHTr1k24ceOGIAjmdVyV5HK54O/vL8TExLTYZsrH9e7du8Lp06eF06dPCwCE999/Xzh9+rR45dbatWsFV1dXYc+ePcK5c+eEWbNmCYGBgUJtba1Yx2OPPSZ89NFH4uv2vveG0ta+3r9/X5g5c6bg6+srnDlzRuU7XF9fL9bRfF/b+y4YSlv7evfuXeHVV18VTpw4IRQUFAgHDx4Uhg8fLvTt21eoq6sT6zCV4yoI7f87FgRBqKysFBwcHIStW7eqrcNUjq2uMCAZwEcffST4+/sLNjY2wqhRo4SMjAxx2/jx44Xnn39epfw333wj9OvXT7CxsREGDRok7N27V88t1gwAtUtcXJxYpvn+Llu2TPzZ9OjRQ5g2bZqQnZ2t/8Z30lNPPSV4e3sLNjY2Qs+ePYWnnnpKuHTpkrjdnI6r0oEDBwQAQm5ubottpnxcU1NT1f67Ve5PY2OjsHr1aqFHjx6Cra2t8Pjjj7f4GfTq1UtYs2aNyrq2vveG0ta+FhQUtPodTk1NFetovq/tfRcMpa19rampESZNmiR0795dsLa2Fnr16iW89NJLLYKOqRxXQWj/37EgCMK2bdsEe3t74c6dO2rrMJVjqysSQRAEnXZREREREZkYjkEiIiIiaoYBiYiIiKgZBiQiIiKiZhiQiIiIiJphQCIiIiJqhgGJiIiIqBkGJCIiIqJmGJCIiIiImmFAIiLSUFpaGiQSCe7cuWPophCRljEgERERETXDgERERETUDAMSEZmsxsZGxMbGIjAwEPb29hg6dCi+++47AA9Of+3duxdDhgyBnZ0dfvOb3yAnJ0elju+//x6DBg2Cra0tAgICsGHDBpXt9fX1iImJgZ+fH2xtbdGnTx988sknKmVOnTqFkSNHwsHBAWFhYcjNzRW3nT17FhMmTICzszNcXFwwYsQIZGVl6egnQkTawoBERCYrNjYWn3/+OT7++GP89NNPWL58OZ599lmkp6eLZV577TVs2LABmZmZ6N69O2bMmAGZTAZAEWyioqLw9NNP4/z583jzzTexevVqbN++XXz/ggUL8NVXX+HDDz/ExYsXsW3bNjg5Oam04/XXX8eGDRuQlZUFKysrvPDCC+K2Z555Br6+vsjMzMSpU6ewcuVKWFtb6/YHQ0RdJxARmaC6ujrBwcFBOH78uMr6RYsWCfPmzRNSU1MFAMLOnTvFbbdv3xbs7e2Fr7/+WhAEQZg/f77wxBNPqLz/tddeEwYOHCgIgiDk5uYKAITk5GS1bVB+xsGDB8V1e/fuFQAItbW1giAIgrOzs7B9+/au7zAR6RV7kIjIJF26dAk1NTV44okn4OTkJC6ff/458vPzxXJjxowRn7u7u6N///64ePEiAODixYsIDw9XqTc8PBx5eXmQy+U4c+YMLC0tMX78+DbbMmTIEPG5t7c3AODGjRsAgBUrVuDFF1/ExIkTsXbtWpW2EZHxYkAiIpNUXV0NANi7dy/OnDkjLhcuXBDHIXWVvb19h8o1PWUmkUgAKMZHAcCbb76Jn376CU8++SRSUlIwcOBAxMfHa6V9RKQ7DEhEZJIGDhwIW1tbFBUVoU+fPiqLn5+fWC4jI0N8XlFRgV9++QUDBgwAAAwYMADHjh1TqffYsWPo168fLC0tERISgsbGRpUxTZro168fli9fjh9++AG//e1vERcX16X6iEj3rAzdACIiTTg7O+PVV1/F8uXL0djYiEcffRSVlZU4duwYXFxc0KtXLwDA3//+d3h4eKBHjx54/fXX0a1bN0RGRgIA/vznPyM0NBRvv/02nnrqKZw4cQKbN2/GP//5TwBAQEAAnn/+ebzwwgv48MMPMXToUBQWFuLGjRuIiopqt421tbV47bXXMHfuXAQGBqK4uBiZmZmYM2eOzn4uRKQlhh4ERUSkqcbGRmHTpk1C//79BWtra6F79+7C5MmThfT0dHEA9f/+9z9h0KBBgo2NjTBq1Cjh7NmzKnV89913wsCBAwVra2vB399fWLduncr22tpaYfny5YK3t7dgY2Mj9OnTR/j0008FQXgwSLuiokIsf/r0aQGAUFBQINTX1wtPP/204OfnJ9jY2Ag+Pj7CkiVLxAHcRGS8JIIgCAbOaEREWpeWloYJEyagoqICrq6uhm4OEZkYjkEiIiIiaoYBiYiIiKgZnmIjIiIiaoY9SERERETNMCARERERNcOARERERNQMAxIRERFRMwxIRERERM0wIBERERE1w4BERERE1AwDEhEREVEz/w9c1wvehQ6XDAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Build and compile the DNN model\n",
    "## Training and Testing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Opt_Adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer = Opt_Adam, loss = custom_loss_DC3)\n",
    "\n",
    "train_input = [train_input_F_H_shuffled, train_input_EsN0_shuffled]\n",
    "valid_input = [valid_input_F_H_shuffled, valid_input_EsN0_shuffled]\n",
    "\n",
    "history = model.fit(train_input, train_y_true, epochs = 20,\n",
    "                    validation_data = (valid_input, valid_y_true), batch_size = 1000)\n",
    "\n",
    "plt.plot(history.epoch, history.history['loss'], color = \"blue\", label = \"Training\")\n",
    "plt.plot(history.epoch, history.history['val_loss'], color=\"black\", label = \"Validation\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data setup\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))  # Predicted power allocation\n",
    "output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], K, 1))  # Reshape to [num_samples, K, 1]\n",
    "output_P_hat_size = tf.shape(output_P_hat)[0]  # Number of samples\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)  # Compute squared magnitude of hij\n",
    "\n",
    "eta = 1e-3  # Learning rate for gradient descent\n",
    "indx_n = []  # List to store indices of samples with constraint violations\n",
    "count_v = 0  # Counter for total violations\n",
    "\n",
    "# Iterate over each test sample\n",
    "for k in range(output_P_hat_size):\n",
    "    p = output_P_hat[k]  # Initial power vector for this sample, shape [K, 1]\n",
    "    hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample, shape [K, K]\n",
    "    sigma_sqr_noise_0dB_sample = sigma_sqr_noise_0dB  # Use constant noise variance for all samples\n",
    "\n",
    "    # Ensure consistent data types\n",
    "    p = tf.cast(p, dtype=tf.float32)\n",
    "    hij_abs_sqr = tf.cast(hij_abs_sqr, dtype=tf.float32)\n",
    "    sigma_sqr_noise_0dB_sample = tf.cast(sigma_sqr_noise_0dB_sample, dtype=tf.float32)\n",
    "    SINR_P_min = tf.cast(SINR_P_min, dtype=tf.float32)\n",
    "\n",
    "    # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "    A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "    b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB_sample, hij_abs_sqr)\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(b, K)\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    # Perform gradient descent for 5 iterations\n",
    "    for i in range(100):\n",
    "        V = B_tilda - tf.matmul(A_tilda, p)\n",
    "        V_relu = tf.nn.relu(V)  # Apply ReLU to the result\n",
    "        gd = 2 * tf.matmul(A_tilda_T, V_relu)  # Gradient descent update\n",
    "        p = p + eta * gd  # Update power allocation\n",
    "\n",
    "    # Check for SINR constraint violations after applying gradient descent\n",
    "    for i in range(K):  # Iterate over each user\n",
    "        ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr[i, :]))  # Interference + noise\n",
    "        numr = tf.multiply(p[i], hij_abs_sqr[i, i])  # Signal power (numerator)\n",
    "        dnumr = sigma_sqr_noise_0dB_sample[i] + ph - numr  # Denominator of SINR\n",
    "        SINR_out = tf.divide(numr, dnumr)  # Compute SINR\n",
    "\n",
    "        # Round SINR to 3 decimal places and check for violations\n",
    "        SINR_out_rounded = tf.round(SINR_out * 1000) / 1000\n",
    "\n",
    "        # Perform element-wise comparison and reduce to check for any violations\n",
    "        violation = tf.reduce_any(SINR_out_rounded < SINR_P_min[i])\n",
    "        if violation:\n",
    "            indx_n.append(k)  # Store index of sample with violation\n",
    "            count_v += 1  # Increment violation counter\n",
    "            break  # Stop checking further users for this sample\n",
    "\n",
    "# Calculate violation probability\n",
    "violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data setup\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))  # Predicted power allocation\n",
    "output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], K, 1))  # Reshape to [num_samples, K, 1]\n",
    "output_P_hat_size = tf.shape(output_P_hat)[0]  # Number of samples\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)  # Compute squared magnitude of hij\n",
    "\n",
    "eta = 1e-3  # Learning rate for gradient descent\n",
    "indx_n = []  # List to store indices of samples with constraint violations\n",
    "count_v = 0  # Counter for total violations\n",
    "\n",
    "# Iterate over each test sample\n",
    "for k in range(output_P_hat_size):\n",
    "    p = output_P_hat[k]  # Initial power vector for this sample, shape [K, 1]\n",
    "    hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample, shape [K, K]\n",
    "    sigma_sqr_noise_0dB_sample = sigma_sqr_noise_0dB[k]  # Noise variance for this sample\n",
    "\n",
    "\n",
    "    # Ensure consistent data types\n",
    "    p = tf.cast(p, dtype=tf.float32)  # Already float32, but ensuring consistency\n",
    "    hij_abs_sqr = tf.cast(hij_abs_sqr, dtype=tf.float32)  # Cast to float32\n",
    "    sigma_sqr_noise_0dB_sample = tf.cast(sigma_sqr_noise_0dB_sample, dtype=tf.float32)  # Cast to float32\n",
    "\n",
    "\n",
    "    # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "    A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "    b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB, hij_abs_sqr)\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(b, K)\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    # Perform gradient descent for 5 iterations\n",
    "    for i in range(5):\n",
    "        V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "        V_relu = tf.nn.relu(V)  # Apply ReLU to the result\n",
    "        gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)  # Gradient descent update\n",
    "        p = p + eta * gd  # Update power allocation\n",
    "\n",
    "    # Check for SINR constraint violations after applying gradient descent\n",
    "    for i in range(K):  # Iterate over each user\n",
    "        ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr[i, :]))  # Interference + noise\n",
    "        numr = tf.multiply(p[i], hij_abs_sqr[i, i])  # Signal power (numerator)\n",
    "        dnumr = sigma_sqr_noise_0dB[i] + ph - numr  # Denominator of SINR\n",
    "        SINR_out = tf.divide(numr, dnumr)  # Compute SINR\n",
    "\n",
    "        # # Check if SINR is below the minimum required value\n",
    "        if tf.round(SINR_out, decimals=3) < SINR_P_min[i]:\n",
    "            indx_n.append(k)  # Store index of sample with violation\n",
    "            count_v += 1  # Increment violation counter\n",
    "            break  # Stop checking further users for this sample\n",
    "\n",
    "# Calculate violation probability\n",
    "violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Updated test code in TensorFlow to apply gradient descent on test data\n",
    "\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))\n",
    "output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], tf.shape(output_P_hat_temp)[1], 1)) # test_input_F_H_size X row X column\n",
    "output_P_hat_size = tf.shape(output_P_hat)[0]\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)\n",
    "\n",
    "eta = 1e-3  # Same learning rate used in the gradient descent\n",
    "\n",
    "indx_n = []\n",
    "count_v = 0\n",
    "\n",
    "for k in range(output_P_hat_size):\n",
    "    p = output_P_hat[k]  # Initial power vector for this sample\n",
    "    hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample\n",
    "\n",
    "    # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "    A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "    b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB, hij_abs_sqr)\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(b, K)\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    # Perform gradient descent on this sample\n",
    "    for i in range(5):\n",
    "        V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "        V_relu = tf.nn.relu(V)  # ReLU operation\n",
    "        gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)\n",
    "        p = p + eta * gd  # Update the power allocation\n",
    "\n",
    "    # Check for SINR constraint violations after applying gradient descent\n",
    "    for i in range(K):  # Total rows\n",
    "        ph = 0\n",
    "        for j in range(K):  # Total columns\n",
    "            ph_j = tf.multiply(p[j], hij_abs_sqr[i, j])\n",
    "            ph = ph + ph_j\n",
    "\n",
    "        numr = tf.multiply(p[i], hij_abs_sqr[i, i])\n",
    "        dnumr = sigma_sqr_noise_0dB[i] + ph - numr\n",
    "        SINR_out = tf.divide(numr, dnumr)\n",
    "\n",
    "        # Check if the SINR is below the minimum required value\n",
    "        if tf.round(SINR_out, decimals=3) < SINR_P_min[i]:\n",
    "            indx_n.append(k)\n",
    "            count_v += 1\n",
    "            break\n",
    "\n",
    "# Calculate violation probability\n",
    "violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constraint violation probability and\n",
    "## finding indexes of test_input_F_H matrix with the hij set that do not satisfy\n",
    "## constraint on the minimum SINR_P_min rate but satisfy the maximum transmit\n",
    "## power PMax\n",
    "\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "# output_P_hat_temp = model.predict(test_input)\n",
    "output_P_hat_temp = np.multiply(PMax, model.predict(test_input))\n",
    "output_P_hat = output_P_hat_temp.reshape((output_P_hat_temp.shape[0], output_P_hat_temp.shape[1], 1)) # test_input_F_H_size X row X column\n",
    "output_P_hat_size = output_P_hat.shape[0]\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)\n",
    "\n",
    "indx_n = []\n",
    "count_v = 0\n",
    "\n",
    "for k in range(output_P_hat_size):\n",
    "  for i in range(K):  # Total rows\n",
    "    ph = 0\n",
    "    for j in range(K):  # Total columns\n",
    "      ph_j = np.multiply(output_P_hat[k,j], test_data_F_H_abs_sqr[k,i,j])\n",
    "      ph = ph + ph_j\n",
    "\n",
    "    numr = np.multiply(output_P_hat[k,i], test_data_F_H_abs_sqr[k,i,i])\n",
    "    dnumr = sigma_sqr_noise_0dB[i] + ph - numr\n",
    "    SINR_out = np.divide(numr, dnumr)\n",
    "\n",
    "    if np.round(SINR_out, decimals= 3) < SINR_P_min[i]:\n",
    "      indx_n.append(k)\n",
    "      count_v = count_v + 1\n",
    "      # print(SINR_out)\n",
    "      break\n",
    "\n",
    "violation_prb = (count_v / output_P_hat_size) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n",
    "# print(len(indx_n))\n",
    "# print(indx_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate the average sum rate\n",
    "# Here, p_model is the output of DNN, and it is a 2D array.\n",
    "import math\n",
    "\n",
    "def average_sum_rate(hij, p_model, sigma_sqr_noise, K):\n",
    "  R = 0\n",
    "  hij_size = hij.shape[0]\n",
    "  hij_abs_sqr = cmplx_abs_sqr(hij)\n",
    "\n",
    "  for k in range(hij_size):\n",
    "    for i in range(K):  # Total rows\n",
    "      phn = 0\n",
    "      for j in range(K):  # Total columns\n",
    "        phn_j = np.multiply(p_model[k,j], hij_abs_sqr[k,i,j])\n",
    "        phn = phn + phn_j\n",
    "\n",
    "      numr_s = np.multiply(p_model[k,i], hij_abs_sqr[k,i,i])\n",
    "      dnumr_s = sigma_sqr_noise[i] + phn - numr_s\n",
    "      R_temp = math.log2(1 + np.divide(numr_s, dnumr_s))\n",
    "      R = R + R_temp\n",
    "\n",
    "  return (R/hij_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step\n",
      "Average Sum Rate for all H matrices: 1.900 Bit/Second/Hertz\n"
     ]
    }
   ],
   "source": [
    "## DNN Sum Rate for test_data_F_H\n",
    "sumrate_F_H = average_sum_rate(test_input[0], model.predict(test_input),sigma_sqr_noise_0dB, K)\n",
    "print(\"Average Sum Rate for all H matrices: {:.3f} Bit/Second/Hertz\".format(sumrate_F_H))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
