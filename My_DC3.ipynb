{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.api._v2.keras import layers\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import numba as nb\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of transmitter-receiver pairs\n",
    "K = 5\n",
    "\n",
    "# Minimum rate for the achievable SINR of multiple concurrent transmissions\n",
    "SINR_P_min = tf.constant([0.2, 0.2, 0.2, 0.2, 0.2], dtype=tf.float32)\n",
    "\n",
    "# Maximum transmit power\n",
    "PMax = tf.constant(1.0, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variances for noise signals at different dB levels\n",
    "sigma_sqr_noise_0dB = np.full(5, 1e-0, dtype=float)\n",
    "sigma_sqr_noise_10dB = np.full(5, 1e-1, dtype=float)\n",
    "sigma_sqr_noise_20dB = np.full(5, 1e-2, dtype=float)\n",
    "sigma_sqr_noise_30dB = np.full(5, 1e-3, dtype=float)\n",
    "sigma_sqr_noise_40dB = np.full(5, 1e-4, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load and reshape the CSV files into 3D arrays\n",
    "def load_and_reshape(file_path, K):\n",
    "    # Load the CSV file as a 2D array\n",
    "    FH2D = loadtxt(file_path, delimiter=',', dtype=str)\n",
    "    \n",
    "    # Reshape the 2D array into a 3D array\n",
    "    FH3D = FH2D.reshape(FH2D.shape[0], -1, K)\n",
    "    \n",
    "    # Return the reshaped array and its size\n",
    "    return FH3D, FH3D.shape[0]\n",
    "\n",
    "Folder = \"C:\\\\Users\\\\essay\\\\Desktop\\\\FYP\\\\Datasets\\\\K=5\"\n",
    "\n",
    "# Loading and reshaping the arrays from CSV files\n",
    "FH3D_0dB, FH3D_0dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_0dB.csv'), K=5)\n",
    "FH3D_10dB, FH3D_10dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_10dB.csv'), K=5)\n",
    "FH3D_20dB, FH3D_20dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_20dB.csv'), K=5)\n",
    "FH3D_30dB, FH3D_30dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_30dB.csv'), K=5)\n",
    "FH3D_40dB, FH3D_40dB_size = load_and_reshape(os.path.join(Folder,'F_H_2D_40dB.csv'), K=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert string data to complex data and remove initial whitespace using vectorized operations\n",
    "def cnvrt_2_cmplx_data(FH3D_size, FH3D):\n",
    "    # Use np.char.strip to remove initial whitespace from the entire 3D array\n",
    "    FH3D_stripped = np.char.strip(FH3D)\n",
    "    \n",
    "    # Convert the stripped string array to complex numbers using vectorized conversion\n",
    "    FHCmplx = FH3D_stripped.astype(np.complex_)\n",
    "    \n",
    "    # Reshape the array directly to the desired shape (H_size, K, K)\n",
    "    F_H = FHCmplx.reshape(FH3D_size, K, K)\n",
    "    \n",
    "    return F_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "## Converting string data to complex data and removing the initial whitespace\n",
    "F_H_0dB = cnvrt_2_cmplx_data(FH3D_0dB_size, FH3D_0dB)\n",
    "F_H_10dB = cnvrt_2_cmplx_data(FH3D_10dB_size, FH3D_10dB)\n",
    "F_H_20dB = cnvrt_2_cmplx_data(FH3D_20dB_size, FH3D_20dB)\n",
    "F_H_30dB = cnvrt_2_cmplx_data(FH3D_30dB_size, FH3D_30dB)\n",
    "F_H_40dB = cnvrt_2_cmplx_data(FH3D_40dB_size, FH3D_40dB)\n",
    "\n",
    "print(F_H_0dB.shape)\n",
    "print(F_H_10dB.shape)\n",
    "print(F_H_20dB.shape)\n",
    "print(F_H_30dB.shape)\n",
    "print(F_H_40dB.shape)\n",
    "\n",
    "F_H_0dB_size = F_H_0dB.shape[0]\n",
    "F_H_10dB_size = F_H_10dB.shape[0]\n",
    "F_H_20dB_size = F_H_20dB.shape[0]\n",
    "F_H_30dB_size = F_H_30dB.shape[0]\n",
    "F_H_40dB_size = F_H_40dB.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.23631937+0.22921883j -0.54667901-0.20138914j\n",
      "   -0.47946164+0.498344j    0.3113009 -0.22798014j\n",
      "    0.69691993-0.88261167j]\n",
      "  [-0.14673233-0.67982819j  1.05716624-0.17533585j\n",
      "    1.40408283-0.3634557j  -0.01055404-0.70807464j\n",
      "   -0.25915166+0.60921694j]\n",
      "  [ 0.78419976-0.33361193j  0.40834267+1.0118874j\n",
      "   -0.96713008-0.16796663j -0.6647029 -0.7954383j\n",
      "    0.02752075-0.71561235j]\n",
      "  [ 0.3465332 -0.09099838j -0.4367235 +1.37334099j\n",
      "    0.7779833 +0.29038137j -0.05983818+0.77268389j\n",
      "    0.50615944-0.15630014j]\n",
      "  [ 0.53521481-0.13481686j  1.21080065-0.03027252j\n",
      "   -0.48457478+0.57532919j  0.01145698-0.21696277j\n",
      "    1.17455914+1.17218511j]]\n",
      "\n",
      " [[ 0.79699507+0.63304366j  0.01760131+0.32898345j\n",
      "    0.05801209+0.55645257j  0.38766506-0.43073101j\n",
      "   -0.45751618-0.60856057j]\n",
      "  [-0.26554943-0.92245427j -0.85025071+0.87457213j\n",
      "    0.29233821+0.99113017j -1.19413667-0.06657383j\n",
      "    0.12229737+0.16174348j]\n",
      "  [-0.10512262-1.25990919j -0.40637738-0.68602838j\n",
      "    0.01210378-1.02630839j  0.47588371-0.08603115j\n",
      "    0.09309989+0.11602879j]\n",
      "  [-0.22732738+0.79207634j -0.16634939-0.27815233j\n",
      "    1.24831871+0.01199174j  0.75898117-0.08660323j\n",
      "    0.81174366+0.45061337j]\n",
      "  [ 0.36262892-0.5270233j  -0.73321827-1.38334335j\n",
      "   -0.00912687+0.92046035j  1.20061156+0.09927137j\n",
      "   -0.14781791+0.99923613j]]\n",
      "\n",
      " [[-0.64804294+0.46525681j  0.16549187+0.47468413j\n",
      "   -0.20747958-0.17463521j  0.43210841-0.12210355j\n",
      "    0.65070062-0.36521428j]\n",
      "  [-0.56029947+1.25975985j -0.11264297+1.73582172j\n",
      "    0.39986776+1.24560395j  0.309937  +0.03050013j\n",
      "    0.02377968-0.09915411j]\n",
      "  [ 0.84955967-0.88454336j -1.06070152+0.40656115j\n",
      "    1.12302148-0.77515379j -1.24576166+0.02660652j\n",
      "    0.05830689-0.10745618j]\n",
      "  [-0.88447658+0.96005678j -0.03175394+0.58287616j\n",
      "   -0.17964543+0.72722242j -0.69696048+0.03552663j\n",
      "   -1.28187984-0.46384551j]\n",
      "  [-0.23177995+0.5015831j   0.09772908+1.59263317j\n",
      "    0.34319981+0.14942333j  0.88534137+0.34671507j\n",
      "    0.19711277+1.59253349j]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.35110619+0.75164102j -0.66832613-0.88770411j\n",
      "    0.56969782+0.60267587j  0.1448037 +0.17523717j\n",
      "    0.2925982 +1.4000573j ]\n",
      "  [ 0.10966727-1.22817466j  0.79169845+0.40461756j\n",
      "    0.16540382+0.72903676j  0.03785419+0.72473118j\n",
      "   -0.97545371+0.74242792j]\n",
      "  [-0.54865403+1.01148071j  0.22893075+0.5099906j\n",
      "    0.89581451-0.89142613j  0.5665831 -0.38018336j\n",
      "   -0.66661349+0.50856041j]\n",
      "  [-0.36387826+1.17965168j -0.01587501-0.66000489j\n",
      "   -0.10909053+0.70365052j  0.05971599+1.01355122j\n",
      "    0.1232049 +0.73097491j]\n",
      "  [ 0.42698062-0.89785996j -0.95494014-0.88348405j\n",
      "   -0.90977225+0.00804317j -0.20193161-0.02668996j\n",
      "   -1.69940106-0.17876902j]]\n",
      "\n",
      " [[ 0.76513758-0.89034527j  1.01685448-0.00874106j\n",
      "    0.28316273+0.87179655j -0.68672858-0.12423602j\n",
      "   -0.44265524+0.24376109j]\n",
      "  [-0.40001253-0.11647371j -0.53445838+1.26245197j\n",
      "   -1.13089017-0.72087593j -0.49797817-0.70575168j\n",
      "   -0.9633443 +0.51147263j]\n",
      "  [ 0.54043188+0.3411341j  -0.67908527+1.55748463j\n",
      "   -1.30985573+0.24588651j -1.43974121-0.04183714j\n",
      "   -0.51747427+1.2642712j ]\n",
      "  [ 0.16977946-0.20115379j -0.55330591-1.15664491j\n",
      "   -0.27434796+0.55125128j -0.85766661-0.10238393j\n",
      "    0.81617442-0.00872848j]\n",
      "  [-0.81229511-0.19632708j  0.41739093-0.45775496j\n",
      "   -0.76014925+0.71615056j -0.30547585-0.55516717j\n",
      "   -1.65385442+0.29650634j]]\n",
      "\n",
      " [[ 0.13441276-1.1112329j  -0.10208992+0.37949394j\n",
      "    0.21410846+0.60197919j  1.06091448-0.72269727j\n",
      "    0.10345367-1.57739645j]\n",
      "  [ 0.24680004+0.11809635j  0.69535003-0.0301694j\n",
      "    0.69358654+0.54599125j  0.54677691-0.53646087j\n",
      "    1.46393104+0.72790428j]\n",
      "  [-0.11393922-0.178748j   -0.01908946-0.04262089j\n",
      "    0.94483365+0.38377272j -0.4907984 -0.4920892j\n",
      "    0.52972141+1.3019612j ]\n",
      "  [-0.7882661 -0.15441574j  0.41362767-0.48322579j\n",
      "    0.90501556+0.51547975j -1.01851061+0.79979708j\n",
      "   -0.01309613-0.60471579j]\n",
      "  [-0.43597285+0.28624563j -0.06172437+0.16210253j\n",
      "    0.43510299+0.38052826j -0.53205679+0.33003762j\n",
      "   -0.81119791+0.79430835j]]]\n"
     ]
    }
   ],
   "source": [
    "print(F_H_0dB)\n",
    "# print(F_H_10dB)\n",
    "# print(F_H_20dB)\n",
    "# print(F_H_30dB)\n",
    "# print(F_H_40dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the square of the absolute value of a complex tensor\n",
    "def cmplx_abs_sqr(cmplx_var):\n",
    "    # Calculate the squared magnitude of the complex numbers\n",
    "    return tf.math.square(tf.math.real(cmplx_var)) + tf.math.square(tf.math.imag(cmplx_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the matrix A (K x K) using TensorFlow functions\n",
    "def generate_A(F_H_size, K, SINR_P_min, F_H):\n",
    "    # Calculate the squared magnitude of the complex matrix and cast to float32\n",
    "    F_H_abs_sqr = tf.cast(cmplx_abs_sqr(F_H), dtype=tf.float32)\n",
    "\n",
    "    # Create an identity matrix for selecting diagonal elements (float32)\n",
    "    identity_matrix = tf.eye(K, dtype=tf.float32)\n",
    "\n",
    "    # Expand SINR_P_min to match dimensions for broadcasting and cast to float32\n",
    "    SINR_P_min_expanded = tf.expand_dims(tf.cast(SINR_P_min, dtype=tf.float32), axis=-1)  # Shape: (K, 1)\n",
    "\n",
    "    # Create the matrix A using TensorFlow operations\n",
    "    Aij = tf.where(\n",
    "        tf.equal(identity_matrix, 1),  # Condition to keep diagonal elements\n",
    "        F_H_abs_sqr,                   # Use F_H_abs_sqr for diagonal elements\n",
    "        -SINR_P_min_expanded * F_H_abs_sqr  # Multiply off-diagonal elements by -SINR_P_min\n",
    "    )\n",
    "\n",
    "    # Reshape the resulting array to (F_H_size, K, K)\n",
    "    Aij = tf.reshape(Aij, (F_H_size, K, K))\n",
    "\n",
    "    return Aij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to generate the vector b (K x 1) using TensorFlow operations\n",
    "def generate_b(F_H_size, K, SINR_P_min, sigma_sqr_noise, F_H):\n",
    "    # Calculate the vector b by broadcasting SINR_P_min and sigma_sqr_noise\n",
    "    b = tf.multiply(SINR_P_min, sigma_sqr_noise)  # Element-wise multiplication\n",
    "    \n",
    "    # Reshape to (1, K, 1) to match dimensions for broadcasting\n",
    "    b = tf.reshape(b, (1, K, 1))\n",
    "\n",
    "    # Repeat this result across the F_H_size dimension\n",
    "    bi = tf.repeat(b, repeats=F_H_size, axis=0)\n",
    "    \n",
    "    return bi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split datasets into training, validation, and testing\n",
    "def split(np_array):\n",
    "    # Define fixed sizes for training, validation, and testing datasets\n",
    "    train_data_size = 200000\n",
    "    valid_data_size = 25000\n",
    "    test_data_size = 25000\n",
    "\n",
    "    # Calculate the indices for slicing the dataset\n",
    "    train_e_indx = train_data_size\n",
    "    valid_e_indx = train_e_indx + valid_data_size\n",
    "    test_e_indx = valid_e_indx + test_data_size\n",
    "\n",
    "    # Slice the input array into training, validation, and testing datasets\n",
    "    train_data = np_array[:train_e_indx]\n",
    "    valid_data = np_array[train_e_indx:valid_e_indx]\n",
    "    test_data = np_array[valid_e_indx:test_e_indx]\n",
    "\n",
    "    # Calculate the absolute values of the datasets\n",
    "    train_input = np.abs(train_data)\n",
    "    valid_input = np.abs(valid_data)\n",
    "    test_input = np.abs(test_data)\n",
    "\n",
    "    # Print the shapes to verify correctness\n",
    "    print(train_input.shape, valid_input.shape, test_input.shape)\n",
    "\n",
    "    # Return the split datasets\n",
    "    return [train_input, valid_input, test_input, test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# List of F_H matrices\n",
    "F_H_matrices = [F_H_0dB, F_H_10dB, F_H_20dB, F_H_30dB, F_H_40dB]\n",
    "\n",
    "# Split each matrix and assign the results to corresponding variables\n",
    "splits = [split(F_H) for F_H in F_H_matrices]\n",
    "\n",
    "(train_input_F_H_0dB, valid_input_F_H_0dB, test_input_F_H_0dB, test_data_F_H_0dB), \\\n",
    "(train_input_F_H_10dB, valid_input_F_H_10dB, test_input_F_H_10dB, test_data_F_H_10dB), \\\n",
    "(train_input_F_H_20dB, valid_input_F_H_20dB, test_input_F_H_20dB, test_data_F_H_20dB), \\\n",
    "(train_input_F_H_30dB, valid_input_F_H_30dB, test_input_F_H_30dB, test_data_F_H_30dB), \\\n",
    "(train_input_F_H_40dB, valid_input_F_H_40dB, test_input_F_H_40dB, test_data_F_H_40dB) = splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of p_hat vectors\n",
    "# p_hat_vectors = [p_hat_0dB, p_hat_10dB, p_hat_20dB, p_hat_30dB, p_hat_40dB]\n",
    "\n",
    "# # Split each vector and assign the results to corresponding variables\n",
    "# p_hat_splits = [split(p_hat) for p_hat in p_hat_vectors]\n",
    "\n",
    "# (train_input_p_hat_0dB, valid_input_p_hat_0dB, test_input_p_hat_0dB, test_data_p_hat_0dB), \\\n",
    "# (train_input_p_hat_10dB, valid_input_p_hat_10dB, test_input_p_hat_10dB, test_data_p_hat_10dB), \\\n",
    "# (train_input_p_hat_20dB, valid_input_p_hat_20dB, test_input_p_hat_20dB, test_data_p_hat_20dB), \\\n",
    "# (train_input_p_hat_30dB, valid_input_p_hat_30dB, test_input_p_hat_30dB, test_data_p_hat_30dB), \\\n",
    "# (train_input_p_hat_40dB, valid_input_p_hat_40dB, test_input_p_hat_40dB, test_data_p_hat_40dB) = p_hat_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of sizes and dB levels\n",
    "sizes = [F_H_0dB_size, F_H_10dB_size, F_H_20dB_size, F_H_30dB_size, F_H_40dB_size]\n",
    "dB_levels = [0, 10, 20, 30, 40]\n",
    "\n",
    "# Create EsN0 arrays and reshape into vectors using TensorFlow\n",
    "EsN0_arrays = [tf.fill([size, 1], dB) for size, dB in zip(sizes, dB_levels)]\n",
    "\n",
    "# Unpack into variables\n",
    "(EsN0_vector_0dB, EsN0_vector_10dB, EsN0_vector_20dB, \n",
    " EsN0_vector_30dB, EsN0_vector_40dB) = EsN0_arrays\n",
    "\n",
    "# Print shapes of the vectors\n",
    "print(EsN0_vector_0dB.shape)\n",
    "print(EsN0_vector_10dB.shape)\n",
    "print(EsN0_vector_20dB.shape)\n",
    "print(EsN0_vector_30dB.shape)\n",
    "print(EsN0_vector_40dB.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10]\n",
      " [10]\n",
      " [10]\n",
      " ...\n",
      " [10]\n",
      " [10]\n",
      " [10]], shape=(250000, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(EsN0_vector_10dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split EsN0 vector for training, validation, and testing\n",
    "def split_EsN0(tf_vector):\n",
    "    # Define fixed sizes for training, validation, and testing datasets\n",
    "    train_data_size = 200000\n",
    "    valid_data_size = 25000\n",
    "    test_data_size = 25000\n",
    "\n",
    "    # Calculate indices for slicing\n",
    "    train_e_indx = train_data_size\n",
    "    valid_e_indx = train_e_indx + valid_data_size\n",
    "    test_e_indx = valid_e_indx + test_data_size\n",
    "\n",
    "    # Slice the tensor directly into training, validation, and testing datasets using TensorFlow\n",
    "    train_data = tf.reshape(tf_vector[:train_e_indx], (train_data_size, -1, 1))\n",
    "    valid_data = tf.reshape(tf_vector[train_e_indx:valid_e_indx], (valid_data_size, -1, 1))\n",
    "    test_data = tf.reshape(tf_vector[valid_e_indx:test_e_indx], (test_data_size, -1, 1))\n",
    "\n",
    "    # Calculate the absolute values (if needed)\n",
    "    train_input = tf.abs(train_data)\n",
    "    valid_input = tf.abs(valid_data)\n",
    "    test_input = tf.abs(test_data)\n",
    "\n",
    "    # Print shapes to verify correctness\n",
    "    print(train_input.shape, valid_input.shape, test_input.shape)\n",
    "\n",
    "    # Return the split datasets\n",
    "    return [train_input, valid_input, test_input, test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of EsN0 vectors\n",
    "EsN0_vectors = [EsN0_vector_0dB, EsN0_vector_10dB, EsN0_vector_20dB, EsN0_vector_30dB, EsN0_vector_40dB]\n",
    "\n",
    "# Split each EsN0 vector\n",
    "EsN0_splits = [split_EsN0(EsN0) for EsN0 in EsN0_vectors]\n",
    "\n",
    "# Unpack the split results into corresponding variables\n",
    "(train_input_EsN0_0dB, valid_input_EsN0_0dB, test_input_EsN0_0dB, test_data_EsN0_0dB), \\\n",
    "(train_input_EsN0_10dB, valid_input_EsN0_10dB, test_input_EsN0_10dB, test_data_EsN0_10dB), \\\n",
    "(train_input_EsN0_20dB, valid_input_EsN0_20dB, test_input_EsN0_20dB, test_data_EsN0_20dB), \\\n",
    "(train_input_EsN0_30dB, valid_input_EsN0_30dB, test_input_EsN0_30dB, test_data_EsN0_30dB), \\\n",
    "(train_input_EsN0_40dB, valid_input_EsN0_40dB, test_input_EsN0_40dB, test_data_EsN0_40dB) = EsN0_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 5, 5)\n",
      "(1000000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of input arrays for F_H and EsN0\n",
    "train_inputs_F_H = [train_input_F_H_0dB, train_input_F_H_10dB, \n",
    "                    train_input_F_H_20dB, train_input_F_H_30dB, \n",
    "                    train_input_F_H_40dB]\n",
    "\n",
    "train_inputs_EsN0 = [train_input_EsN0_0dB, train_input_EsN0_10dB, \n",
    "                     train_input_EsN0_20dB, train_input_EsN0_30dB, \n",
    "                     train_input_EsN0_40dB]\n",
    "\n",
    "# Stack the datasets vertically using TensorFlow's tf.concat\n",
    "train_input_F_H = tf.concat(train_inputs_F_H, axis=0)\n",
    "train_input_EsN0 = tf.concat(train_inputs_EsN0, axis=0)\n",
    "\n",
    "# Print shapes to verify correctness\n",
    "print(train_input_F_H.shape)\n",
    "print(train_input_EsN0.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 5, 5)\n",
      "(125000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of validation input arrays for F_H and EsN0\n",
    "valid_inputs_F_H = [valid_input_F_H_0dB, valid_input_F_H_10dB, \n",
    "                    valid_input_F_H_20dB, valid_input_F_H_30dB, \n",
    "                    valid_input_F_H_40dB]\n",
    "\n",
    "valid_inputs_EsN0 = [valid_input_EsN0_0dB, valid_input_EsN0_10dB, \n",
    "                     valid_input_EsN0_20dB, valid_input_EsN0_30dB, \n",
    "                     valid_input_EsN0_40dB]\n",
    "\n",
    "# Stack the datasets vertically using TensorFlow's tf.concat\n",
    "valid_input_F_H = tf.concat(valid_inputs_F_H, axis=0)\n",
    "valid_input_EsN0 = tf.concat(valid_inputs_EsN0, axis=0)\n",
    "\n",
    "# Print shapes to verify correctness\n",
    "print(valid_input_F_H.shape)\n",
    "print(valid_input_EsN0.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the training datasets using TensorFlow\n",
    "train_shuffler = tf.random.shuffle(tf.range(tf.shape(train_input_F_H)[0]))\n",
    "\n",
    "train_input_F_H_shuffled = tf.gather(train_input_F_H, train_shuffler)\n",
    "train_input_EsN0_shuffled = tf.gather(train_input_EsN0, train_shuffler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the validation datasets using TensorFlow\n",
    "valid_shuffler = tf.random.shuffle(tf.range(tf.shape(valid_input_F_H)[0]))\n",
    "\n",
    "valid_input_F_H_shuffled = tf.gather(valid_input_F_H, valid_shuffler)\n",
    "valid_input_EsN0_shuffled = tf.gather(valid_input_EsN0, valid_shuffler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1000000       1      26], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "const = K * K\n",
    "len1 = tf.shape(train_input_F_H_shuffled)[0]\n",
    "\n",
    "# Reshape train_input_F_H_shuffled using TensorFlow's reshape function\n",
    "train_input_F_H_shuffled_reshaped = tf.reshape(train_input_F_H_shuffled, (len1, 1, const))  # size X row X column\n",
    "\n",
    "# Ensure both tensors are of the same type, e.g., float32\n",
    "train_input_F_H_shuffled_reshaped = tf.cast(train_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "train_input_EsN0_shuffled = tf.cast(train_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# Remove the dimension of size 1 in the middle\n",
    "#train_y_true = tf.squeeze(train_y_true, axis=1)\n",
    "\n",
    "# Print the shape of the result\n",
    "print(tf.shape(train_y_true))  # Expected output: [1000000, 26]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 1, 25)\n",
      "(1000000, 1, 1)\n",
      "(1000000, 1, 26)\n"
     ]
    }
   ],
   "source": [
    "print(train_input_F_H_shuffled_reshaped.shape)\n",
    "print(train_input_EsN0_shuffled.shape)\n",
    "print(train_y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constants\n",
    "# const = K * K\n",
    "# len1 = tf.shape(train_input_F_H_shuffled)[0]\n",
    "\n",
    "# # Reshape train_input_F_H_shuffled using TensorFlow's reshape function\n",
    "# train_input_F_H_shuffled_reshaped = tf.reshape(train_input_F_H_shuffled, (len1, 1, const))  # size X row X column\n",
    "\n",
    "# # Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "# train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# # Print the shape of the result\n",
    "# print(tf.shape(train_y_true))\n",
    "\n",
    "# # Ensure both tensors are of the same type, e.g., float32\n",
    "# train_input_F_H_shuffled_reshaped = tf.cast(train_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "# train_input_EsN0_shuffled = tf.cast(train_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# # Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "# train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# # Print the shape of the result\n",
    "# print(tf.shape(train_y_true))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([125000      1     26], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Reshape valid_input_F_H_shuffled\n",
    "len2 = tf.shape(valid_input_F_H_shuffled)[0]\n",
    "\n",
    "# Reshape using TensorFlow\n",
    "valid_input_F_H_shuffled_reshaped = tf.reshape(valid_input_F_H_shuffled, [len2, 1, const])  # size X row X column\n",
    "\n",
    "# Ensure both tensors are of the same data type, for example, float32\n",
    "valid_input_F_H_shuffled_reshaped = tf.cast(valid_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "valid_input_EsN0_shuffled = tf.cast(valid_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# Concatenate reshaped F_H and EsN0 inputs using TensorFlow\n",
    "valid_y_true = tf.concat([valid_input_F_H_shuffled_reshaped, valid_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "#valid_y_true = tf.squeeze(valid_y_true, axis=1) \n",
    "\n",
    "# Print the shape of the result using TensorFlow\n",
    "print(tf.shape(valid_y_true))\n",
    "\n",
    "#print(valid_y_true.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 1, 25)\n",
      "(125000, 1, 1)\n",
      "(125000, 1, 26)\n"
     ]
    }
   ],
   "source": [
    "print(valid_input_F_H_shuffled_reshaped.shape)\n",
    "print(valid_input_EsN0_shuffled.shape)\n",
    "print(valid_y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Functional_Api\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " hij_inputs (InputLayer)        [(None, 5, 5)]       0           []                               \n",
      "                                                                                                  \n",
      " EsN0_inputs (InputLayer)       [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " flatten_layer_hij (Flatten)    (None, 25)           0           ['hij_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " Flatten_Layer_EsN0 (Flatten)   (None, 1)            0           ['EsN0_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 26)           0           ['flatten_layer_hij[0][0]',      \n",
      "                                                                  'Flatten_Layer_EsN0[0][0]']     \n",
      "                                                                                                  \n",
      " Dense_layer_1 (Dense)          (None, 50)           1350        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " BN_Layer_1 (BatchNormalization  (None, 50)          200         ['Dense_layer_1[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Dense_Layer_2 (Dense)          (None, 25)           1275        ['BN_Layer_1[0][0]']             \n",
      "                                                                                                  \n",
      " BN_Layer_2 (BatchNormalization  (None, 25)          100         ['Dense_Layer_2[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " P_hat (Dense)                  (None, 5)            130         ['BN_Layer_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,055\n",
      "Trainable params: 2,905\n",
      "Non-trainable params: 150\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define the DNN model - The Functional API\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "hij_inputs = keras.Input(shape=(K,K), name = \"hij_inputs\")\n",
    "Flatten_1 = layers.Flatten(name = \"flatten_layer_hij\")(hij_inputs)\n",
    "\n",
    "EsN0_inputs = keras.Input(shape=(1,1), name = \"EsN0_inputs\")\n",
    "Flatten_2 = layers.Flatten(name = \"Flatten_Layer_EsN0\")(EsN0_inputs)\n",
    "\n",
    "concat_layers = concatenate([Flatten_1, Flatten_2])\n",
    "\n",
    "Dense_1 = layers.Dense(2*K*K, activation=\"relu\", name = \"Dense_layer_1\")(concat_layers)\n",
    "BN_1 = layers.BatchNormalization(name = \"BN_Layer_1\")(Dense_1)\n",
    "\n",
    "Dense_2 = layers.Dense(K*K, activation=\"relu\", name = \"Dense_Layer_2\")(BN_1)\n",
    "BN_2 = layers.BatchNormalization(name = \"BN_Layer_2\")(Dense_2)\n",
    "\n",
    "P_hat = layers.Dense(K, activation=\"sigmoid\", name = \"P_hat\")(BN_2)\n",
    "\n",
    "model = keras.Model(inputs = [hij_inputs, EsN0_inputs], outputs = P_hat, name = \"Functional_Api\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "## Convert SINR_P_min from numpy array to tensor\n",
    "SINR_P_min_t = tf.convert_to_tensor(SINR_P_min, dtype = float)\n",
    "tf.print(SINR_P_min_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A_tilda(A, K):\n",
    "    # Identity matrix of size K x K\n",
    "    I = tf.eye(K)\n",
    "    \n",
    "    # Negative identity matrix\n",
    "    neg_I = -I\n",
    "\n",
    "    # Repeat the identity and negative identity across batch dimension (1000)\n",
    "    I_batch = tf.tile(tf.expand_dims(I, axis=0), [A.shape[0], 1, 1])\n",
    "    neg_I_batch = tf.tile(tf.expand_dims(neg_I, axis=0), [A.shape[0], 1, 1])\n",
    "\n",
    "    # Concatenate I, -I, and A to form A_tilda\n",
    "    A_tilda = tf.concat([I_batch, neg_I_batch, A], axis=1)\n",
    "\n",
    "    return A_tilda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 5)\n"
     ]
    }
   ],
   "source": [
    "print(A_tilda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_B_tilda(B, K):\n",
    "    # Zero vector of size K\n",
    "    zeros = tf.zeros_like(B)\n",
    "    ones = tf.ones_like(B) * -PMax\n",
    "\n",
    "    # Reshape B to match the required dimensions\n",
    "    B_reshaped = tf.reshape(B, (-1, K, 1))\n",
    "\n",
    "    # Concatenate zeros and B to form B_tilda\n",
    "    B_tilda = tf.concat([zeros, ones, B_reshaped], axis=1)\n",
    "\n",
    "    return B_tilda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "print(B_tilda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_A_tilda(A_tilda):\n",
    "    return tf.transpose(A_tilda, perm=[0, 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 15)\n"
     ]
    }
   ],
   "source": [
    "print(A_tilda_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized loss function that penalizes the constraint violation\n",
    "def custom_loss_DC3(y_true, y_pred):\n",
    "    # Multiply predicted values by p_max\n",
    "    p = tf.multiply(PMax, y_pred)\n",
    "    p = tf.reshape(p, (-1, K, 1))\n",
    "\n",
    "\n",
    "\n",
    "    # Extract EsN0 value and reshape y_true to exclude EsN0 column\n",
    "    mtrx_elmnt = K * K\n",
    "    EsN0_val = y_true[:, 0, mtrx_elmnt]\n",
    "    y_true_updt = y_true[:, :, :-1]\n",
    "\n",
    "    # Determine noise variance based on EsN0 value\n",
    "    sigma_sqr_noise_lf = tf.where(EsN0_val < 10, 1e-0,\n",
    "                                  tf.where(EsN0_val < 20, 1e-1,\n",
    "                                          tf.where(EsN0_val < 30, 1e-2,\n",
    "                                                    tf.where(EsN0_val < 40, 1e-3, 1e-4))))\n",
    "\n",
    "    # Reshape y_true to form hij matrix and calculate squared magnitudes\n",
    "    hij = tf.reshape(y_true_updt[:, 0:K*K], (-1, K, K))\n",
    "    hij_abs_sqr = tf.square(tf.abs(hij))\n",
    "\n",
    "\n",
    "\n",
    "    ## Create matrix A\n",
    "    A = generate_A(hij.shape[0], K, SINR_P_min, hij)\n",
    "    b = generate_b(hij.shape[0], K, SINR_P_min, sigma_sqr_noise_0dB, hij)\n",
    "    \n",
    "    B = tf.reshape(b, (-1, K, 1))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Define A_tilda, b_tilda, A_transpose_tilda\n",
    "    ## Compute A_tilda and B_tilda\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(B, K)\n",
    "\n",
    "    ## Transpose A_tilda\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    # Gradient Descent for Correction\n",
    "    for i in range(100):\n",
    "      # V = tf.linalg.matmul(A_tilda , p )  - b_tilda\n",
    "      V = B_tilda - tf.matmul(A_tilda, p)\n",
    "      V_relu = tf.nn.relu(V)\n",
    "      gd   = -2 * tf.matmul( A_tilda_T ,V_relu)\n",
    "      p = p - learning_rate * gd\n",
    "    \n",
    "    p = tf.nn.relu(p)\n",
    "\n",
    "    \n",
    "    # # Calculate interference and SINR for each transmitter-receiver pair\n",
    "    #ph = tf.reduce_sum(tf.multiply(p[:, tf.newaxis], hij_abs_sqr), axis=2)  # Interference + noise\n",
    "\n",
    "    ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr), axis=2) \n",
    "    diag_part_expanded = tf.expand_dims(tf.linalg.diag_part(hij_abs_sqr), axis=-1)\n",
    "    numr = tf.multiply(p, diag_part_expanded)  # Signal power (numerator)\n",
    "    sigma_sqr_noise_lf_expanded = tf.expand_dims(sigma_sqr_noise_lf, axis=-1)\n",
    "    dnumr = sigma_sqr_noise_lf_expanded + ph - tf.squeeze(numr, axis=-1)\n",
    "    SINR_i = tf.divide(tf.squeeze(numr, axis=-1), dnumr)\n",
    "    \n",
    "    #numr = tf.multiply(p, tf.linalg.diag_part(hij_abs_sqr))  # Signal power (numerator)\n",
    "    #dnumr = sigma_sqr_noise_lf[:, tf.newaxis] + ph - numr  # Denominator of SINR\n",
    "    #SINR_i = tf.divide(numr, dnumr)  # SINR values\n",
    "    R_P = tf.reduce_sum(tf.math.log(1 + SINR_i) / tf.math.log(2.0), axis=1)  # Sum rate\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  # p1 = tf.reshape(p, (-1, K, 1))\n",
    "\n",
    "    w = p - PMax\n",
    "    \n",
    "    A_p = tf.matmul(A, p)\n",
    "\n",
    "    #B = tf.reshape(b, (-1, K, 1))\n",
    "  \n",
    "    s = B - A_p\n",
    "    \n",
    "    #Ex\n",
    "    # tf.print(w.shape)\n",
    "    # tf.print(s.shape)\n",
    "    # tf.print(A.shape)\n",
    "    # tf.print(b.shape)\n",
    "    # tf.print(B.shape)\n",
    "    # tf.print(p.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # Apply ReLU to the constraint violation\n",
    "    constraint_violation = tf.nn.relu(tf.concat([-p, w, s],axis=1))\n",
    "    \n",
    "    # L2 norm of the constraint violation\n",
    "    penalty_term = tf.reduce_sum(tf.square(constraint_violation), axis=1)  # ||ReLU(gx(y))||^2\n",
    "\n",
    "\n",
    "    # Final loss calculation\n",
    "\n",
    "    # lambda_l = 5.0\n",
    "    lambda_l = 10.0\n",
    "    # lambda_l = 15.0\n",
    "    # lambda_l = 20.0\n",
    "    # lambda_l = 25.0\n",
    "\n",
    "    loss = -R_P + lambda_l * penalty_term\n",
    "    return tf.reduce_mean(loss)  # Batch mean loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss_DC3(y_true, y_pred):\n",
    "#     # Multiply predicted values by PMax\n",
    "#     p = tf.multiply(PMax, y_pred)  # p: [batch_size, K, 1]\n",
    "#     p = tf.reshape(p, (-1, K, 1))  # Ensure p has shape [batch_size, K, 1]\n",
    "\n",
    "#     eta = 1e-3\n",
    "\n",
    "#     # Extract EsN0 value and reshape y_true to exclude EsN0 column\n",
    "#     mtrx_elmnt = K * K\n",
    "#     EsN0_val = y_true[:, 0, mtrx_elmnt]\n",
    "#     y_true_updt = y_true[:, :, :-1]\n",
    "\n",
    "#     # Determine noise variance based on EsN0 value\n",
    "#     sigma_sqr_noise_lf = tf.where(\n",
    "#         EsN0_val < 10, 1e-0,\n",
    "#         tf.where(EsN0_val < 20, 1e-1,\n",
    "#                  tf.where(EsN0_val < 30, 1e-2,\n",
    "#                           tf.where(EsN0_val < 40, 1e-3, 1e-4))))\n",
    "#     sigma_sqr_noise_lf = tf.reshape(sigma_sqr_noise_lf, (-1, 1, 1))  # Shape: [batch_size, 1, 1]\n",
    "\n",
    "#     # Reshape y_true to form hij matrix and calculate squared magnitudes\n",
    "#     hij = tf.reshape(y_true_updt[:, 0:K*K], (-1, K, K))  # Shape: [batch_size, K, K]\n",
    "#     hij_abs_sqr = tf.square(tf.abs(hij))  # Shape: [batch_size, K, K]\n",
    "\n",
    "#     # Generate matrices A and b (assuming these functions are defined)\n",
    "#     A = generate_A(hij.shape[0], K, SINR_P_min, hij)\n",
    "#     b = generate_b(hij.shape[0], K, SINR_P_min, sigma_sqr_noise_0dB, hij)\n",
    "\n",
    "#     # Define A_tilda, b_tilda, A_transpose_tilda\n",
    "#     A_tilda = generate_A_tilda(A, K)\n",
    "#     B_tilda = generate_B_tilda(b, K)\n",
    "#     A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "#     # Gradient Descent for Correction\n",
    "#     for i in range(5):\n",
    "#         V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "#         V_relu = tf.nn.relu(V)\n",
    "#         gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)\n",
    "#         p = p + eta * gd\n",
    "\n",
    "#     # Ensure p remains of shape [batch_size, K, 1]\n",
    "\n",
    "#     # Compute ph (Interference + noise)\n",
    "#     p_expanded = tf.expand_dims(p, axis=1)  # Shape: [batch_size, 1, K, 1]\n",
    "#     hij_abs_sqr_expanded = tf.expand_dims(hij_abs_sqr, axis=-1)  # Shape: [batch_size, K, K, 1]\n",
    "\n",
    "#     # Multiply p and hij_abs_sqr\n",
    "#     ph_intermediate = tf.multiply(p_expanded, hij_abs_sqr_expanded)  # Shape: [batch_size, K, K, 1]\n",
    "#     ph = tf.reduce_sum(ph_intermediate, axis=2)  # Sum over interfering users; shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute numr (Signal power numerator)\n",
    "#     diag_hij_abs_sqr = tf.linalg.diag_part(hij_abs_sqr)  # Shape: [batch_size, K]\n",
    "#     diag_hij_abs_sqr = tf.expand_dims(diag_hij_abs_sqr, axis=-1)  # Shape: [batch_size, K, 1]\n",
    "#     numr = tf.multiply(p, diag_hij_abs_sqr)  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute dnumr (Denominator of SINR)\n",
    "#     dnumr = sigma_sqr_noise_lf + ph - numr  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute SINR\n",
    "#     SINR_i = tf.divide(numr, dnumr)  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute sum rate R_P\n",
    "#     R_P = tf.reduce_sum(tf.math.log(1 + SINR_i) / tf.math.log(2.0), axis=1)  # Shape: [batch_size, 1]\n",
    "\n",
    "#     # Constraint terms\n",
    "#     w = PMax - p  # Shape: [batch_size, K, 1]\n",
    "#     A_p = tf.linalg.matmul(A, p)  # Ensure A is of shape [batch_size, K, K], p: [batch_size, K, 1]; result: [batch_size, K, 1]\n",
    "#     s = b - A_p  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Apply ReLU to the constraint violation\n",
    "#     constraint_violation = tf.nn.relu(tf.concat([p, w, s], axis=1))  # Shape: [batch_size, 3*K, 1]\n",
    "\n",
    "#     # L2 norm of the constraint violation\n",
    "#     penalty_term = tf.reduce_sum(tf.square(constraint_violation), axis=[1, 2])  # Shape: [batch_size]\n",
    "\n",
    "#     # Final loss calculation\n",
    "#     lambda_l = 10.0\n",
    "#     loss = -R_P[:, 0] + lambda_l * penalty_term  # Shape: [batch_size]\n",
    "#     return tf.reduce_mean(loss)  # Batch mean loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 289s 289ms/step - loss: -1.2893 - val_loss: -1.6249\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 298s 298ms/step - loss: -1.7457 - val_loss: -1.8034\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.8291 - val_loss: -1.8404\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 303s 303ms/step - loss: -1.8439 - val_loss: -1.8515\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 305s 305ms/step - loss: -1.8576 - val_loss: -1.8671\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 307s 307ms/step - loss: -1.8727 - val_loss: -1.8821\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 307s 307ms/step - loss: -1.8888 - val_loss: -1.9002\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 308s 308ms/step - loss: -1.9074 - val_loss: -1.9166\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 308s 308ms/step - loss: -1.9203 - val_loss: -1.9265\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 303s 303ms/step - loss: -1.9295 - val_loss: -1.9364\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 304s 304ms/step - loss: -1.9383 - val_loss: -1.9451\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 303s 303ms/step - loss: -1.9459 - val_loss: -1.9512\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 303s 303ms/step - loss: -1.9508 - val_loss: -1.9563\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 302s 302ms/step - loss: -1.9544 - val_loss: -1.9583\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 303s 303ms/step - loss: -1.9573 - val_loss: -1.9620\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 302s 302ms/step - loss: -1.9599 - val_loss: -1.9642\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.9622 - val_loss: -1.9668\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.9642 - val_loss: -1.9673\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.9660 - val_loss: -1.9706\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.9676 - val_loss: -1.9722\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 303s 303ms/step - loss: -1.9692 - val_loss: -1.9731\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9705 - val_loss: -1.9744\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 302s 302ms/step - loss: -1.9719 - val_loss: -1.9760\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.9731 - val_loss: -1.9776\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9742 - val_loss: -1.9784\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9756 - val_loss: -1.9798\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.9768 - val_loss: -1.9809\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 298s 298ms/step - loss: -1.9778 - val_loss: -1.9820\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9788 - val_loss: -1.9824\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 298s 298ms/step - loss: -1.9799 - val_loss: -1.9832\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 298s 298ms/step - loss: -1.9809 - val_loss: -1.9843\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9817 - val_loss: -1.9857\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 298s 298ms/step - loss: -1.9827 - val_loss: -1.9861\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9836 - val_loss: -1.9870\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9844 - val_loss: -1.9884\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9854 - val_loss: -1.9889\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9865 - val_loss: -1.9901\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9874 - val_loss: -1.9910\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9883 - val_loss: -1.9921\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 298s 298ms/step - loss: -1.9894 - val_loss: -1.9927\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9902 - val_loss: -1.9939\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9909 - val_loss: -1.9933\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9916 - val_loss: -1.9954\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: -1.9924 - val_loss: -1.9959\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9930 - val_loss: -1.9969\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9937 - val_loss: -1.9965\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: -1.9945 - val_loss: -1.9982\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: -1.9951 - val_loss: -1.9986\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 294s 294ms/step - loss: -1.9960 - val_loss: -1.9997\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 294s 294ms/step - loss: -1.9966 - val_loss: -1.9999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Build and compile the DNN model\n",
    "## Training and Testing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Opt_Adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer = Opt_Adam, loss = custom_loss_DC3)\n",
    "\n",
    "train_input = [train_input_F_H_shuffled, train_input_EsN0_shuffled]\n",
    "valid_input = [valid_input_F_H_shuffled, valid_input_EsN0_shuffled]\n",
    "\n",
    "history = model.fit(train_input, train_y_true, epochs = 50,\n",
    "                    validation_data = (valid_input, valid_y_true), batch_size = 1000)\n",
    "\n",
    "plt.plot(history.epoch, history.history['loss'], color = \"blue\", label = \"Training\")\n",
    "plt.plot(history.epoch, history.history['val_loss'], color=\"black\", label = \"Validation\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17280\\2631559221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Iterate over each user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhij_abs_sqr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Interference + noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mnumr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhij_abs_sqr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Signal power (numerator)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mdnumr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigma_sqr_noise_0dB_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mph\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnumr\u001b[0m  \u001b[1;31m# Denominator of SINR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mSINR_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnumr\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Compute SINR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\essay\\anaconda3\\envs\\bin\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\essay\\anaconda3\\envs\\bin\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7208\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7209\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "# Test data setup\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))  # Predicted power allocation\n",
    "output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], K, 1))  # Reshape to [num_samples, K, 1]\n",
    "output_P_hat_size = tf.shape(output_P_hat)[0]  # Number of samples\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)  # Compute squared magnitude of hij\n",
    "\n",
    "eta = 1e-3  # Learning rate for gradient descent\n",
    "indx_n = []  # List to store indices of samples with constraint violations\n",
    "count_v = 0  # Counter for total violations\n",
    "\n",
    "# Iterate over each test sample\n",
    "for k in range(output_P_hat_size):\n",
    "    p = output_P_hat[k]  # Initial power vector for this sample, shape [K, 1]\n",
    "    hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample, shape [K, K]\n",
    "    sigma_sqr_noise_0dB_sample = sigma_sqr_noise_0dB  # Use constant noise variance for all samples\n",
    "\n",
    "    # Ensure consistent data types\n",
    "    p = tf.cast(p, dtype=tf.float32)\n",
    "    hij_abs_sqr = tf.cast(hij_abs_sqr, dtype=tf.float32)\n",
    "    sigma_sqr_noise_0dB_sample = tf.cast(sigma_sqr_noise_0dB_sample, dtype=tf.float32)\n",
    "    SINR_P_min = tf.cast(SINR_P_min, dtype=tf.float32)\n",
    "\n",
    "    # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "    A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "    b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB_sample, hij_abs_sqr)\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(b, K)\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    # Perform gradient descent for 5 iterations\n",
    "    for i in range(100):\n",
    "        V = B_tilda - tf.matmul(A_tilda, p)\n",
    "        V_relu = tf.nn.relu(V)  # Apply ReLU to the result\n",
    "        gd = -2 * tf.matmul(A_tilda_T, V_relu)  # Gradient descent update\n",
    "        p = p + eta * gd  # Update power allocation\n",
    "\n",
    "    # Check for SINR constraint violations after applying gradient descent\n",
    "    for i in range(K):  # Iterate over each user\n",
    "        ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr[i, :]))  # Interference + noise\n",
    "        numr = tf.multiply(p[i], hij_abs_sqr[i, i])  # Signal power (numerator)\n",
    "        dnumr = sigma_sqr_noise_0dB_sample[i] + ph - numr  # Denominator of SINR\n",
    "        SINR_out = tf.divide(numr, dnumr)  # Compute SINR\n",
    "\n",
    "        # Round SINR to 3 decimal places and check for violations\n",
    "        SINR_out_rounded = tf.round(SINR_out * 1000) / 1000\n",
    "\n",
    "        # Perform element-wise comparison and reduce to check for any violations\n",
    "        violation = tf.reduce_any(SINR_out_rounded < SINR_P_min[i])\n",
    "        if violation:\n",
    "            indx_n.append(k)  # Store index of sample with violation\n",
    "            count_v += 1  # Increment violation counter\n",
    "            break  # Stop checking further users for this sample\n",
    "\n",
    "# Calculate violation probability\n",
    "violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data setup\n",
    "# test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "# output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))  # Predicted power allocation\n",
    "# output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], K, 1))  # Reshape to [num_samples, K, 1]\n",
    "# output_P_hat_size = tf.shape(output_P_hat)[0]  # Number of samples\n",
    "# test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)  # Compute squared magnitude of hij\n",
    "\n",
    "# eta = 1e-3  # Learning rate for gradient descent\n",
    "# indx_n = []  # List to store indices of samples with constraint violations\n",
    "# count_v = 0  # Counter for total violations\n",
    "\n",
    "# # Iterate over each test sample\n",
    "# for k in range(output_P_hat_size):\n",
    "#     p = output_P_hat[k]  # Initial power vector for this sample, shape [K, 1]\n",
    "#     hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample, shape [K, K]\n",
    "#     sigma_sqr_noise_0dB_sample = sigma_sqr_noise_0dB[k]  # Noise variance for this sample\n",
    "\n",
    "\n",
    "#     # Ensure consistent data types\n",
    "#     p = tf.cast(p, dtype=tf.float32)  # Already float32, but ensuring consistency\n",
    "#     hij_abs_sqr = tf.cast(hij_abs_sqr, dtype=tf.float32)  # Cast to float32\n",
    "#     sigma_sqr_noise_0dB_sample = tf.cast(sigma_sqr_noise_0dB_sample, dtype=tf.float32)  # Cast to float32\n",
    "\n",
    "\n",
    "#     # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "#     A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "#     b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB, hij_abs_sqr)\n",
    "#     A_tilda = generate_A_tilda(A, K)\n",
    "#     B_tilda = generate_B_tilda(b, K)\n",
    "#     A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "#     # Perform gradient descent for 5 iterations\n",
    "#     for i in range(5):\n",
    "#         V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "#         V_relu = tf.nn.relu(V)  # Apply ReLU to the result\n",
    "#         gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)  # Gradient descent update\n",
    "#         p = p + eta * gd  # Update power allocation\n",
    "\n",
    "#     # Check for SINR constraint violations after applying gradient descent\n",
    "#     for i in range(K):  # Iterate over each user\n",
    "#         ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr[i, :]))  # Interference + noise\n",
    "#         numr = tf.multiply(p[i], hij_abs_sqr[i, i])  # Signal power (numerator)\n",
    "#         dnumr = sigma_sqr_noise_0dB[i] + ph - numr  # Denominator of SINR\n",
    "#         SINR_out = tf.divide(numr, dnumr)  # Compute SINR\n",
    "\n",
    "#         # # Check if SINR is below the minimum required value\n",
    "#         if tf.round(SINR_out, decimals=3) < SINR_P_min[i]:\n",
    "#             indx_n.append(k)  # Store index of sample with violation\n",
    "#             count_v += 1  # Increment violation counter\n",
    "#             break  # Stop checking further users for this sample\n",
    "\n",
    "# # Calculate violation probability\n",
    "# violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "# print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Updated test code in TensorFlow to apply gradient descent on test data\n",
    "\n",
    "# test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "# output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))\n",
    "# output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], tf.shape(output_P_hat_temp)[1], 1)) # test_input_F_H_size X row X column\n",
    "# output_P_hat_size = tf.shape(output_P_hat)[0]\n",
    "# test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)\n",
    "\n",
    "# eta = 1e-3  # Same learning rate used in the gradient descent\n",
    "\n",
    "# indx_n = []\n",
    "# count_v = 0\n",
    "\n",
    "# for k in range(output_P_hat_size):\n",
    "#     p = output_P_hat[k]  # Initial power vector for this sample\n",
    "#     hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample\n",
    "\n",
    "#     # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "#     A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "#     b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB, hij_abs_sqr)\n",
    "#     A_tilda = generate_A_tilda(A, K)\n",
    "#     B_tilda = generate_B_tilda(b, K)\n",
    "#     A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "#     # Perform gradient descent on this sample\n",
    "#     for i in range(5):\n",
    "#         V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "#         V_relu = tf.nn.relu(V)  # ReLU operation\n",
    "#         gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)\n",
    "#         p = p + eta * gd  # Update the power allocation\n",
    "\n",
    "#     # Check for SINR constraint violations after applying gradient descent\n",
    "#     for i in range(K):  # Total rows\n",
    "#         ph = 0\n",
    "#         for j in range(K):  # Total columns\n",
    "#             ph_j = tf.multiply(p[j], hij_abs_sqr[i, j])\n",
    "#             ph = ph + ph_j\n",
    "\n",
    "#         numr = tf.multiply(p[i], hij_abs_sqr[i, i])\n",
    "#         dnumr = sigma_sqr_noise_0dB[i] + ph - numr\n",
    "#         SINR_out = tf.divide(numr, dnumr)\n",
    "\n",
    "#         # Check if the SINR is below the minimum required value\n",
    "#         if tf.round(SINR_out, decimals=3) < SINR_P_min[i]:\n",
    "#             indx_n.append(k)\n",
    "#             count_v += 1\n",
    "#             break\n",
    "\n",
    "# # Calculate violation probability\n",
    "# violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "# print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Constraint violation probability and\n",
    "# ## finding indexes of test_input_F_H matrix with the hij set that do not satisfy\n",
    "# ## constraint on the minimum SINR_P_min rate but satisfy the maximum transmit\n",
    "# ## power PMax\n",
    "\n",
    "# test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "# # output_P_hat_temp = model.predict(test_input)\n",
    "# output_P_hat_temp = np.multiply(PMax, model.predict(test_input))\n",
    "# output_P_hat = output_P_hat_temp.reshape((output_P_hat_temp.shape[0], output_P_hat_temp.shape[1], 1)) # test_input_F_H_size X row X column\n",
    "# output_P_hat_size = output_P_hat.shape[0]\n",
    "# test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)\n",
    "\n",
    "# indx_n = []\n",
    "# count_v = 0\n",
    "\n",
    "# for k in range(output_P_hat_size):\n",
    "#   for i in range(K):  # Total rows\n",
    "#     ph = 0\n",
    "#     for j in range(K):  # Total columns\n",
    "#       ph_j = np.multiply(output_P_hat[k,j], test_data_F_H_abs_sqr[k,i,j])\n",
    "#       ph = ph + ph_j\n",
    "\n",
    "#     numr = np.multiply(output_P_hat[k,i], test_data_F_H_abs_sqr[k,i,i])\n",
    "#     dnumr = sigma_sqr_noise_0dB[i] + ph - numr\n",
    "#     SINR_out = np.divide(numr, dnumr)\n",
    "\n",
    "#     if np.round(SINR_out, decimals= 3) < SINR_P_min[i]:\n",
    "#       indx_n.append(k)\n",
    "#       count_v = count_v + 1\n",
    "#       # print(SINR_out)\n",
    "#       break\n",
    "\n",
    "# violation_prb = (count_v / output_P_hat_size) * 100\n",
    "# print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n",
    "# # print(len(indx_n))\n",
    "# # print(indx_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate the average sum rate\n",
    "# Here, p_model is the output of DNN, and it is a 2D array.\n",
    "import math\n",
    "\n",
    "def average_sum_rate(hij, p_model, sigma_sqr_noise, K):\n",
    "  R = 0\n",
    "  hij_size = hij.shape[0]\n",
    "  hij_abs_sqr = cmplx_abs_sqr(hij)\n",
    "\n",
    "  for k in range(hij_size):\n",
    "    for i in range(K):  # Total rows\n",
    "      phn = 0\n",
    "      for j in range(K):  # Total columns\n",
    "        phn_j = np.multiply(p_model[k,j], hij_abs_sqr[k,i,j])\n",
    "        phn = phn + phn_j\n",
    "\n",
    "      numr_s = np.multiply(p_model[k,i], hij_abs_sqr[k,i,i])\n",
    "      dnumr_s = sigma_sqr_noise[i] + phn - numr_s\n",
    "      R_temp = math.log2(1 + np.divide(numr_s, dnumr_s))\n",
    "      R = R + R_temp\n",
    "\n",
    "  return (R/hij_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step\n",
      "Average Sum Rate for all H matrices: 1.922 Bit/Second/Hertz\n"
     ]
    }
   ],
   "source": [
    "## DNN Sum Rate for test_data_F_H\n",
    "sumrate_F_H = average_sum_rate(test_input[0], model.predict(test_input),sigma_sqr_noise_0dB, K)\n",
    "print(\"Average Sum Rate for all H matrices: {:.3f} Bit/Second/Hertz\".format(sumrate_F_H))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
