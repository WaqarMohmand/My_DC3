{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.api._v2.keras import layers\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import numba as nb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of transmitter-receiver pairs\n",
    "K = 5\n",
    "\n",
    "# Minimum rate for the achievable SINR of multiple concurrent transmissions\n",
    "SINR_P_min = tf.constant([0.2, 0.2, 0.2, 0.2, 0.2], dtype=tf.float32)\n",
    "\n",
    "# Maximum transmit power\n",
    "PMax = tf.constant(1.0, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variances for noise signals at different dB levels\n",
    "sigma_sqr_noise_0dB = np.full(5, 1e-0, dtype=float)\n",
    "sigma_sqr_noise_10dB = np.full(5, 1e-1, dtype=float)\n",
    "sigma_sqr_noise_20dB = np.full(5, 1e-2, dtype=float)\n",
    "sigma_sqr_noise_30dB = np.full(5, 1e-3, dtype=float)\n",
    "sigma_sqr_noise_40dB = np.full(5, 1e-4, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load and reshape the CSV files into 3D arrays\n",
    "def load_and_reshape(file_path, K):\n",
    "    # Load the CSV file as a 2D array\n",
    "    FH2D = loadtxt(file_path, delimiter=',', dtype=str)\n",
    "    \n",
    "    # Reshape the 2D array into a 3D array\n",
    "    FH3D = FH2D.reshape(FH2D.shape[0], -1, K)\n",
    "    \n",
    "    # Return the reshaped array and its size\n",
    "    return FH3D, FH3D.shape[0]\n",
    "\n",
    "# Loading and reshaping the arrays from CSV files\n",
    "FH3D_0dB, FH3D_0dB_size = load_and_reshape('F_H_2D_0dB_K5.csv', K=5)\n",
    "FH3D_10dB, FH3D_10dB_size = load_and_reshape('F_H_2D_10dB_K5.csv', K=5)\n",
    "FH3D_20dB, FH3D_20dB_size = load_and_reshape('F_H_2D_20dB_K5.csv', K=5)\n",
    "FH3D_30dB, FH3D_30dB_size = load_and_reshape('F_H_2D_30dB_K5.csv', K=5)\n",
    "FH3D_40dB, FH3D_40dB_size = load_and_reshape('F_H_2D_40dB_K5.csv', K=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert string data to complex data and remove initial whitespace using vectorized operations\n",
    "def cnvrt_2_cmplx_data(FH3D_size, FH3D):\n",
    "    # Use np.char.strip to remove initial whitespace from the entire 3D array\n",
    "    FH3D_stripped = np.char.strip(FH3D)\n",
    "    \n",
    "    # Convert the stripped string array to complex numbers using vectorized conversion\n",
    "    FHCmplx = FH3D_stripped.astype(np.complex_)\n",
    "    \n",
    "    # Reshape the array directly to the desired shape (H_size, K, K)\n",
    "    F_H = FHCmplx.reshape(FH3D_size, K, K)\n",
    "    \n",
    "    return F_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n",
      "(250000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "## Converting string data to complex data and removing the initial whitespace\n",
    "F_H_0dB = cnvrt_2_cmplx_data(FH3D_0dB_size, FH3D_0dB)\n",
    "F_H_10dB = cnvrt_2_cmplx_data(FH3D_10dB_size, FH3D_10dB)\n",
    "F_H_20dB = cnvrt_2_cmplx_data(FH3D_20dB_size, FH3D_20dB)\n",
    "F_H_30dB = cnvrt_2_cmplx_data(FH3D_30dB_size, FH3D_30dB)\n",
    "F_H_40dB = cnvrt_2_cmplx_data(FH3D_40dB_size, FH3D_40dB)\n",
    "\n",
    "print(F_H_0dB.shape)\n",
    "print(F_H_10dB.shape)\n",
    "print(F_H_20dB.shape)\n",
    "print(F_H_30dB.shape)\n",
    "print(F_H_40dB.shape)\n",
    "\n",
    "F_H_0dB_size = F_H_0dB.shape[0]\n",
    "F_H_10dB_size = F_H_10dB.shape[0]\n",
    "F_H_20dB_size = F_H_20dB.shape[0]\n",
    "F_H_30dB_size = F_H_30dB.shape[0]\n",
    "F_H_40dB_size = F_H_40dB.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.23631937+0.22921883j -0.54667901-0.20138914j\n",
      "   -0.47946164+0.498344j    0.3113009 -0.22798014j\n",
      "    0.69691993-0.88261167j]\n",
      "  [-0.14673233-0.67982819j  1.05716624-0.17533585j\n",
      "    1.40408283-0.3634557j  -0.01055404-0.70807464j\n",
      "   -0.25915166+0.60921694j]\n",
      "  [ 0.78419976-0.33361193j  0.40834267+1.0118874j\n",
      "   -0.96713008-0.16796663j -0.6647029 -0.7954383j\n",
      "    0.02752075-0.71561235j]\n",
      "  [ 0.3465332 -0.09099838j -0.4367235 +1.37334099j\n",
      "    0.7779833 +0.29038137j -0.05983818+0.77268389j\n",
      "    0.50615944-0.15630014j]\n",
      "  [ 0.53521481-0.13481686j  1.21080065-0.03027252j\n",
      "   -0.48457478+0.57532919j  0.01145698-0.21696277j\n",
      "    1.17455914+1.17218511j]]\n",
      "\n",
      " [[ 0.79699507+0.63304366j  0.01760131+0.32898345j\n",
      "    0.05801209+0.55645257j  0.38766506-0.43073101j\n",
      "   -0.45751618-0.60856057j]\n",
      "  [-0.26554943-0.92245427j -0.85025071+0.87457213j\n",
      "    0.29233821+0.99113017j -1.19413667-0.06657383j\n",
      "    0.12229737+0.16174348j]\n",
      "  [-0.10512262-1.25990919j -0.40637738-0.68602838j\n",
      "    0.01210378-1.02630839j  0.47588371-0.08603115j\n",
      "    0.09309989+0.11602879j]\n",
      "  [-0.22732738+0.79207634j -0.16634939-0.27815233j\n",
      "    1.24831871+0.01199174j  0.75898117-0.08660323j\n",
      "    0.81174366+0.45061337j]\n",
      "  [ 0.36262892-0.5270233j  -0.73321827-1.38334335j\n",
      "   -0.00912687+0.92046035j  1.20061156+0.09927137j\n",
      "   -0.14781791+0.99923613j]]\n",
      "\n",
      " [[-0.64804294+0.46525681j  0.16549187+0.47468413j\n",
      "   -0.20747958-0.17463521j  0.43210841-0.12210355j\n",
      "    0.65070062-0.36521428j]\n",
      "  [-0.56029947+1.25975985j -0.11264297+1.73582172j\n",
      "    0.39986776+1.24560395j  0.309937  +0.03050013j\n",
      "    0.02377968-0.09915411j]\n",
      "  [ 0.84955967-0.88454336j -1.06070152+0.40656115j\n",
      "    1.12302148-0.77515379j -1.24576166+0.02660652j\n",
      "    0.05830689-0.10745618j]\n",
      "  [-0.88447658+0.96005678j -0.03175394+0.58287616j\n",
      "   -0.17964543+0.72722242j -0.69696048+0.03552663j\n",
      "   -1.28187984-0.46384551j]\n",
      "  [-0.23177995+0.5015831j   0.09772908+1.59263317j\n",
      "    0.34319981+0.14942333j  0.88534137+0.34671507j\n",
      "    0.19711277+1.59253349j]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.35110619+0.75164102j -0.66832613-0.88770411j\n",
      "    0.56969782+0.60267587j  0.1448037 +0.17523717j\n",
      "    0.2925982 +1.4000573j ]\n",
      "  [ 0.10966727-1.22817466j  0.79169845+0.40461756j\n",
      "    0.16540382+0.72903676j  0.03785419+0.72473118j\n",
      "   -0.97545371+0.74242792j]\n",
      "  [-0.54865403+1.01148071j  0.22893075+0.5099906j\n",
      "    0.89581451-0.89142613j  0.5665831 -0.38018336j\n",
      "   -0.66661349+0.50856041j]\n",
      "  [-0.36387826+1.17965168j -0.01587501-0.66000489j\n",
      "   -0.10909053+0.70365052j  0.05971599+1.01355122j\n",
      "    0.1232049 +0.73097491j]\n",
      "  [ 0.42698062-0.89785996j -0.95494014-0.88348405j\n",
      "   -0.90977225+0.00804317j -0.20193161-0.02668996j\n",
      "   -1.69940106-0.17876902j]]\n",
      "\n",
      " [[ 0.76513758-0.89034527j  1.01685448-0.00874106j\n",
      "    0.28316273+0.87179655j -0.68672858-0.12423602j\n",
      "   -0.44265524+0.24376109j]\n",
      "  [-0.40001253-0.11647371j -0.53445838+1.26245197j\n",
      "   -1.13089017-0.72087593j -0.49797817-0.70575168j\n",
      "   -0.9633443 +0.51147263j]\n",
      "  [ 0.54043188+0.3411341j  -0.67908527+1.55748463j\n",
      "   -1.30985573+0.24588651j -1.43974121-0.04183714j\n",
      "   -0.51747427+1.2642712j ]\n",
      "  [ 0.16977946-0.20115379j -0.55330591-1.15664491j\n",
      "   -0.27434796+0.55125128j -0.85766661-0.10238393j\n",
      "    0.81617442-0.00872848j]\n",
      "  [-0.81229511-0.19632708j  0.41739093-0.45775496j\n",
      "   -0.76014925+0.71615056j -0.30547585-0.55516717j\n",
      "   -1.65385442+0.29650634j]]\n",
      "\n",
      " [[ 0.13441276-1.1112329j  -0.10208992+0.37949394j\n",
      "    0.21410846+0.60197919j  1.06091448-0.72269727j\n",
      "    0.10345367-1.57739645j]\n",
      "  [ 0.24680004+0.11809635j  0.69535003-0.0301694j\n",
      "    0.69358654+0.54599125j  0.54677691-0.53646087j\n",
      "    1.46393104+0.72790428j]\n",
      "  [-0.11393922-0.178748j   -0.01908946-0.04262089j\n",
      "    0.94483365+0.38377272j -0.4907984 -0.4920892j\n",
      "    0.52972141+1.3019612j ]\n",
      "  [-0.7882661 -0.15441574j  0.41362767-0.48322579j\n",
      "    0.90501556+0.51547975j -1.01851061+0.79979708j\n",
      "   -0.01309613-0.60471579j]\n",
      "  [-0.43597285+0.28624563j -0.06172437+0.16210253j\n",
      "    0.43510299+0.38052826j -0.53205679+0.33003762j\n",
      "   -0.81119791+0.79430835j]]]\n"
     ]
    }
   ],
   "source": [
    "print(F_H_0dB)\n",
    "# print(F_H_10dB)\n",
    "# print(F_H_20dB)\n",
    "# print(F_H_30dB)\n",
    "# print(F_H_40dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the square of the absolute value of a complex tensor\n",
    "def cmplx_abs_sqr(cmplx_var):\n",
    "    # Calculate the squared magnitude of the complex numbers\n",
    "    return tf.math.square(tf.math.real(cmplx_var)) + tf.math.square(tf.math.imag(cmplx_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the matrix A (K x K) using TensorFlow functions\n",
    "def generate_A(F_H_size, K, SINR_P_min, F_H):\n",
    "    # Calculate the squared magnitude of the complex matrix and cast to float32\n",
    "    F_H_abs_sqr = tf.cast(cmplx_abs_sqr(F_H), dtype=tf.float32)\n",
    "\n",
    "    # Create an identity matrix for selecting diagonal elements (float32)\n",
    "    identity_matrix = tf.eye(K, dtype=tf.float32)\n",
    "\n",
    "    # Expand SINR_P_min to match dimensions for broadcasting and cast to float32\n",
    "    SINR_P_min_expanded = tf.expand_dims(tf.cast(SINR_P_min, dtype=tf.float32), axis=-1)  # Shape: (K, 1)\n",
    "\n",
    "    # Create the matrix A using TensorFlow operations\n",
    "    Aij = tf.where(\n",
    "        tf.equal(identity_matrix, 1),  # Condition to keep diagonal elements\n",
    "        F_H_abs_sqr,                   # Use F_H_abs_sqr for diagonal elements\n",
    "        -SINR_P_min_expanded * F_H_abs_sqr  # Multiply off-diagonal elements by -SINR_P_min\n",
    "    )\n",
    "\n",
    "    # Reshape the resulting array to (F_H_size, K, K)\n",
    "    Aij = tf.reshape(Aij, (F_H_size, K, K))\n",
    "\n",
    "    return Aij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to generate the vector b (K x 1) using TensorFlow operations\n",
    "def generate_b(F_H_size, K, SINR_P_min, sigma_sqr_noise, F_H):\n",
    "    # Calculate the vector b by broadcasting SINR_P_min and sigma_sqr_noise\n",
    "    b = tf.multiply(SINR_P_min, sigma_sqr_noise)  # Element-wise multiplication\n",
    "    \n",
    "    # Reshape to (1, K, 1) to match dimensions for broadcasting\n",
    "    b = tf.reshape(b, (1, K, 1))\n",
    "\n",
    "    # Repeat this result across the F_H_size dimension\n",
    "    bi = tf.repeat(b, repeats=F_H_size, axis=0)\n",
    "    \n",
    "    return bi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split datasets into training, validation, and testing\n",
    "def split(np_array):\n",
    "    # Define fixed sizes for training, validation, and testing datasets\n",
    "    train_data_size = 200000\n",
    "    valid_data_size = 25000\n",
    "    test_data_size = 25000\n",
    "\n",
    "    # Calculate the indices for slicing the dataset\n",
    "    train_e_indx = train_data_size\n",
    "    valid_e_indx = train_e_indx + valid_data_size\n",
    "    test_e_indx = valid_e_indx + test_data_size\n",
    "\n",
    "    # Slice the input array into training, validation, and testing datasets\n",
    "    train_data = np_array[:train_e_indx]\n",
    "    valid_data = np_array[train_e_indx:valid_e_indx]\n",
    "    test_data = np_array[valid_e_indx:test_e_indx]\n",
    "\n",
    "    # Calculate the absolute values of the datasets\n",
    "    train_input = np.abs(train_data)\n",
    "    valid_input = np.abs(valid_data)\n",
    "    test_input = np.abs(test_data)\n",
    "\n",
    "    # Print the shapes to verify correctness\n",
    "    print(train_input.shape, valid_input.shape, test_input.shape)\n",
    "\n",
    "    # Return the split datasets\n",
    "    return [train_input, valid_input, test_input, test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n",
      "(200000, 5, 5) (25000, 5, 5) (25000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# List of F_H matrices\n",
    "F_H_matrices = [F_H_0dB, F_H_10dB, F_H_20dB, F_H_30dB, F_H_40dB]\n",
    "\n",
    "# Split each matrix and assign the results to corresponding variables\n",
    "splits = [split(F_H) for F_H in F_H_matrices]\n",
    "\n",
    "(train_input_F_H_0dB, valid_input_F_H_0dB, test_input_F_H_0dB, test_data_F_H_0dB), \\\n",
    "(train_input_F_H_10dB, valid_input_F_H_10dB, test_input_F_H_10dB, test_data_F_H_10dB), \\\n",
    "(train_input_F_H_20dB, valid_input_F_H_20dB, test_input_F_H_20dB, test_data_F_H_20dB), \\\n",
    "(train_input_F_H_30dB, valid_input_F_H_30dB, test_input_F_H_30dB, test_data_F_H_30dB), \\\n",
    "(train_input_F_H_40dB, valid_input_F_H_40dB, test_input_F_H_40dB, test_data_F_H_40dB) = splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of p_hat vectors\n",
    "# p_hat_vectors = [p_hat_0dB, p_hat_10dB, p_hat_20dB, p_hat_30dB, p_hat_40dB]\n",
    "\n",
    "# # Split each vector and assign the results to corresponding variables\n",
    "# p_hat_splits = [split(p_hat) for p_hat in p_hat_vectors]\n",
    "\n",
    "# (train_input_p_hat_0dB, valid_input_p_hat_0dB, test_input_p_hat_0dB, test_data_p_hat_0dB), \\\n",
    "# (train_input_p_hat_10dB, valid_input_p_hat_10dB, test_input_p_hat_10dB, test_data_p_hat_10dB), \\\n",
    "# (train_input_p_hat_20dB, valid_input_p_hat_20dB, test_input_p_hat_20dB, test_data_p_hat_20dB), \\\n",
    "# (train_input_p_hat_30dB, valid_input_p_hat_30dB, test_input_p_hat_30dB, test_data_p_hat_30dB), \\\n",
    "# (train_input_p_hat_40dB, valid_input_p_hat_40dB, test_input_p_hat_40dB, test_data_p_hat_40dB) = p_hat_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n",
      "(250000, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of sizes and dB levels\n",
    "sizes = [F_H_0dB_size, F_H_10dB_size, F_H_20dB_size, F_H_30dB_size, F_H_40dB_size]\n",
    "dB_levels = [0, 10, 20, 30, 40]\n",
    "\n",
    "# Create EsN0 arrays and reshape into vectors using TensorFlow\n",
    "EsN0_arrays = [tf.fill([size, 1], dB) for size, dB in zip(sizes, dB_levels)]\n",
    "\n",
    "# Unpack into variables\n",
    "(EsN0_vector_0dB, EsN0_vector_10dB, EsN0_vector_20dB, \n",
    " EsN0_vector_30dB, EsN0_vector_40dB) = EsN0_arrays\n",
    "\n",
    "# Print shapes of the vectors\n",
    "print(EsN0_vector_0dB.shape)\n",
    "print(EsN0_vector_10dB.shape)\n",
    "print(EsN0_vector_20dB.shape)\n",
    "print(EsN0_vector_30dB.shape)\n",
    "print(EsN0_vector_40dB.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split EsN0 vector for training, validation, and testing\n",
    "def split_EsN0(tf_vector):\n",
    "    # Define fixed sizes for training, validation, and testing datasets\n",
    "    train_data_size = 200000\n",
    "    valid_data_size = 25000\n",
    "    test_data_size = 25000\n",
    "\n",
    "    # Calculate indices for slicing\n",
    "    train_e_indx = train_data_size\n",
    "    valid_e_indx = train_e_indx + valid_data_size\n",
    "    test_e_indx = valid_e_indx + test_data_size\n",
    "\n",
    "    # Slice the tensor directly into training, validation, and testing datasets using TensorFlow\n",
    "    train_data = tf.reshape(tf_vector[:train_e_indx], (train_data_size, -1, 1))\n",
    "    valid_data = tf.reshape(tf_vector[train_e_indx:valid_e_indx], (valid_data_size, -1, 1))\n",
    "    test_data = tf.reshape(tf_vector[valid_e_indx:test_e_indx], (test_data_size, -1, 1))\n",
    "\n",
    "    # Calculate the absolute values (if needed)\n",
    "    train_input = tf.abs(train_data)\n",
    "    valid_input = tf.abs(valid_data)\n",
    "    test_input = tf.abs(test_data)\n",
    "\n",
    "    # Print shapes to verify correctness\n",
    "    print(train_input.shape, valid_input.shape, test_input.shape)\n",
    "\n",
    "    # Return the split datasets\n",
    "    return [train_input, valid_input, test_input, test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n",
      "(200000, 1, 1) (25000, 1, 1) (25000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of EsN0 vectors\n",
    "EsN0_vectors = [EsN0_vector_0dB, EsN0_vector_10dB, EsN0_vector_20dB, EsN0_vector_30dB, EsN0_vector_40dB]\n",
    "\n",
    "# Split each EsN0 vector\n",
    "EsN0_splits = [split_EsN0(EsN0) for EsN0 in EsN0_vectors]\n",
    "\n",
    "# Unpack the split results into corresponding variables\n",
    "(train_input_EsN0_0dB, valid_input_EsN0_0dB, test_input_EsN0_0dB, test_data_EsN0_0dB), \\\n",
    "(train_input_EsN0_10dB, valid_input_EsN0_10dB, test_input_EsN0_10dB, test_data_EsN0_10dB), \\\n",
    "(train_input_EsN0_20dB, valid_input_EsN0_20dB, test_input_EsN0_20dB, test_data_EsN0_20dB), \\\n",
    "(train_input_EsN0_30dB, valid_input_EsN0_30dB, test_input_EsN0_30dB, test_data_EsN0_30dB), \\\n",
    "(train_input_EsN0_40dB, valid_input_EsN0_40dB, test_input_EsN0_40dB, test_data_EsN0_40dB) = EsN0_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 5, 5)\n",
      "(1000000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of input arrays for F_H and EsN0\n",
    "train_inputs_F_H = [train_input_F_H_0dB, train_input_F_H_10dB, \n",
    "                    train_input_F_H_20dB, train_input_F_H_30dB, \n",
    "                    train_input_F_H_40dB]\n",
    "\n",
    "train_inputs_EsN0 = [train_input_EsN0_0dB, train_input_EsN0_10dB, \n",
    "                     train_input_EsN0_20dB, train_input_EsN0_30dB, \n",
    "                     train_input_EsN0_40dB]\n",
    "\n",
    "# Stack the datasets vertically using TensorFlow's tf.concat\n",
    "train_input_F_H = tf.concat(train_inputs_F_H, axis=0)\n",
    "train_input_EsN0 = tf.concat(train_inputs_EsN0, axis=0)\n",
    "\n",
    "# Print shapes to verify correctness\n",
    "print(train_input_F_H.shape)\n",
    "print(train_input_EsN0.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 5, 5)\n",
      "(125000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of validation input arrays for F_H and EsN0\n",
    "valid_inputs_F_H = [valid_input_F_H_0dB, valid_input_F_H_10dB, \n",
    "                    valid_input_F_H_20dB, valid_input_F_H_30dB, \n",
    "                    valid_input_F_H_40dB]\n",
    "\n",
    "valid_inputs_EsN0 = [valid_input_EsN0_0dB, valid_input_EsN0_10dB, \n",
    "                     valid_input_EsN0_20dB, valid_input_EsN0_30dB, \n",
    "                     valid_input_EsN0_40dB]\n",
    "\n",
    "# Stack the datasets vertically using TensorFlow's tf.concat\n",
    "valid_input_F_H = tf.concat(valid_inputs_F_H, axis=0)\n",
    "valid_input_EsN0 = tf.concat(valid_inputs_EsN0, axis=0)\n",
    "\n",
    "# Print shapes to verify correctness\n",
    "print(valid_input_F_H.shape)\n",
    "print(valid_input_EsN0.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the training datasets using TensorFlow\n",
    "train_shuffler = tf.random.shuffle(tf.range(tf.shape(train_input_F_H)[0]))\n",
    "\n",
    "train_input_F_H_shuffled = tf.gather(train_input_F_H, train_shuffler)\n",
    "train_input_EsN0_shuffled = tf.gather(train_input_EsN0, train_shuffler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the validation datasets using TensorFlow\n",
    "valid_shuffler = tf.random.shuffle(tf.range(tf.shape(valid_input_F_H)[0]))\n",
    "\n",
    "valid_input_F_H_shuffled = tf.gather(valid_input_F_H, valid_shuffler)\n",
    "valid_input_EsN0_shuffled = tf.gather(valid_input_EsN0, valid_shuffler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1000000       1      26], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "const = K * K\n",
    "len1 = tf.shape(train_input_F_H_shuffled)[0]\n",
    "\n",
    "# Reshape train_input_F_H_shuffled using TensorFlow's reshape function\n",
    "train_input_F_H_shuffled_reshaped = tf.reshape(train_input_F_H_shuffled, (len1, 1, const))  # size X row X column\n",
    "\n",
    "# Ensure both tensors are of the same type, e.g., float32\n",
    "train_input_F_H_shuffled_reshaped = tf.cast(train_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "train_input_EsN0_shuffled = tf.cast(train_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# Remove the dimension of size 1 in the middle\n",
    "#train_y_true = tf.squeeze(train_y_true, axis=1)\n",
    "\n",
    "# Print the shape of the result\n",
    "print(tf.shape(train_y_true))  # Expected output: [1000000, 26]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constants\n",
    "# const = K * K\n",
    "# len1 = tf.shape(train_input_F_H_shuffled)[0]\n",
    "\n",
    "# # Reshape train_input_F_H_shuffled using TensorFlow's reshape function\n",
    "# train_input_F_H_shuffled_reshaped = tf.reshape(train_input_F_H_shuffled, (len1, 1, const))  # size X row X column\n",
    "\n",
    "# # Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "# train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# # Print the shape of the result\n",
    "# print(tf.shape(train_y_true))\n",
    "\n",
    "# # Ensure both tensors are of the same type, e.g., float32\n",
    "# train_input_F_H_shuffled_reshaped = tf.cast(train_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "# train_input_EsN0_shuffled = tf.cast(train_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# # Concatenate reshaped F_H and EsN0 inputs using TensorFlow's concat function\n",
    "# train_y_true = tf.concat([train_input_F_H_shuffled_reshaped, train_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "# # Print the shape of the result\n",
    "# print(tf.shape(train_y_true))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([125000      1     26], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Reshape valid_input_F_H_shuffled\n",
    "len2 = tf.shape(valid_input_F_H_shuffled)[0]\n",
    "\n",
    "# Reshape using TensorFlow\n",
    "valid_input_F_H_shuffled_reshaped = tf.reshape(valid_input_F_H_shuffled, [len2, 1, const])  # size X row X column\n",
    "\n",
    "# Ensure both tensors are of the same data type, for example, float32\n",
    "valid_input_F_H_shuffled_reshaped = tf.cast(valid_input_F_H_shuffled_reshaped, dtype=tf.float32)\n",
    "valid_input_EsN0_shuffled = tf.cast(valid_input_EsN0_shuffled, dtype=tf.float32)\n",
    "\n",
    "# Concatenate reshaped F_H and EsN0 inputs using TensorFlow\n",
    "valid_y_true = tf.concat([valid_input_F_H_shuffled_reshaped, valid_input_EsN0_shuffled], axis=2)\n",
    "\n",
    "#valid_y_true = tf.squeeze(valid_y_true, axis=1) \n",
    "\n",
    "# Print the shape of the result using TensorFlow\n",
    "print(tf.shape(valid_y_true))\n",
    "\n",
    "#print(valid_y_true.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Functional_Api\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " hij_inputs (InputLayer)        [(None, 5, 5)]       0           []                               \n",
      "                                                                                                  \n",
      " EsN0_inputs (InputLayer)       [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " flatten_layer_hij (Flatten)    (None, 25)           0           ['hij_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " Flatten_Layer_EsN0 (Flatten)   (None, 1)            0           ['EsN0_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 26)           0           ['flatten_layer_hij[0][0]',      \n",
      "                                                                  'Flatten_Layer_EsN0[0][0]']     \n",
      "                                                                                                  \n",
      " Dense_layer_1 (Dense)          (None, 50)           1350        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " BN_Layer_1 (BatchNormalization  (None, 50)          200         ['Dense_layer_1[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Dense_Layer_2 (Dense)          (None, 25)           1275        ['BN_Layer_1[0][0]']             \n",
      "                                                                                                  \n",
      " BN_Layer_2 (BatchNormalization  (None, 25)          100         ['Dense_Layer_2[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " P_hat (Dense)                  (None, 5)            130         ['BN_Layer_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,055\n",
      "Trainable params: 2,905\n",
      "Non-trainable params: 150\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define the DNN model - The Functional API\n",
    "\n",
    "hij_inputs = keras.Input(shape=(K,K), name = \"hij_inputs\")\n",
    "Flatten_1 = layers.Flatten(name = \"flatten_layer_hij\")(hij_inputs)\n",
    "\n",
    "EsN0_inputs = keras.Input(shape=(1,1), name = \"EsN0_inputs\")\n",
    "Flatten_2 = layers.Flatten(name = \"Flatten_Layer_EsN0\")(EsN0_inputs)\n",
    "\n",
    "concat_layers = concatenate([Flatten_1, Flatten_2])\n",
    "\n",
    "Dense_1 = layers.Dense(2*K*K, activation=\"relu\", name = \"Dense_layer_1\")(concat_layers)\n",
    "BN_1 = layers.BatchNormalization(name = \"BN_Layer_1\")(Dense_1)\n",
    "\n",
    "Dense_2 = layers.Dense(K*K, activation=\"relu\", name = \"Dense_Layer_2\")(BN_1)\n",
    "BN_2 = layers.BatchNormalization(name = \"BN_Layer_2\")(Dense_2)\n",
    "\n",
    "P_hat = layers.Dense(K, activation=\"sigmoid\", name = \"P_hat\")(BN_2)\n",
    "\n",
    "model = keras.Model(inputs = [hij_inputs, EsN0_inputs], outputs = P_hat, name = \"Functional_Api\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "## Convert SINR_P_min from numpy array to tensor\n",
    "SINR_P_min_t = tf.convert_to_tensor(SINR_P_min, dtype = float)\n",
    "tf.print(SINR_P_min_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A_tilda(A, K):\n",
    "    # Identity matrix of size K x K\n",
    "    I = tf.eye(K)\n",
    "    \n",
    "    # Negative identity matrix\n",
    "    neg_I = -I\n",
    "\n",
    "    # Repeat the identity and negative identity across batch dimension (1000)\n",
    "    I_batch = tf.tile(tf.expand_dims(I, axis=0), [A.shape[0], 1, 1])\n",
    "    neg_I_batch = tf.tile(tf.expand_dims(neg_I, axis=0), [A.shape[0], 1, 1])\n",
    "\n",
    "    # Concatenate I, -I, and A to form A_tilda\n",
    "    A_tilda = tf.concat([I_batch, neg_I_batch, A], axis=1)\n",
    "\n",
    "    return A_tilda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_B_tilda(B, K):\n",
    "    # Zero vector of size K\n",
    "    zeros = tf.zeros_like(B)\n",
    "    ones = tf.ones_like(B) * -PMax\n",
    "\n",
    "    # Reshape B to match the required dimensions\n",
    "    B_reshaped = tf.reshape(B, (-1, K, 1))\n",
    "\n",
    "    # Concatenate zeros and B to form B_tilda\n",
    "    B_tilda = tf.concat([zeros, ones, B_reshaped], axis=1)\n",
    "\n",
    "    return B_tilda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_A_tilda(A_tilda):\n",
    "    return tf.transpose(A_tilda, perm=[0, 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized loss function that penalizes the constraint violation\n",
    "def custom_loss_DC3(y_true, y_pred):\n",
    "    # Multiply predicted values by p_max\n",
    "    p = tf.multiply(PMax, y_pred)\n",
    "    p = tf.reshape(p, (-1, K, 1))\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "    eta = 1e-3\n",
    "        \n",
    "\n",
    "    # Extract EsN0 value and reshape y_true to exclude EsN0 column\n",
    "    mtrx_elmnt = K * K\n",
    "    EsN0_val = y_true[:, 0, mtrx_elmnt]\n",
    "    y_true_updt = y_true[:, :, :-1]\n",
    "\n",
    "    # Determine noise variance based on EsN0 value\n",
    "    sigma_sqr_noise_lf = tf.where(EsN0_val < 10, 1e-0,\n",
    "                                  tf.where(EsN0_val < 20, 1e-1,\n",
    "                                           tf.where(EsN0_val < 30, 1e-2,\n",
    "                                                    tf.where(EsN0_val < 40, 1e-3, 1e-4))))\n",
    "\n",
    "    # Reshape y_true to form hij matrix and calculate squared magnitudes\n",
    "    hij = tf.reshape(y_true_updt[:, 0:K*K], (-1, K, K))\n",
    "    hij_abs_sqr = tf.square(tf.abs(hij))\n",
    "\n",
    "\n",
    "\n",
    "      ## Create matrix A\n",
    "    A = generate_A(hij.shape[0], K, SINR_P_min, hij)\n",
    "    b = generate_b(hij.shape[0], K, SINR_P_min, sigma_sqr_noise_0dB, hij)\n",
    "    \n",
    "    B = tf.reshape(b, (-1, K, 1))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Define A_tilda, b_tilda, A_transpose_tilda\n",
    "     ## Compute A_tilda and B_tilda\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(B, K)\n",
    "\n",
    "    ## Transpose A_tilda\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    \n",
    "    # Gradient Descent for Correction\n",
    "    for i in range(5):\n",
    "         # V = tf.linalg.matmul(A_tilda , p )  - b_tilda\n",
    "         V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "         V_relu = tf.nn.relu(V)\n",
    "         gd   = 2 * tf.linalg.matmul( A_tilda_T ,V_relu)\n",
    "         p = p + eta * gd\n",
    "         \n",
    "\n",
    "             \n",
    "    # # Calculate interference and SINR for each transmitter-receiver pair\n",
    "    #ph = tf.reduce_sum(tf.multiply(p[:, tf.newaxis], hij_abs_sqr), axis=2)  # Interference + noise\n",
    "\n",
    "    ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr), axis=2) \n",
    "    diag_part_expanded = tf.expand_dims(tf.linalg.diag_part(hij_abs_sqr), axis=-1)\n",
    "    numr = tf.multiply(p, diag_part_expanded)  # Signal power (numerator)\n",
    "    sigma_sqr_noise_lf_expanded = tf.expand_dims(sigma_sqr_noise_lf, axis=-1)\n",
    "    dnumr = sigma_sqr_noise_lf_expanded + ph - tf.squeeze(numr, axis=-1)\n",
    "    SINR_i = tf.divide(tf.squeeze(numr, axis=-1), dnumr)\n",
    "    \n",
    "    #numr = tf.multiply(p, tf.linalg.diag_part(hij_abs_sqr))  # Signal power (numerator)\n",
    "    #dnumr = sigma_sqr_noise_lf[:, tf.newaxis] + ph - numr  # Denominator of SINR\n",
    "    #SINR_i = tf.divide(numr, dnumr)  # SINR values\n",
    "    R_P = tf.reduce_sum(tf.math.log(1 + SINR_i) / tf.math.log(2.0), axis=1)  # Sum rate\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # p1 = tf.reshape(p, (-1, K, 1))\n",
    "\n",
    "    w = PMax - p\n",
    "    \n",
    "    A_p = tf.matmul(A, p)\n",
    "\n",
    "    #B = tf.reshape(b, (-1, K, 1))\n",
    "   \n",
    "    s = B - A_p\n",
    "\n",
    "\n",
    "    # Apply ReLU to the constraint violation\n",
    "    constraint_violation = tf.nn.relu(tf.concat([p, w, s],axis=1))\n",
    "    \n",
    "    # L2 norm of the constraint violation\n",
    "    penalty_term = tf.reduce_sum(tf.square(constraint_violation), axis=1)  # ||ReLU(gx(y))||^2\n",
    "\n",
    "\n",
    "    # Final loss calculation\n",
    "\n",
    "    # lambda_l = 5.0\n",
    "    lambda_l = 10.0\n",
    "    # lambda_l = 15.0\n",
    "    # lambda_l = 20.0\n",
    "    # lambda_l = 25.0\n",
    "\n",
    "    loss = -R_P + lambda_l * penalty_term\n",
    "    return tf.reduce_mean(loss)  # Batch mean loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss_DC3(y_true, y_pred):\n",
    "#     # Multiply predicted values by PMax\n",
    "#     p = tf.multiply(PMax, y_pred)  # p: [batch_size, K, 1]\n",
    "#     p = tf.reshape(p, (-1, K, 1))  # Ensure p has shape [batch_size, K, 1]\n",
    "\n",
    "#     eta = 1e-3\n",
    "\n",
    "#     # Extract EsN0 value and reshape y_true to exclude EsN0 column\n",
    "#     mtrx_elmnt = K * K\n",
    "#     EsN0_val = y_true[:, 0, mtrx_elmnt]\n",
    "#     y_true_updt = y_true[:, :, :-1]\n",
    "\n",
    "#     # Determine noise variance based on EsN0 value\n",
    "#     sigma_sqr_noise_lf = tf.where(\n",
    "#         EsN0_val < 10, 1e-0,\n",
    "#         tf.where(EsN0_val < 20, 1e-1,\n",
    "#                  tf.where(EsN0_val < 30, 1e-2,\n",
    "#                           tf.where(EsN0_val < 40, 1e-3, 1e-4))))\n",
    "#     sigma_sqr_noise_lf = tf.reshape(sigma_sqr_noise_lf, (-1, 1, 1))  # Shape: [batch_size, 1, 1]\n",
    "\n",
    "#     # Reshape y_true to form hij matrix and calculate squared magnitudes\n",
    "#     hij = tf.reshape(y_true_updt[:, 0:K*K], (-1, K, K))  # Shape: [batch_size, K, K]\n",
    "#     hij_abs_sqr = tf.square(tf.abs(hij))  # Shape: [batch_size, K, K]\n",
    "\n",
    "#     # Generate matrices A and b (assuming these functions are defined)\n",
    "#     A = generate_A(hij.shape[0], K, SINR_P_min, hij)\n",
    "#     b = generate_b(hij.shape[0], K, SINR_P_min, sigma_sqr_noise_0dB, hij)\n",
    "\n",
    "#     # Define A_tilda, b_tilda, A_transpose_tilda\n",
    "#     A_tilda = generate_A_tilda(A, K)\n",
    "#     B_tilda = generate_B_tilda(b, K)\n",
    "#     A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "#     # Gradient Descent for Correction\n",
    "#     for i in range(5):\n",
    "#         V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "#         V_relu = tf.nn.relu(V)\n",
    "#         gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)\n",
    "#         p = p + eta * gd\n",
    "\n",
    "#     # Ensure p remains of shape [batch_size, K, 1]\n",
    "\n",
    "#     # Compute ph (Interference + noise)\n",
    "#     p_expanded = tf.expand_dims(p, axis=1)  # Shape: [batch_size, 1, K, 1]\n",
    "#     hij_abs_sqr_expanded = tf.expand_dims(hij_abs_sqr, axis=-1)  # Shape: [batch_size, K, K, 1]\n",
    "\n",
    "#     # Multiply p and hij_abs_sqr\n",
    "#     ph_intermediate = tf.multiply(p_expanded, hij_abs_sqr_expanded)  # Shape: [batch_size, K, K, 1]\n",
    "#     ph = tf.reduce_sum(ph_intermediate, axis=2)  # Sum over interfering users; shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute numr (Signal power numerator)\n",
    "#     diag_hij_abs_sqr = tf.linalg.diag_part(hij_abs_sqr)  # Shape: [batch_size, K]\n",
    "#     diag_hij_abs_sqr = tf.expand_dims(diag_hij_abs_sqr, axis=-1)  # Shape: [batch_size, K, 1]\n",
    "#     numr = tf.multiply(p, diag_hij_abs_sqr)  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute dnumr (Denominator of SINR)\n",
    "#     dnumr = sigma_sqr_noise_lf + ph - numr  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute SINR\n",
    "#     SINR_i = tf.divide(numr, dnumr)  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Compute sum rate R_P\n",
    "#     R_P = tf.reduce_sum(tf.math.log(1 + SINR_i) / tf.math.log(2.0), axis=1)  # Shape: [batch_size, 1]\n",
    "\n",
    "#     # Constraint terms\n",
    "#     w = PMax - p  # Shape: [batch_size, K, 1]\n",
    "#     A_p = tf.linalg.matmul(A, p)  # Ensure A is of shape [batch_size, K, K], p: [batch_size, K, 1]; result: [batch_size, K, 1]\n",
    "#     s = b - A_p  # Shape: [batch_size, K, 1]\n",
    "\n",
    "#     # Apply ReLU to the constraint violation\n",
    "#     constraint_violation = tf.nn.relu(tf.concat([p, w, s], axis=1))  # Shape: [batch_size, 3*K, 1]\n",
    "\n",
    "#     # L2 norm of the constraint violation\n",
    "#     penalty_term = tf.reduce_sum(tf.square(constraint_violation), axis=[1, 2])  # Shape: [batch_size]\n",
    "\n",
    "#     # Final loss calculation\n",
    "#     lambda_l = 10.0\n",
    "#     loss = -R_P[:, 0] + lambda_l * penalty_term  # Shape: [batch_size]\n",
    "#     return tf.reduce_mean(loss)  # Batch mean loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 13s 11ms/step - loss: 24.2639 - val_loss: 24.2609\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2617 - val_loss: 24.2615\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2584 - val_loss: 24.2589\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2552 - val_loss: 24.2570\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2514 - val_loss: 24.2478\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2478 - val_loss: 24.2488\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2458 - val_loss: 24.2445\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2442 - val_loss: 24.2411\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2428 - val_loss: 24.2407\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2418 - val_loss: 24.2401\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2394 - val_loss: 24.2397\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2382 - val_loss: 24.2358\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2375 - val_loss: 24.2370\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2355 - val_loss: 24.2319\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2340 - val_loss: 24.2314\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2311 - val_loss: 24.2272\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2295 - val_loss: 24.2273\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2287 - val_loss: 24.2269\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2266 - val_loss: 24.2235\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2248 - val_loss: 24.2207\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2236 - val_loss: 24.2210\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2228 - val_loss: 24.2199\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2223 - val_loss: 24.2178\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 24.2217 - val_loss: 24.2188\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 24.2213 - val_loss: 24.2184\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 24.2209 - val_loss: 24.2192\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2204 - val_loss: 24.2163\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2199 - val_loss: 24.2165\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2196 - val_loss: 24.2179\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2193 - val_loss: 24.2163\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2192 - val_loss: 24.2169\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2189 - val_loss: 24.2161\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2186 - val_loss: 24.2150\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2185 - val_loss: 24.2153\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2181 - val_loss: 24.2188\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2166 - val_loss: 24.2138\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2154 - val_loss: 24.2114\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2148 - val_loss: 24.2106\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2146 - val_loss: 24.2119\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2144 - val_loss: 24.2104\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2143 - val_loss: 24.2109\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2142 - val_loss: 24.2107\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2141 - val_loss: 24.2110\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2140 - val_loss: 24.2106\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2139 - val_loss: 24.2098\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2138 - val_loss: 24.2101\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2137 - val_loss: 24.2117\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2137 - val_loss: 24.2102\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2134 - val_loss: 24.2096\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 24.2134 - val_loss: 24.2094\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Build and compile the DNN model\n",
    "## Training and Testing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Opt_Adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer = Opt_Adam, loss = custom_loss_DC3)\n",
    "\n",
    "train_input = [train_input_F_H_shuffled, train_input_EsN0_shuffled]\n",
    "valid_input = [valid_input_F_H_shuffled, valid_input_EsN0_shuffled]\n",
    "\n",
    "history = model.fit(train_input, train_y_true, epochs = 50,\n",
    "                    validation_data = (valid_input, valid_y_true), batch_size = 1000)\n",
    "\n",
    "plt.plot(history.epoch, history.history['loss'], color = \"blue\", label = \"Training\")\n",
    "plt.plot(history.epoch, history.history['val_loss'], color=\"black\", label = \"Validation\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step\n",
      "Constraints Violation Probability: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Test data setup\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))  # Predicted power allocation\n",
    "output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], K, 1))  # Reshape to [num_samples, K, 1]\n",
    "output_P_hat_size = tf.shape(output_P_hat)[0]  # Number of samples\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)  # Compute squared magnitude of hij\n",
    "\n",
    "eta = 1e-3  # Learning rate for gradient descent\n",
    "indx_n = []  # List to store indices of samples with constraint violations\n",
    "count_v = 0  # Counter for total violations\n",
    "\n",
    "# Iterate over each test sample\n",
    "for k in range(output_P_hat_size):\n",
    "    p = output_P_hat[k]  # Initial power vector for this sample, shape [K, 1]\n",
    "    hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample, shape [K, K]\n",
    "    sigma_sqr_noise_0dB_sample = sigma_sqr_noise_0dB  # Use constant noise variance for all samples\n",
    "\n",
    "    # Ensure consistent data types\n",
    "    p = tf.cast(p, dtype=tf.float32)\n",
    "    hij_abs_sqr = tf.cast(hij_abs_sqr, dtype=tf.float32)\n",
    "    sigma_sqr_noise_0dB_sample = tf.cast(sigma_sqr_noise_0dB_sample, dtype=tf.float32)\n",
    "    SINR_P_min = tf.cast(SINR_P_min, dtype=tf.float32)\n",
    "\n",
    "    # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "    A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "    b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB_sample, hij_abs_sqr)\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(b, K)\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    # Perform gradient descent for 5 iterations\n",
    "    for i in range(5):\n",
    "        V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "        V_relu = tf.nn.relu(V)  # Apply ReLU to the result\n",
    "        gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)  # Gradient descent update\n",
    "        p = p + eta * gd  # Update power allocation\n",
    "\n",
    "    # Check for SINR constraint violations after applying gradient descent\n",
    "    for i in range(K):  # Iterate over each user\n",
    "        ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr[i, :]))  # Interference + noise\n",
    "        numr = tf.multiply(p[i], hij_abs_sqr[i, i])  # Signal power (numerator)\n",
    "        dnumr = sigma_sqr_noise_0dB_sample[i] + ph - numr  # Denominator of SINR\n",
    "        SINR_out = tf.divide(numr, dnumr)  # Compute SINR\n",
    "\n",
    "        # Round SINR to 3 decimal places and check for violations\n",
    "        SINR_out_rounded = tf.round(SINR_out * 1000) / 1000\n",
    "\n",
    "        # Perform element-wise comparison and reduce to check for any violations\n",
    "        violation = tf.reduce_any(SINR_out_rounded < SINR_P_min[i])\n",
    "        if violation:\n",
    "            indx_n.append(k)  # Store index of sample with violation\n",
    "            count_v += 1  # Increment violation counter\n",
    "            break  # Stop checking further users for this sample\n",
    "\n",
    "# Calculate violation probability\n",
    "violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data setup\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))  # Predicted power allocation\n",
    "output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], K, 1))  # Reshape to [num_samples, K, 1]\n",
    "output_P_hat_size = tf.shape(output_P_hat)[0]  # Number of samples\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)  # Compute squared magnitude of hij\n",
    "\n",
    "eta = 1e-3  # Learning rate for gradient descent\n",
    "indx_n = []  # List to store indices of samples with constraint violations\n",
    "count_v = 0  # Counter for total violations\n",
    "\n",
    "# Iterate over each test sample\n",
    "for k in range(output_P_hat_size):\n",
    "    p = output_P_hat[k]  # Initial power vector for this sample, shape [K, 1]\n",
    "    hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample, shape [K, K]\n",
    "    sigma_sqr_noise_0dB_sample = sigma_sqr_noise_0dB[k]  # Noise variance for this sample\n",
    "\n",
    "\n",
    "    # Ensure consistent data types\n",
    "    p = tf.cast(p, dtype=tf.float32)  # Already float32, but ensuring consistency\n",
    "    hij_abs_sqr = tf.cast(hij_abs_sqr, dtype=tf.float32)  # Cast to float32\n",
    "    sigma_sqr_noise_0dB_sample = tf.cast(sigma_sqr_noise_0dB_sample, dtype=tf.float32)  # Cast to float32\n",
    "\n",
    "\n",
    "    # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "    A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "    b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB, hij_abs_sqr)\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(b, K)\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    # Perform gradient descent for 5 iterations\n",
    "    for i in range(5):\n",
    "        V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "        V_relu = tf.nn.relu(V)  # Apply ReLU to the result\n",
    "        gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)  # Gradient descent update\n",
    "        p = p + eta * gd  # Update power allocation\n",
    "\n",
    "    # Check for SINR constraint violations after applying gradient descent\n",
    "    for i in range(K):  # Iterate over each user\n",
    "        ph = tf.reduce_sum(tf.multiply(p, hij_abs_sqr[i, :]))  # Interference + noise\n",
    "        numr = tf.multiply(p[i], hij_abs_sqr[i, i])  # Signal power (numerator)\n",
    "        dnumr = sigma_sqr_noise_0dB[i] + ph - numr  # Denominator of SINR\n",
    "        SINR_out = tf.divide(numr, dnumr)  # Compute SINR\n",
    "\n",
    "        # # Check if SINR is below the minimum required value\n",
    "        if tf.round(SINR_out, decimals=3) < SINR_P_min[i]:\n",
    "            indx_n.append(k)  # Store index of sample with violation\n",
    "            count_v += 1  # Increment violation counter\n",
    "            break  # Stop checking further users for this sample\n",
    "\n",
    "# Calculate violation probability\n",
    "violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Updated test code in TensorFlow to apply gradient descent on test data\n",
    "\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "output_P_hat_temp = tf.multiply(PMax, model.predict(test_input))\n",
    "output_P_hat = tf.reshape(output_P_hat_temp, (tf.shape(output_P_hat_temp)[0], tf.shape(output_P_hat_temp)[1], 1)) # test_input_F_H_size X row X column\n",
    "output_P_hat_size = tf.shape(output_P_hat)[0]\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)\n",
    "\n",
    "eta = 1e-3  # Same learning rate used in the gradient descent\n",
    "\n",
    "indx_n = []\n",
    "count_v = 0\n",
    "\n",
    "for k in range(output_P_hat_size):\n",
    "    p = output_P_hat[k]  # Initial power vector for this sample\n",
    "    hij_abs_sqr = test_data_F_H_abs_sqr[k]  # hij squared magnitude for this sample\n",
    "\n",
    "    # Generate matrices A, b, A_tilda, and B_tilda for this sample\n",
    "    A = generate_A(1, K, SINR_P_min, hij_abs_sqr)\n",
    "    b = generate_b(1, K, SINR_P_min, sigma_sqr_noise_0dB, hij_abs_sqr)\n",
    "    A_tilda = generate_A_tilda(A, K)\n",
    "    B_tilda = generate_B_tilda(b, K)\n",
    "    A_tilda_T = transpose_A_tilda(A_tilda)\n",
    "\n",
    "    # Perform gradient descent on this sample\n",
    "    for i in range(5):\n",
    "        V = B_tilda - tf.linalg.matmul(A_tilda, p)\n",
    "        V_relu = tf.nn.relu(V)  # ReLU operation\n",
    "        gd = 2 * tf.linalg.matmul(A_tilda_T, V_relu)\n",
    "        p = p + eta * gd  # Update the power allocation\n",
    "\n",
    "    # Check for SINR constraint violations after applying gradient descent\n",
    "    for i in range(K):  # Total rows\n",
    "        ph = 0\n",
    "        for j in range(K):  # Total columns\n",
    "            ph_j = tf.multiply(p[j], hij_abs_sqr[i, j])\n",
    "            ph = ph + ph_j\n",
    "\n",
    "        numr = tf.multiply(p[i], hij_abs_sqr[i, i])\n",
    "        dnumr = sigma_sqr_noise_0dB[i] + ph - numr\n",
    "        SINR_out = tf.divide(numr, dnumr)\n",
    "\n",
    "        # Check if the SINR is below the minimum required value\n",
    "        if tf.round(SINR_out, decimals=3) < SINR_P_min[i]:\n",
    "            indx_n.append(k)\n",
    "            count_v += 1\n",
    "            break\n",
    "\n",
    "# Calculate violation probability\n",
    "violation_prb = (count_v / output_P_hat_size.numpy()) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step\n",
      "Constraints Violation Probability: 94.46%\n"
     ]
    }
   ],
   "source": [
    "## Constraint violation probability and\n",
    "## finding indexes of test_input_F_H matrix with the hij set that do not satisfy\n",
    "## constraint on the minimum SINR_P_min rate but satisfy the maximum transmit\n",
    "## power PMax\n",
    "\n",
    "test_input = [test_input_F_H_0dB, test_input_EsN0_0dB]\n",
    "# output_P_hat_temp = model.predict(test_input)\n",
    "output_P_hat_temp = np.multiply(PMax, model.predict(test_input))\n",
    "output_P_hat = output_P_hat_temp.reshape((output_P_hat_temp.shape[0], output_P_hat_temp.shape[1], 1)) # test_input_F_H_size X row X column\n",
    "output_P_hat_size = output_P_hat.shape[0]\n",
    "test_data_F_H_abs_sqr = cmplx_abs_sqr(test_data_F_H_0dB)\n",
    "\n",
    "indx_n = []\n",
    "count_v = 0\n",
    "\n",
    "for k in range(output_P_hat_size):\n",
    "  for i in range(K):  # Total rows\n",
    "    ph = 0\n",
    "    for j in range(K):  # Total columns\n",
    "      ph_j = np.multiply(output_P_hat[k,j], test_data_F_H_abs_sqr[k,i,j])\n",
    "      ph = ph + ph_j\n",
    "\n",
    "    numr = np.multiply(output_P_hat[k,i], test_data_F_H_abs_sqr[k,i,i])\n",
    "    dnumr = sigma_sqr_noise_0dB[i] + ph - numr\n",
    "    SINR_out = np.divide(numr, dnumr)\n",
    "\n",
    "    if np.round(SINR_out, decimals= 3) < SINR_P_min[i]:\n",
    "      indx_n.append(k)\n",
    "      count_v = count_v + 1\n",
    "      # print(SINR_out)\n",
    "      break\n",
    "\n",
    "violation_prb = (count_v / output_P_hat_size) * 100\n",
    "print(\"Constraints Violation Probability: {:.2f}%\".format(violation_prb))\n",
    "# print(len(indx_n))\n",
    "# print(indx_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate the average sum rate\n",
    "# Here, p_model is the output of DNN, and it is a 2D array.\n",
    "import math\n",
    "\n",
    "def average_sum_rate(hij, p_model, sigma_sqr_noise, K):\n",
    "  R = 0\n",
    "  hij_size = hij.shape[0]\n",
    "  hij_abs_sqr = cmplx_abs_sqr(hij)\n",
    "\n",
    "  for k in range(hij_size):\n",
    "    for i in range(K):  # Total rows\n",
    "      phn = 0\n",
    "      for j in range(K):  # Total columns\n",
    "        phn_j = np.multiply(p_model[k,j], hij_abs_sqr[k,i,j])\n",
    "        phn = phn + phn_j\n",
    "\n",
    "      numr_s = np.multiply(p_model[k,i], hij_abs_sqr[k,i,i])\n",
    "      dnumr_s = sigma_sqr_noise[i] + phn - numr_s\n",
    "      R_temp = math.log2(1 + np.divide(numr_s, dnumr_s))\n",
    "      R = R + R_temp\n",
    "\n",
    "  return (R/hij_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step\n",
      "Average Sum Rate for all H matrices: 1.910 Bit/Second/Hertz\n"
     ]
    }
   ],
   "source": [
    "## DNN Sum Rate for test_data_F_H\n",
    "sumrate_F_H = average_sum_rate(test_input[0], model.predict(test_input),sigma_sqr_noise_0dB, K)\n",
    "print(\"Average Sum Rate for all H matrices: {:.3f} Bit/Second/Hertz\".format(sumrate_F_H))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
